[CODE] LLTitle (654)
- file: sample\submodules\coursebook\appendix\appendix.tex (line 450)
  message: Should this be "Includes and Conditionals"? Follow your preferred style guide and register as an exception if necessary.
   448: 
   449: 
>  450: \section{Includes and conditionals}
   451: 
   452: The other preprocessor include is the \keyword{\#include} directive and conditionals.

- file: sample\submodules\coursebook\appendix\appendix.tex (line 774)
  message: Should this be "Implementing CVs With Mutexes Alone"? Follow your preferred style guide and register as an exception if necessary.
   772: 
   773: 
>  774: \section{Implementing CVs with Mutexes Alone}
   775: 
   776: Implementing a condition variable using only a mutex isn't trivial.

- file: sample\submodules\coursebook\appendix\appendix.tex (line 29)
  message: Should this be "Shell Tricks and Tips"? Follow your preferred style guide and register as an exception if necessary.
    27: You can always call through the full path. That is always why in past classes if you want to run something on the terminal you've had to do \keyword{./exe} because typically the directory that you are working in is not in the \keyword{PATH} variable. The \keyword{.} expands to your current directory and your shell executes \keyword{\textless{}current\_dir\textgreater{}/exe} which is a valid command.
    28: 
>   29: \subsection{Shell tricks and tips}
    30: 
    31: \begin{itemize}

- file: sample\submodules\coursebook\appendix\appendix.tex (line 46)
  message: Should this be "What's a Terminal?"? Follow your preferred style guide and register as an exception if necessary.
    44: \end{itemize}
    45: 
>   46: \subsection{What's a terminal?}
    47: 
    48: A terminal is an application that displays the output from the shell. You can have your default terminal, a quake based terminal, terminator, the options are endless!

- file: sample\submodules\coursebook\appendix\appendix.tex (line 145)
  message: Should this be "What Are Environment Variables?"? Follow your preferred style guide and register as an exception if necessary.
   143: \end{lstlisting}
   144: 
>  145: \subsection{What are environment variables?}
   146: 
   147: Each process gets its own dictionary of environment variables that are copied over to the child. Meaning, if the parent changes their environment variables it won't be transferred to the child and vice versa. This is important in the fork-exec-wait trilogy if you want to exec a program with different environment variables than your parent (or any other process).

- file: sample\submodules\coursebook\appendix\appendix.tex (line 590)
  message: Should this be "Cutting Edge File Systems"? Follow your preferred style guide and register as an exception if necessary.
   588: \end{itemize}
   589: 
>  590: \subsection{Cutting Edge File systems}
   591: 
   592: There are a few filesystem hardware nowadays that are truly cutting edge.

- file: sample\submodules\coursebook\appendix\appendix.tex (line 1404)
  message: Should this be "In-Depth IPv4 Specification"? Follow your preferred style guide and register as an exception if necessary.
  1402: 
  1403: 
> 1404: \subsection{In-depth IPv4 Specification}
  1405: 
  1406: The Internet Protocol deals with routing, fragmentation, and reassembly of fragments.

- file: sample\submodules\coursebook\appendix\appendix.tex (line 1507)
  message: Should this be "Kqueue"? Follow your preferred style guide and register as an exception if necessary.
  1505: 
  1506: 
> 1507: \subsection{kqueue}
  1508: 
  1509: When it comes to Event-Driven IO, the name of the game is to be fast.

- file: sample\submodules\coursebook\appendix\appendix.tex (line 1727)
  message: Should this be "Light Bulb Jokes"? Follow your preferred style guide and register as an exception if necessary.
  1725: Warning: Authors are not responsible for any neuro-apoptosis caused by these ``jokes.'' - Groaners are allowed.
  1726: 
> 1727: \subsection{Light bulb jokes}
  1728: 
  1729: Q. How many system programmers does it take to change a lightbulb?

- file: sample\submodules\coursebook\appendix\appendix.tex (line 152)
  message: Should this be "Struct Packing"? Follow your preferred style guide and register as an exception if necessary.
   150: 
   151: 
>  152: \subsubsection{Struct packing}
   153: 
   154: Structs may require something called \href{http://www.catb.org/esr/structure-packing/}{padding} (tutorial).

- file: sample\submodules\coursebook\honors\kernel.tex (line 8)
  message: Should this be "What Kinds of Kernels Are There?"? Follow your preferred style guide and register as an exception if necessary.
     6: We will mostly be focusing on the Linux kernel in this chapter, so please assume that all examples pertain to the Linux kernel unless otherwise specified.
     7: 
>    8: \subsection{What kinds of kernels are there?}
     9: 
    10: As it stands, most of you are probably familiar with the Linux kernel, at least in terms of interacting with it via system calls.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 307)
  message: Should this be "Mmap"? Follow your preferred style guide and register as an exception if necessary.
   305: The other is to ask the kernel to map two pages of memory to the same virtual memory area and handle all the synchronization yourself.
   306: 	 
>  307: \section{mmap}
   308: 	 
   309: \keyword{mmap} is a trick of virtual memory of instead of mapping a page to a frame, that frame can be backed by a file on disk, or the frame can be shared among processes.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 136)
  message: Should this be "Multi-Level Page Tables"? Follow your preferred style guide and register as an exception if necessary.
   134: We'll take about this below. There is one last piece of terminology that needs to be covered.
   135: 	 
>  136: \subsection{Multi-level page tables}
   137: 	 
   138: Multi-level pages are one solution to the page table size issue for 64-bit architectures.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 327)
  message: Should this be "Mmap Definitions"? Follow your preferred style guide and register as an exception if necessary.
   325: Page faults are so powerful because let the operating system take control of when a file is used.
   326: 	 
>  327: \subsection{mmap Definitions}
   328: 	 
   329: \keyword{mmap} does more than take a file and map it to memory.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 350)
  message: Should this be "Annotated Mmap Walkthrough"? Follow your preferred style guide and register as an exception if necessary.
   348: The other parameters to mmap are described in the annotated walkthrough below.
   349: 	 
>  350: \subsection{Annotated mmap Walkthrough}
   351: 	 
   352: Below is an annotated walkthrough of the example code in the man pages.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 697)
  message: Should this be "Other Pipe Facts"? Follow your preferred style guide and register as an exception if necessary.
   695: \keyword{cat} needs to receive a SIGPIPE informing it that the program tried to write to a pipe that no one is listening on.
   696: 	 
>  697: \subsection{Other pipe facts}
   698: 	 
   699: A pipe gets filled up when the writer writes too much to the pipe without the reader reading any of it. When the pipes become full, all writes fail until a read occurs. Even then, a write may partially fail if the pipe has a little bit of space left but not enough for the entire message. Usually, two things are done to avoid this. Either increase the size of the pipe. Or more commonly, fix your program design so that the pipe is constantly being read from.

- file: sample\submodules\coursebook\ipc\ipc.tex (line 861)
  message: Should this be "Race Condition With Named Pipes"? Follow your preferred style guide and register as an exception if necessary.
   859: Any \keyword{open} is called on a named pipe the kernel blocks until another process calls the opposite open. Meaning, echo calls \keyword{open(..,\ O\_RDONLY)} but that blocks until cat calls \keyword{open(..,\ O\_WRONLY)}, then the programs are allowed to continue.
   860: 	 
>  861: \subsection{Race condition with named pipes}
   862: 	 
   863: What is wrong with the following program?

- file: sample\submodules\coursebook\ipc\ipc.tex (line 978)
  message: Should this be "Use Stat Instead"? Follow your preferred style guide and register as an exception if necessary.
   976: See the man pages for fseek and ftell for more information.
   977: 	 
>  978: \subsection{Use stat instead}
   979: 	 
   980: This only works on some architectures and compilers

- file: sample\submodules\coursebook\ipc\ipc.tex (line 995)
  message: Should this be "Gotchas With Files"? Follow your preferred style guide and register as an exception if necessary.
   993: \keyword{buf.st\_size} is of type \keyword{off\_t} which is big enough for large files.
   994: 	 
>  995: \subsection{Gotchas with files}
   996: 	 
   997: What happens when file streams are closed by two different processes?

- file: sample\submodules\coursebook\ipc\ipc.tex (line 157)
  message: Should this be "Visualizing the Dereference"? Follow your preferred style guide and register as an exception if necessary.
   155: Then, the MMU adds the offset and do the read or write.
   156: 	 
>  157: \subsubsection{Visualizing The Dereference}
   158: 	 
   159: In one diagram, the dereference looks like the following image.

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 51)
  message: Should this be "Returning Pointers to Automatic Variables"? Follow your preferred style guide and register as an exception if necessary.
    49: \end{lstlisting}
    50: 
>   51: \subsection{Returning pointers to automatic variables}
    52: 
    53: \begin{lstlisting}[language=C]

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 65)
  message: Should this be "Insufficient Memory Allocation"? Follow your preferred style guide and register as an exception if necessary.
    63: After the function returns, it is an error to continue to use the memory.
    64: 
>   65: \subsection{Insufficient memory allocation}
    66: 
    67: \begin{lstlisting}[language=C]

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 90)
  message: Should this be "Buffer Overflow/ Underflow"? Follow your preferred style guide and register as an exception if necessary.
    88: \end{lstlisting}
    89: 
>   90: \subsection{Buffer overflow/ underflow}
    91: 
    92: A famous example: Heart Bleed performed a memcpy into a buffer that was of insufficient size.

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 112)
  message: Should this be "Strings Require Strlen(s)+1 Bytes"? Follow your preferred style guide and register as an exception if necessary.
   110: 
   111: 
>  112: \subsection{Strings require strlen(s)+1 bytes}
   113: 
   114: Every string must have a NUL byte after the last characters.

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 128)
  message: Should this be "Using Uninitialized Variables"? Follow your preferred style guide and register as an exception if necessary.
   126: \end{lstlisting}
   127: 
>  128: \subsection{Using uninitialized variables}
   129: 
   130: \begin{lstlisting}[language=C]

- file: sample\submodules\coursebook\introc\common_bugs.tex (line 140)
  message: Should this be "Assuming Uninitialized Memory Will Be Zeroed"? Follow your preferred style guide and register as an exception if necessary.
   138: It is an error to assume that it will always be initialized to zero.
   139: 
>  140: \subsection{Assuming Uninitialized memory will be zeroed}
   141: 
   142: \begin{lstlisting}[language=C]

- file: sample\submodules\coursebook\introc\language_facilities.tex (line 527)
  message: Should this be "C Data Types"? Follow your preferred style guide and register as an exception if necessary.
   525: \end{enumerate}
   526: 
>  527: \subsection{C data types}
   528: 
   529: There are many data types in C.

- file: sample\submodules\coursebook\networking\networking.tex (line 60)
  message: Should this be "Layer 3: the Internet Protocol"? Follow your preferred style guide and register as an exception if necessary.
    58: As for another definition, a protocol is a set of specifications put forward by the Internet Engineering Task Force that govern how implementers of a protocol have their program or circuit behave under specific circumstances.
    59: 
>   60: \section{Layer 3: The Internet Protocol}
    61: 
    62: The following is a short introduction to internet protocol (IP), the primary way to send datagrams of information from one machine to another.

- file: sample\submodules\coursebook\networking\networking.tex (line 83)
  message: Should this be "What's the Deal With IPv6?"? Follow your preferred style guide and register as an exception if necessary.
    81: This book covers how IP deals with routing, fragmenting, and reassembling upper-level protocols. A more in-depth aside follows.
    82: 
>   83: \subsection{What's the deal with IPv6?}
    84: 
    85: \begin{figure}[H]

- file: sample\submodules\coursebook\networking\networking.tex (line 323)
  message: Should this be "Note on Network Orders"? Follow your preferred style guide and register as an exception if necessary.
   321: \end{enumerate}
   322: 
>  323: \subsection{Note on network orders}
   324: 
   325: Integers can be represented in the least significant byte first or most significant byte first.

- file: sample\submodules\coursebook\networking\networking.tex (line 441)
  message: Should this be "Sending Some Data"? Follow your preferred style guide and register as an exception if necessary.
   439: For more information see this \href{http://www.beej.us/guide/bgnet/output/html/multipage/getaddrinfoman.html}{guide}.
   440: 
>  441: \subsection{Sending some data}
   442: 
   443: Once we have a successful connection we can read or write like any old file descriptor.

- file: sample\submodules\coursebook\networking\networking.tex (line 766)
  message: Should this be "Sorry to Interrupt"? Follow your preferred style guide and register as an exception if necessary.
   764: \end{lstlisting}[language=C]
   765: 
>  766: \subsection{Sorry To Interrupt}
   767: 
   768: One concept that we need to make clear is that you need to handle interrupts in your networking code.

- file: sample\submodules\coursebook\networking\networking.tex (line 1019)
  message: Should this be "What's My Name?"? Follow your preferred style guide and register as an exception if necessary.
  1017: \end{enumerate}
  1018: 
> 1019: \subsection{What's my name?}
  1020: 
  1021: Remember when we were talking before about converting a website to an IP address?

- file: sample\submodules\coursebook\networking\networking.tex (line 1154)
  message: Should this be "Epoll"? Follow your preferred style guide and register as an exception if necessary.
  1152: There is an alternative, that isn't much better.
  1153: 
> 1154: \subsection{epoll}
  1155: 
  1156: \keyword{epoll} is not part of POSIX, but it is supported by Linux.

- file: sample\submodules\coursebook\malloc\malloc.tex (line 548)
  message: Should this be "Case Study: Buddy Allocator, an Example of a Segregated List"? Follow your preferred style guide and register as an exception if necessary.
   546: However, there is less fragmentation.
   547: 
>  548: \section{Case Study: Buddy Allocator, an example of a segregated list}
   549: 
   550: A segregated allocator is one that divides the heap into different areas that are handled by different sub-allocators dependent on the size of the allocation request.

- file: sample\submodules\coursebook\malloc\malloc.tex (line 564)
  message: Should this be "Case Study: SLUB Allocator, Slab Allocation"? Follow your preferred style guide and register as an exception if necessary.
   562: For example, a 68-byte allocation will require a 128-byte block.
   563: 
>  564: \section{Case Study: SLUB Allocator, Slab allocation}
   565: 
   566: The SLUB allocator is a slab allocator that serves different needs for the Linux kernel \href{http://en.wikipedia.org/wiki/SLUB_\%28software\%29}{SLUB}.

- file: sample\submodules\coursebook\malloc\malloc.tex (line 118)
  message: Should this be "Heaps and Sbrk"? Follow your preferred style guide and register as an exception if necessary.
   116: \end{itemize}
   117: 
>  118: \subsection{Heaps and sbrk}
   119: 
   120: The heap is part of the process memory and varies in size.

- file: sample\submodules\coursebook\malloc\malloc.tex (line 418)
  message: Should this be "Alignment and Rounding Up Considerations"? Follow your preferred style guide and register as an exception if necessary.
   416: This is before alignment concerns as well.
   417: 
>  418: \subsection{Alignment and rounding up considerations}
   419: 
   420: Many architectures expect multibyte primitives to be aligned to some multiple of 2 (4, 16, etc).

- file: sample\submodules\coursebook\malloc\malloc.tex (line 450)
  message: Should this be "Implementing Free"? Follow your preferred style guide and register as an exception if necessary.
   448: There is a \emph{lot} of overhead for that allocation which is what we are trying to avoid.
   449: 
>  450: \subsection{Implementing free}
   451: 
   452: When \keyword{free} is called we need to re-apply the offset to get back to the `real' start of the block -- to where we stored the size information.

- file: sample\submodules\coursebook\malloc\malloc.tex (line 538)
  message: Should this be "Explicit Linked List Insertion Policy"? Follow your preferred style guide and register as an exception if necessary.
   536: We recommend when trying to implement malloc that you draw out all the cases conceptually and then write the code.
   537: 
>  538: \subsubsection{Explicit linked list insertion policy}
   539: 
   540: The newly deallocated block can be inserted easily into two possible positions: at the beginning or in address order.

- file: sample\submodules\coursebook\honors\containers.tex (line 14)
  message: Should this be "What Is a Container?"? Follow your preferred style guide and register as an exception if necessary.
    12: \keyword{containerization} at the problem.
    13: 
>   14: \subsection{What is a container?}
    15: A container is almost like a virtual machine.
    16: In some senses, containers are to virtual machines as threads are to processes.

- file: sample\submodules\coursebook\honors\containers.tex (line 25)
  message: Should this be "Building a Container From Scratch"? Follow your preferred style guide and register as an exception if necessary.
    23: \subsection{Linux Namespaces}
    24: 
>   25: \subsection{Building a container from scratch}
    26: 
    27: \subsection{Containers in the wild: Software distribution is a Snap}

- file: sample\submodules\coursebook\honors\containers.tex (line 27)
  message: Should this be "Containers in the Wild: Software Distribution Is a Snap"? Follow your preferred style guide and register as an exception if necessary.
    25: \subsection{Building a container from scratch}
    26: 
>   27: \subsection{Containers in the wild: Software distribution is a Snap}

- file: sample\submodules\coursebook\scheduling\scheduling.tex (line 61)
  message: Should this be "What Is Preemption?"? Follow your preferred style guide and register as an exception if necessary.
    59: If a CPU is idle, the arrival time would also be the starting time of execution.
    60: 
>   61: \subsection{What is preemption?}
    62: 
    63: Without preemption, processes will run until they are unable to utilize the CPU any further.

- file: sample\submodules\coursebook\scheduling\scheduling.tex (line 79)
  message: Should this be "Why Might a Process (Or Thread) Be Placed on the Ready Queue?"? Follow your preferred style guide and register as an exception if necessary.
    77: It all depends on the \href{https://en.wikipedia.org/wiki/Scheduling_(computing)\#Types_of_operating_system_schedulers}{type of scheduler}.
    78: 
>   79: \subsection{Why might a process (or thread) be placed on the ready queue?}
    80: 
    81: A process is placed on the ready queue when it can use a CPU. Some examples include:

- file: sample\submodules\coursebook\introc\common_c_functions.tex (line 133)
  message: Should this be "Stdin Oriented Functions"? Follow your preferred style guide and register as an exception if necessary.
   131: \end{lstlisting}
   132: 
>  133: \subsection{stdin oriented functions}
   134: 
   135: Standard input or stdin oriented functions read from stdin directly.

- file: sample\submodules\coursebook\introc\common_c_functions.tex (line 65)
  message: Should this be "Stdout Oriented Streams"? Follow your preferred style guide and register as an exception if necessary.
    63: They are designated by the file descriptors 0 and 1 respectively. 2 is reserved for standard error which by library convention is unbuffered (i.e. IO operations are performed immediately).
    64: 
>   65: \subsubsection{stdout oriented streams}
    66: 
    67: Standard output or stdout oriented streams are streams whose only options are to write to stdout.

- file: sample\submodules\coursebook\introc\common_c_functions.tex (line 112)
  message: Should this be "Other Streams"? Follow your preferred style guide and register as an exception if necessary.
   110: \end{lstlisting}
   111: 
>  112: \subsubsection{Other streams}
   113: 
   114: To print to other file streams, use \keyword{fprintf(\ \_file\_\ ,\ "Hello\ \%s,\ score:\ \%d",\ name,\ score);} Where \_file\_ is either predefined (`stdout' or `stderr') or a FILE pointer that was returned by \keyword{fopen} or \keyword{fdopen}.

- file: sample\submodules\coursebook\processes\processes.tex (line 746)
  message: Should this be "Exec"? Follow your preferred style guide and register as an exception if necessary.
   744: \end{lstlisting}
   745: 
>  746: \section{exec}
   747: 
   748: To make the child process execute another program, use one of the \keyword{exec} functions after forking.

- file: sample\submodules\coursebook\processes\processes.tex (line 872)
  message: Should this be "The Fork-Exec-Wait Pattern"? Follow your preferred style guide and register as an exception if necessary.
   870: Passing something along the lines of argv[1] = "; sudo su" is a huge security risk called \href{https://en.wikipedia.org/wiki/Privilege\_escalation}{privilege escalation}.
   871: 
>  872: \section{The fork-exec-wait Pattern}
   873: 
   874: A common programming pattern is to call \keyword{fork} followed by \keyword{exec} and \keyword{wait}.

- file: sample\submodules\coursebook\processes\processes.tex (line 214)
  message: Should this be "A Word of Warning"? Follow your preferred style guide and register as an exception if necessary.
   212: \section{Intro to Fork}
   213: 
>  214: \subsection{A word of warning}
   215: 
   216: Process forking is a powerful and dangerous tool.

- file: sample\submodules\coursebook\processes\processes.tex (line 629)
  message: Should this be "Exit Statuses"? Follow your preferred style guide and register as an exception if necessary.
   627: Exit statuses or the value stored in the integer pointer for both of the calls above are explained below.
   628: 
>  629: \subsection{Exit statuses}
   630: 
   631: To find the return value of \keyword{main()} or value included in \keyword{exit()} from a child process, use the \keyword{Wait macros}. Typically, a program will use \keyword{WIFEXITED} and \keyword{WEXITSTATUS}.

- file: sample\submodules\coursebook\review\review.tex (line 147)
  message: Should this be "Input Parsing"? Follow your preferred style guide and register as an exception if necessary.
   145: \end{enumerate}
   146: 
>  147: \subsection{Input parsing}
   148: 
   149: \begin{enumerate}

- file: sample\submodules\coursebook\introc\pointers.tex (line 134)
  message: Should this be "So What Is a Void Pointer?"? Follow your preferred style guide and register as an exception if necessary.
   132: \textbf{Every time you do pointer arithmetic, take a deep breath and make sure that you are shifting over the number of bytes you think you are shifting over.}
   133: 
>  134: \subsection{So what is a void pointer?}
   135: 
   136: A void pointer is a pointer without a type.

- file: sample\submodules\coursebook\introc\pointers.tex (line 41)
  message: Should this be "Reading / Writing With Pointers"? Follow your preferred style guide and register as an exception if necessary.
    39: \end{lstlisting}
    40: 
>   41: \subsubsection{Reading / Writing with pointers}
    42: 
    43: Let's say that \keyword{int\ *ptr} was declared.

- file: sample\submodules\coursebook\introc\c_memory_model.tex (line 122)
  message: Should this be "Places for Strings"? Follow your preferred style guide and register as an exception if necessary.
   120: A string in C is defined as a bunch of bytes ended by `\0' or the NUL Byte.
   121: 
>  122: \subsection{Places for strings}
   123: 
   124: Whenever you define a string literal - one in the form \keyword{char*\ str\ =\ "constant"} -- that string is stored in the \emph{data} section. Depending on your architecture, it is \textbf{read-only}, meaning that any attempt to modify the string will cause a SEGFAULT.

- file: sample\submodules\coursebook\introc\c_memory_model.tex (line 136)
  message: Should this be "String Literals Are Constant"? Follow your preferred style guide and register as an exception if necessary.
   134: C characters are always exactly one byte each.
   135: 
>  136: \subsubsection{String literals are constant}
   137: 
   138: A string literal is naturally constant.

- file: sample\submodules\coursebook\introc\crash_course_introduction_to_c.tex (line 1)
  message: Should this be "Crash Course Introduction to C"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Crash course introduction to C}
     2: 
     3: The canonical way to start learning C is by starting with the hello world program.

- file: sample\submodules\coursebook\honors\tcp.tex (line 1)
  message: Should this be "TCP in Depth"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{TCP In Depth}
     2: 
     3: TCP or the transmission control protocol handles the retransmission, acknowledgement, and flow of packets. Naturally a pre-requisite to this section is

- file: sample\submodules\coursebook\background\background.tex (line 102)
  message: Should this be "Ssh"? Follow your preferred style guide and register as an exception if necessary.
   100: Let's go through some of the common tools that you'll be working on and need to be familiar with.
   101: 
>  102: \subsection{ssh}
   103: 
   104: \keyword{ssh} is short for the Secure Shell \cite{openbsd_ssh}.

- file: sample\submodules\coursebook\background\background.tex (line 136)
  message: Should this be "Git"? Follow your preferred style guide and register as an exception if necessary.
   134: \end{lstlisting}
   135: 
>  136: \subsection{git}
   137: 
   138: What is `git`? Git is a version control system. What that means is git stores the entire history of a directory. We refer to the directory as a repository. So what do you need to know is a few things. First, create your repository with the repo creator. If you haven't already signed into enterprise GitHub, make sure to do so otherwise your repository won't be created for you. After that, your repository is created on the server. Git is a decentralized version control system, meaning that you'll need to get a repository onto your VM. We can do this with a clone. Whatever you do, \textbf{do not go through the README.md tutorial}.

- file: sample\submodules\coursebook\background\background.tex (line 535)
  message: Should this be "Involved Gdb Example"? Follow your preferred style guide and register as an exception if necessary.
   533: Here, by using the \keyword{x} command with parameters \keyword{16xb}, we can see that starting at memory address \keyword{0x7fff5fbff9c} (value of \keyword{bad\_string}), \keyword{printf} would actually see the following sequence of bytes as a string because we provided a malformed string without a null terminator.
   534: 
>  535: \subsection{Involved gdb example}
   536: 
   537: Here is how one of your TAs would go through and debug a simple program that is going wrong.

- file: sample\submodules\coursebook\background\background.tex (line 659)
  message: Should this be "Strace and Ltrace"? Follow your preferred style guide and register as an exception if necessary.
   657: And in addition to the make output, you will get static build warnings.
   658: 
>  659: \subsection{strace and ltrace}
   660: 
   661: strace and ltrace are two programs that trace the system calls and library calls, respectively, of a running program or command.

- file: sample\submodules\coursebook\background\background.tex (line 732)
  message: Should this be "Printfs"? Follow your preferred style guide and register as an exception if necessary.
   730: Meaning that you'll have to install it from the source.
   731: 
>  732: \subsection{printfs}
   733: 
   734: When all else fails, print! Each of your functions should have an idea of what it is going to do.

- file: sample\submodules\coursebook\background\background.tex (line 815)
  message: Should this be "So You Want to Master System Programming? and Get a Better Grade Than B?"? Follow your preferred style guide and register as an exception if necessary.
   813: \end{lstlisting}
   814: 
>  815: \subsection{So you want to master System Programming? And get a better grade than B?}
   816: 
   817: \begin{minted}{C}

- file: sample\submodules\coursebook\background\background.tex (line 839)
  message: Should this be "Watch the Videos and Write Up Your Answers to the Following Questions"? Follow your preferred style guide and register as an exception if necessary.
   837: \end{minted}
   838: 
>  839: \subsection{Watch the videos and write up your answers to the following questions}
   840: 
   841: \textbf{Important!}

- file: sample\submodules\coursebook\background\background.tex (line 986)
  message: Should this be "Optional: Just for Fun"? Follow your preferred style guide and register as an exception if necessary.
   984: \end{enumerate}
   985: 
>  986: \subsection{Optional: Just for fun}
   987: 
   988: \begin{itemize}

- file: sample\submodules\coursebook\background\background.tex (line 997)
  message: Should this be "The Class Forum"? Follow your preferred style guide and register as an exception if necessary.
   995: \section{University of Illinois Specific Guidelines}
   996: 
>  997: \subsection{The class forum}
   998: 
   999: TAs and student assistants get a ton of questions.

- file: sample\submodules\coursebook\background\background.tex (line 641)
  message: Should this be "Undefined Behavior - Why We Can't Solve It in General"? Follow your preferred style guide and register as an exception if necessary.
   639: \url{https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html}
   640: 
>  641: \subsubsection{Undefined behavior - why we can't solve it in general}
   642: 
   643: Also please please read Chris Lattner's 3 Part blog post on undefined behavior. It can shed light on debug builds and the mystery of compiler optimization.

- file: sample\submodules\coursebook\background\background.tex (line 443)
  message: Should this be "Setting Breakpoints Programmatically"? Follow your preferred style guide and register as an exception if necessary.
   441: GDB is short for the GNU Debugger. GDB is a program that helps you track down errors by interactively debugging them \cite{gdb}. It can start and stop your program, look around, and put in ad hoc constraints and checks. Here are a few examples.
   442: 
>  443: \paragraph{Setting breakpoints programmatically}
   444: 
   445: A breakpoint is a line of code where you want the execution to stop and give control back to the debugger.

- file: sample\submodules\coursebook\background\background.tex (line 491)
  message: Should this be "Checking Memory Content"? Follow your preferred style guide and register as an exception if necessary.
   489: \end{lstlisting}
   490: 
>  491: \paragraph{Checking memory content}
   492: 
   493: 

- file: sample\submodules\coursebook\introc\the_c_and_linux.tex (line 9)
  message: Should this be "Everything Is a File"? Follow your preferred style guide and register as an exception if necessary.
     7: There are several things to that philosophy that makes the rest of this easier to know, so we'll put those things here.
     8: 
>    9: \subsection{Everything is a file}
    10: 
    11: One POSIX mantra is that everything is a file.

- file: sample\submodules\coursebook\introc\logic_and_program_flow_mistakes.tex (line 1)
  message: Should this be "Logic and Program Flow Mistakes"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Logic and Program flow mistakes}
     2: 
     3: These are a set of mistakes that may let the program compile but perform unintended functionality.

- file: sample\submodules\coursebook\introc\logic_and_program_flow_mistakes.tex (line 43)
  message: Should this be "Undeclared or Incorrectly Prototyped Functions"? Follow your preferred style guide and register as an exception if necessary.
    41: It is always good practice to put parentheses around any assignment condition.
    42: 
>   43: \subsection{Undeclared or incorrectly prototyped functions}
    44: 
    45: Some snippets of code may do the following.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 67)
  message: Should this be "What Is a Filesystem?"? Follow your preferred style guide and register as an exception if necessary.
    65: Though when you are pushing production code, make sure to ask about the difference!
    66: 
>   67: \section{What is a filesystem?}
    68: 
    69: You may have encountered the old UNIX adage, "everything is a file".

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 132)
  message: Should this be "Storing Data on Disk"? Follow your preferred style guide and register as an exception if necessary.
   130: If you would like to learn more about this interface, try looking at the documentation for Filesystems at the User Space Level (FUSE).
   131: 
>  132: \section{Storing data on disk}
   133: 
   134: To understand how a filesystem interacts with data on disk, there are three key terms we will be using.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 590)
  message: Should this be "Permissions and Bits"? Follow your preferred style guide and register as an exception if necessary.
   588: \end{lstlisting}
   589: 
>  590: \section{Permissions and bits}
   591: 
   592: Permissions are a key part of the way UNIX systems provide security in a filesystem.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 790)
  message: Should this be "Virtual Filesystems and Other Filesystems"? Follow your preferred style guide and register as an exception if necessary.
   788: Note that in the example above, the username is prepended to the prompt, and the command \keyword{su} is used to switch users.
   789: 
>  790: \section{Virtual filesystems and other filesystems}
   791: 
   792: POSIX systems, such as Linux and Mac OS X (which is based on BSD) include several virtual filesystems that are mounted (available) as part of the file-system.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 654)
  message: Should this be "Reading / Changing File Permissions"? Follow your preferred style guide and register as an exception if necessary.
   652: If none of the IDs match, then the other field will apply.
   653: 
>  654: \subsection{Reading / Changing file permissions}
   655: 
   656: Before we discuss how to change permission bits, we should be able to read them.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 698)
  message: Should this be "Understanding the `Umask'"? Follow your preferred style guide and register as an exception if necessary.
   696: \end{enumerate}
   697: 
>  698: \subsection{Understanding the `umask'}
   699: 
   700: The umask \emph{subtracts} (reduces) permission bits from \keyword{777} and is used when new files and new directories are created by open, mkdir etc.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 724)
  message: Should this be "The `Setuid' Bit"? Follow your preferred style guide and register as an exception if necessary.
   722: \end{lstlisting}
   723: 
>  724: \subsection{The `setuid' bit}
   725: 
   726: You may have noticed an additional bit that files with execute permission may have set.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 758)
  message: Should this be "The `Sticky' Bit"? Follow your preferred style guide and register as an exception if necessary.
   756: These functions can allow one to write a program that can only be run by a privileged user by checking \keyword{geteuid} or go a step further and ensure that the only user who can run the code is root by using \keyword{getuid}.
   757: 
>  758: \subsection{The `sticky' bit}
   759: 
   760: Sticky bits as we use them today serve a different purpose from initial introduction.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 819)
  message: Should this be "Managing Files and Filesystems"? Follow your preferred style guide and register as an exception if necessary.
   817: \end{lstlisting}
   818: 
>  819: \subsection{Managing files and filesystems}
   820: 
   821: Given the multitude of operations that are available to you from the filesystem, let's explore some tools and techniques that can be used to manage files and filesystems.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 1250)
  message: Should this be "Writing to Files"? Follow your preferred style guide and register as an exception if necessary.
  1248: 
  1249: \subsection{Performing Writes}
> 1250: \subsubsection{Writing to files}
  1251: Performing writes fall into two categories, writes to files and writes to directories.
  1252: First we'll focus on files and assume that we are writing a byte to the $6$th KiB of our file.

- file: sample\submodules\coursebook\filesystems\filesystems.tex (line 1266)
  message: Should this be "Writing to Directories"? Follow your preferred style guide and register as an exception if necessary.
  1264: \end{itemize}
  1265: 
> 1266: \subsubsection{Writing to directories}
  1267: Performing a write to a directory implies that an inode needs to be added to a directory.
  1268: If we pretend that the example above is a directory.

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 320)
  message: Should this be "Advanced: Implementing a Mutex With Hardware"? Follow your preferred style guide and register as an exception if necessary.
   318: For now, we will talk about semaphores.
   319: 
>  320: \subsection{Advanced: Implementing a Mutex with hardware}
   321: 
   322: We can use C11 Atomics to do that perfectly!

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 1091)
  message: Should this be "Turn-Based Solutions"? Follow your preferred style guide and register as an exception if necessary.
  1089: This suggests we should use a turn-based variable to try to resolve who should proceed.
  1090: 
> 1091: \subsection{Turn-based solutions}
  1092: 
  1093: The following candidate solution \#3 uses a turn-based variable to politely allow one thread and then the other to continue

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 1109)
  message: Should this be "Turn and Flag Solutions"? Follow your preferred style guide and register as an exception if necessary.
  1107: This `solution' is ineffective because our threads should be able to make progress and enter the critical section if no other thread is currently in the critical section.
  1108: 
> 1109: \subsection{Turn and Flag solutions}
  1110: 
  1111: Is the following a correct solution to CSP?

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 1302)
  message: Should this be "Other Semaphore Considerations"? Follow your preferred style guide and register as an exception if necessary.
  1300: \end{lstlisting}
  1301: 
> 1302: \subsection{Other semaphore considerations}
  1303: 
  1304: \begin{itemize}

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 1693)
  message: Should this be "Starving Writers"? Follow your preferred style guide and register as an exception if necessary.
  1691: The reader and writer should use \keyword{cond\_broadcast} so that all threads should wake up and check their while-loop condition.
  1692: 
> 1693: \subsection{Starving writers}
  1694: 
  1695: Candidate \#3 above suffers from starvation.

- file: sample\submodules\coursebook\synchronization\synchronization.tex (line 1963)
  message: Should this be "Correct Implementation of a Ring Buffer"? Follow your preferred style guide and register as an exception if necessary.
  1961: \end{itemize}
  1962: 
> 1963: \subsection{Correct implementation of a ring buffer}
  1964: 
  1965: As the mutex lock is stored in global (static) memory it can be initialized with \keyword{PTHREAD\_MUTEX\_INITIALIZER}.

- file: sample\submodules\coursebook\threads\threads.tex (line 15)
  message: Should this be "Processes vs Threads"? Follow your preferred style guide and register as an exception if necessary.
    13: But in some cases, notably python uses this, multiprocessing is the way to make your code faster.
    14: 
>   15: \section{Processes vs threads}
    16: 
    17: Creating separate processes is useful when:

- file: sample\submodules\coursebook\threads\threads.tex (line 273)
  message: Should this be "A Day at the Races"? Follow your preferred style guide and register as an exception if necessary.
   271: We need to come up with a software solution to this problem.
   272: 
>  273: \subsubsection{A day at the races}
   274: 
   275: Here is another small race condition.

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 25)
  message: Should this be "Normal Distribution"? Follow your preferred style guide and register as an exception if necessary.
    23: 
    24: %_________________
>   25: \section{Normal distribution}
    26: \label{normalDist}
    27: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 756)
  message: Should this be "Evaluating the Normal Approximation"? Follow your preferred style guide and register as an exception if necessary.
   754: 
   755: %%_________________
>  756: %\section{Evaluating the normal approximation}
   757: %\label{assessingNormal}
   758: %

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 971)
  message: Should this be "Geometric Distribution"? Follow your preferred style guide and register as an exception if necessary.
   969: 
   970: %_________________
>  971: \section{Geometric distribution}
   972: \label{geomDist}
   973: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1268)
  message: Should this be "Binomial Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1266: 
  1267: 
> 1268: \section{Binomial distribution}
  1269: \label{binomialModel}
  1270: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1927)
  message: Should this be "Negative Binomial Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1925: 
  1926: %_________________
> 1927: \section{Negative binomial distribution}
  1928: \label{negativeBinomial}
  1929: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 2111)
  message: Should this be "Poisson Distribution"? Follow your preferred style guide and register as an exception if necessary.
  2109: 
  2110: %_________________
> 2111: \section{Poisson distribution}
  2112: \label{poisson}
  2113: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 62)
  message: Should this be "Normal Distribution Model"? Follow your preferred style guide and register as an exception if necessary.
    60: 
    61: 
>   62: \subsection{Normal distribution model}
    63: 
    64: The \term{normal distribution} always describes a symmetric,

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 137)
  message: Should this be "Standardizing With Z-Scores"? Follow your preferred style guide and register as an exception if necessary.
   135: 
   136: 
>  137: \subsection{Standardizing with Z-scores}
   138: 
   139: \noindent%

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 311)
  message: Should this be "Finding Tail Areas"? Follow your preferred style guide and register as an exception if necessary.
   309: 
   310: 
>  311: \subsection{Finding tail areas}
   312: 
   313: It's very useful in statistics to be able to identify tail areas

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 395)
  message: Should this be "Normal Probability Examples"? Follow your preferred style guide and register as an exception if necessary.
   393: \D{\newpage}
   394: 
>  395: \subsection{Normal probability examples}
   396: \label{normal_probability_examples}
   397: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 693)
  message: Should this be "68-95-99.7 Rule"? Follow your preferred style guide and register as an exception if necessary.
   691: \D{\newpage}
   692: 
>  693: \subsection{68-95-99.7 rule}
   694: 
   695: Here, we present a useful rule of thumb for the probability of falling within 1, 2, and 3 standard deviations of the mean in the normal distribution. This will be useful in a wide range of practical settings, especially when trying to make a quick estimate without a calculator or Z-table.

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 976)
  message: Should this be "Bernoulli Distribution"? Follow your preferred style guide and register as an exception if necessary.
   974: How long should we expect to flip a coin until it turns up \resp{heads}? Or how many times should we expect to roll a die until we get a \resp{1}? These questions can be answered using the geometric distribution. We first formalize each trial -- such as a single coin flip or die toss -- using the Bernoulli distribution, and then we combine these with our tools from probability (Chapter~\ref{probability}) to construct the geometric distribution.
   975: 
>  976: \subsection{Bernoulli distribution}
   977: \label{bernoulli}
   978: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1072)
  message: Should this be "Geometric Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1070: \D{\newpage}
  1071: 
> 1072: \subsection{Geometric distribution}
  1073: 
  1074: \index{distribution!geometric|(}

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1285)
  message: Should this be "The Binomial Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1283: 
  1284: 
> 1285: \subsection{The binomial distribution}
  1286: 
  1287: %\newcommand{\insureSprob}{0.7}

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1696)
  message: Should this be "Normal Approximation to the Binomial Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1694: 
  1695: 
> 1696: \subsection{Normal approximation to the binomial distribution}
  1697: \label{normalApproxBinomialDistSubsection}
  1698: 

- file: sample\submodules\openintro-statistics\ch_distributions\TeX\ch_distributions.tex (line 1856)
  message: Should this be "The Normal Approximation Breaks Down on Small Intervals"? Follow your preferred style guide and register as an exception if necessary.
  1854: 
  1855: 
> 1856: \subsection{The normal approximation breaks down on small intervals}
  1857: 
  1858: The normal approximation to the binomial distribution tends to perform poorly when estimating the probability of a small range of counts, even when the conditions are met.

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 41)
  message: Should this be "Case Study: Using Stents to Prevent Strokes"? Follow your preferred style guide and register as an exception if necessary.
    39: 
    40: 
>   41: \section{Case study: using stents to prevent strokes}
    42: \label{basicExampleOfStentsAndStrokes}
    43: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 145)
  message: Should this be "Data Basics"? Follow your preferred style guide and register as an exception if necessary.
   143: 
   144: 
>  145: \section{Data basics}
   146: \label{dataBasics}
   147: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 799)
  message: Should this be "Sampling Principles and Strategies"? Follow your preferred style guide and register as an exception if necessary.
   797: 
   798: %%%%%
>  799: \section{Sampling principles and strategies}
   800: \label{overviewOfDataCollectionPrinciples}
   801: \label{section_obs_data_sampling}

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 154)
  message: Should this be "Observations, Variables, and Data Matrices"? Follow your preferred style guide and register as an exception if necessary.
   152: that will be used throughout this book.
   153: 
>  154: \subsection{Observations, variables, and data matrices}
   155: 
   156: \index{data!loan50|(}

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 393)
  message: Should this be "Types of Variables"? Follow your preferred style guide and register as an exception if necessary.
   391: \end{landscape}
   392: 
>  393: \subsection{Types of variables}
   394: \label{variableTypes}
   395: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 494)
  message: Should this be "Relationships Between Variables"? Follow your preferred style guide and register as an exception if necessary.
   492: \D{\newpage}
   493: 
>  494: \subsection{Relationships between variables}
   495: \label{variableRelations}
   496: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 671)
  message: Should this be "Explanatory and Response Variables"? Follow your preferred style guide and register as an exception if necessary.
   669: \D{\newpage}
   670: 
>  671: \subsection{Explanatory and response variables}
   672: \label{explanatoryAndResponse}
   673: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 746)
  message: Should this be "Introducing Observational Studies and Experiments"? Follow your preferred style guide and register as an exception if necessary.
   744: 
   745: 
>  746: \subsection{Introducing observational studies and experiments}
   747: 
   748: \noindent%

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 815)
  message: Should this be "Populations and Samples"? Follow your preferred style guide and register as an exception if necessary.
   813: 
   814: 
>  815: \subsection{Populations and samples}
   816: \label{populationsAndSamples}
   817: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 858)
  message: Should this be "Anecdotal Evidence"? Follow your preferred style guide and register as an exception if necessary.
   856: 
   857: 
>  858: \subsection{Anecdotal evidence}
   859: \label{anecdotalEvidenceSubsection}
   860: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 914)
  message: Should this be "Sampling From a Population"? Follow your preferred style guide and register as an exception if necessary.
   912: Anecdotal evidence typically is composed of unusual cases that we recall based on their striking characteristics. For instance, we are more likely to remember the two people we met who took 7~years to graduate than the six others who graduated in four years. Instead of looking at the most unusual cases, we should examine a sample of many cases that represent the population.
   913: 
>  914: \subsection{Sampling from a population}
   915: 
   916: \index{sample!random sample|(}

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 1048)
  message: Should this be "Observational Studies"? Follow your preferred style guide and register as an exception if necessary.
  1046: \D{\newpage}
  1047: 
> 1048: \subsection{Observational studies}
  1049: 
  1050: Data where no treatment has been explicitly applied

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 1129)
  message: Should this be "Four Sampling Methods"? Follow your preferred style guide and register as an exception if necessary.
  1127: 
  1128: 
> 1129: \subsection{Four sampling methods}
  1130: \label{fourSamplingMethods}
  1131: \label{threeSamplingMethods}

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 1259)
  message: Should this be "Principles of Experimental Design"? Follow your preferred style guide and register as an exception if necessary.
  1257: 
  1258: 
> 1259: \subsection{Principles of experimental design}
  1260: \label{experimentalDesignPrinciples}
  1261: 

- file: sample\submodules\openintro-statistics\ch_intro_to_data\TeX\ch_intro_to_data.tex (line 1306)
  message: Should this be "Reducing Bias in Human Experiments"? Follow your preferred style guide and register as an exception if necessary.
  1304: using blocking.
  1305: 
> 1306: \subsection{Reducing bias in human experiments}
  1307: \label{biasInHumanExperiments}
  1308: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 29)
  message: Should this be "Inference for a Single Proportion"? Follow your preferred style guide and register as an exception if necessary.
    27: 
    28: %__________________
>   29: \section{Inference for a single proportion}
    30: \label{singleProportion}
    31: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 555)
  message: Should this be "Difference of Two Proportions"? Follow your preferred style guide and register as an exception if necessary.
   553: 
   554: %__________________
>  555: \section{Difference of two proportions}
   556: \label{differenceOfTwoProportions}
   557: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1316)
  message: Should this be "Determining a Sample Size for an Experiment"? Follow your preferred style guide and register as an exception if necessary.
  1314: 
  1315: %%__________________
> 1316: %\section{Determining a sample size for an experiment}
  1317: %\label{SampleSizeFor2Proportions}
  1318: %

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1344)
  message: Should this be "Testing for Goodness of Fit Using Chi-Square"? Follow your preferred style guide and register as an exception if necessary.
  1342: 
  1343: %__________________
> 1344: \section{Testing for goodness of fit using chi-square}
  1345: \label{oneWayChiSquare}
  1346: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 2008)
  message: Should this be "Testing for Independence in Two-Way Tables"? Follow your preferred style guide and register as an exception if necessary.
  2006: 
  2007: %__________________
> 2008: \section{Testing for independence in two-way tables}
  2009: \label{twoWayTablesAndChiSquare}
  2010: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 41)
  message: Should this be "Identifying When the Sample Proportion Is Nearly Normal"? Follow your preferred style guide and register as an exception if necessary.
    39: 
    40: 
>   41: \subsection{Identifying when the sample proportion is nearly normal}
    42: 
    43: A sample proportion $\hat{p}$ can be modeled using

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 87)
  message: Should this be "Confidence Intervals for a Proportion"? Follow your preferred style guide and register as an exception if necessary.
    85: 
    86: 
>   87: \subsection{Confidence intervals for a proportion}
    88: \label{confIntForPropSection}
    89: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 206)
  message: Should this be "Hypothesis Testing for a Proportion"? Follow your preferred style guide and register as an exception if necessary.
   204: 
   205: 
>  206: \subsection{Hypothesis testing for a proportion}
   207: \label{htForPropSection}
   208: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 325)
  message: Should this be "When One or More Conditions Aren't Met"? Follow your preferred style guide and register as an exception if necessary.
   323: \D{\newpage}
   324: 
>  325: \subsection{When one or more conditions aren't met}
   326: 
   327: We've spent a lot of time discussing conditions for when

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 374)
  message: Should this be "Choosing a Sample Size When Estimating a Proportion"? Follow your preferred style guide and register as an exception if necessary.
   372: \D{\newpage}
   373: 
>  374: \subsection{Choosing a sample size when estimating a proportion}
   375: 
   376: \index{margin of error|(}

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 583)
  message: Should this be "Sampling Distribution of the Difference
    of Two Proportions"? Follow your preferred style guide and register as an exception if necessary.
   581: 
   582: 
>  583: \subsection{Sampling distribution of the difference
   584:     of two proportions}
   585: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1131)
  message: Should this be "More on 2-Proportion Hypothesis Tests (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  1129: \D{\newpage}
  1130: 
> 1131: \subsection{More on 2-proportion hypothesis tests (special topic)}
  1132: 
  1133: When we conduct a 2-proportion hypothesis test,

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1259)
  message: Should this be "Examining the Standard Error Formula
    (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  1257: \D{\newpage}
  1258: 
> 1259: \subsection{Examining the standard error formula
  1260:     (special topic)}
  1261: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1381)
  message: Should this be "Creating a Test Statistic for One-Way Tables"? Follow your preferred style guide and register as an exception if necessary.
  1379: 
  1380: 
> 1381: \subsection{Creating a test statistic for one-way tables}
  1382: 
  1383: \begin{examplewrap}

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1420)
  message: Should this be "The Chi-Square Test Statistic"? Follow your preferred style guide and register as an exception if necessary.
  1418: 
  1419: 
> 1420: \subsection{The chi-square test statistic}
  1421: \label{chiSquareTestStatistic}
  1422: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1474)
  message: Should this be "The Chi-Square Distribution and Finding Areas"? Follow your preferred style guide and register as an exception if necessary.
  1472: 
  1473: 
> 1474: \subsection{The chi-square distribution and finding areas}
  1475: 
  1476: The \term{chi-square distribution} is sometimes used to

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1636)
  message: Should this be "Finding a P-Value for a Chi-Square Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1634: \D{\newpage}
  1635: 
> 1636: \subsection{Finding a p-value for a chi-square distribution}
  1637: \label{pValueForAChiSquareTest}
  1638: 

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 1767)
  message: Should this be "Evaluating Goodness of Fit for a Distribution"? Follow your preferred style guide and register as an exception if necessary.
  1765: \D{\newpage}
  1766: 
> 1767: \subsection{Evaluating goodness of fit for a distribution}
  1768: 
  1769: Section~\ref{geomDist} would be useful background reading

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 2119)
  message: Should this be "Expected Counts in Two-Way Tables"? Follow your preferred style guide and register as an exception if necessary.
  2117: \D{\newpage}
  2118: 
> 2119: \subsection{Expected counts in two-way tables}
  2120: 
  2121: \noindent%

- file: sample\submodules\openintro-statistics\ch_inference_for_props\TeX\ch_inference_for_props.tex (line 2239)
  message: Should this be "The Chi-Square Test for Two-Way Tables"? Follow your preferred style guide and register as an exception if necessary.
  2237: 
  2238: 
> 2239: \subsection{The chi-square test for two-way tables}
  2240: 
  2241: The chi-square test statistic for a two-way table is found

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 36)
  message: Should this be "Point Estimates and Sampling Variability"? Follow your preferred style guide and register as an exception if necessary.
    34: 
    35: %__________________
>   36: \section{Point estimates and sampling variability}
    37: \label{pointEstimates}
    38: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 911)
  message: Should this be "Confidence Intervals for a Proportion"? Follow your preferred style guide and register as an exception if necessary.
   909: 
   910: %__________________
>  911: \section{Confidence intervals for a proportion}
   912: \label{confidenceIntervals}
   913: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1509)
  message: Should this be "Hypothesis Testing for a Proportion"? Follow your preferred style guide and register as an exception if necessary.
  1507: 
  1508: %__________________
> 1509: \section{Hypothesis testing for a proportion}
  1510: \label{hypothesisTesting}
  1511: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 102)
  message: Should this be "Point Estimates and Error"? Follow your preferred style guide and register as an exception if necessary.
   100: 
   101: 
>  102: \subsection{Point estimates and error}
   103: 
   104: \index{point estimate|(}

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 258)
  message: Should this be "Understanding the Variability of a Point Estimate"? Follow your preferred style guide and register as an exception if necessary.
   256: 
   257: 
>  258: \subsection{Understanding the variability of a point estimate}
   259: \label{simulationForUnderstandingVariabilitySection}
   260: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 650)
  message: Should this be "Applying the Central Limit Theorem To
    a Real-World Setting"? Follow your preferred style guide and register as an exception if necessary.
   648: 
   649: 
>  650: \subsection{Applying the Central Limit Theorem to
   651:     a real-world setting}
   652: \label{apply_clt_real_world_setting}

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 714)
  message: Should this be "More Details Regarding the Central Limit Theorem"? Follow your preferred style guide and register as an exception if necessary.
   712: \D{\newpage}
   713: 
>  714: \subsection{More details regarding the Central Limit Theorem}
   715: 
   716: \noindent%

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 875)
  message: Should this be "Extending the Framework for Other Statistics"? Follow your preferred style guide and register as an exception if necessary.
   873: 
   874: 
>  875: \subsection{Extending the framework for other statistics}
   876: 
   877: The strategy of using a sample statistic to estimate

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 926)
  message: Should this be "Capturing the Population Parameter"? Follow your preferred style guide and register as an exception if necessary.
   924: 
   925: 
>  926: \subsection{Capturing the population parameter}
   927: 
   928: Using only a point estimate is like fishing in a murky

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1073)
  message: Should this be "Changing the Confidence Level"? Follow your preferred style guide and register as an exception if necessary.
  1071: \D{\newpage}
  1072: 
> 1073: \subsection{Changing the confidence level}
  1074: \label{changingTheConfidenceLevelSection}
  1075: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1236)
  message: Should this be "More Case Studies"? Follow your preferred style guide and register as an exception if necessary.
  1234: \D{\newpage}
  1235: 
> 1236: \subsection{More case studies}
  1237: 
  1238: \index{data!Ebola poll|(}

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1424)
  message: Should this be "Interpreting Confidence Intervals"? Follow your preferred style guide and register as an exception if necessary.
  1422: 
  1423: 
> 1424: \subsection{Interpreting confidence intervals}
  1425: \label{interpretingCIs}
  1426: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1574)
  message: Should this be "Hypothesis Testing Framework"? Follow your preferred style guide and register as an exception if necessary.
  1572: 
  1573: 
> 1574: \subsection{Hypothesis testing framework}
  1575: 
  1576: Were interested in understanding how much people know

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1720)
  message: Should this be "Testing Hypotheses Using Confidence Intervals"? Follow your preferred style guide and register as an exception if necessary.
  1718: \D{\newpage}
  1719: 
> 1720: \subsection{Testing hypotheses using confidence intervals}
  1721: \label{utilizingOurCI}
  1722: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 1967)
  message: Should this be "Decision Errors"? Follow your preferred style guide and register as an exception if necessary.
  1965: \D{\newpage}
  1966: 
> 1967: \subsection{Decision errors}
  1968: 
  1969: \index{hypothesis testing!decision errors|(}

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 2117)
  message: Should this be "Formal Testing Using P-Values"? Follow your preferred style guide and register as an exception if necessary.
  2115: 
  2116: 
> 2117: \subsection{Formal testing using p-values}
  2118: 
  2119: \label{pValue}

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 2595)
  message: Should this be "Choosing a Significance Level"? Follow your preferred style guide and register as an exception if necessary.
  2593: 
  2594: 
> 2595: \subsection{Choosing a significance level}
  2596: \label{significanceLevel}
  2597: 

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 2720)
  message: Should this be "Statistical Significance Versus Practical Significance"? Follow your preferred style guide and register as an exception if necessary.
  2718: 
  2719: 
> 2720: \subsection{Statistical significance versus practical significance}
  2721: 
  2722: When the sample size becomes larger,

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\ch_foundations_for_inf.tex (line 2765)
  message: Should this be "One-Sided Hypothesis Tests (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  2763: \D{\newpage}
  2764: 
> 2765: \subsection{One-sided hypothesis tests (special topic)}
  2766: 
  2767: So far we've only considered what are called \term{two-sided

- file: sample\submodules\openintro-statistics\ch_foundations_for_inf\TeX\one_sided_tests.tex (line 1)
  message: Should this be "One-Sided Hypothesis Tests (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
>    1: \subsection{One-sided hypothesis tests (special topic)}
     2: 
     3: \Comment{This section needs a lot of work. Maybe it shouldn't

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1059)
  message: Should this be "Paired Data"? Follow your preferred style guide and register as an exception if necessary.
  1057: 
  1058: %__________________
> 1059: \section{Paired data}
  1060: \label{pairedData}
  1061: 

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1335)
  message: Should this be "Difference of Two Means"? Follow your preferred style guide and register as an exception if necessary.
  1333: 
  1334: %__________________
> 1335: \section{Difference of two means}
  1336: \label{differenceOfTwoMeans}
  1337: 

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2062)
  message: Should this be "Power Calculations for a Difference of Means"? Follow your preferred style guide and register as an exception if necessary.
  2060: 
  2061: %__________________
> 2062: \section{Power calculations for a difference of means}
  2063: \label{PowerForDifferenceOfTwoMeans}
  2064: 

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2582)
  message: Should this be "Comparing Many Means With ANOVA"? Follow your preferred style guide and register as an exception if necessary.
  2580: 
  2581: %__________________
> 2582: \section{Comparing many means with ANOVA}
  2583: \label{anovaAndRegrWithCategoricalVariables}
  2584: 

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1111)
  message: Should this be "Paired Observations"? Follow your preferred style guide and register as an exception if necessary.
  1109: % library(openintro); library(xtable); library(dplyr); d <- select(ucla_textbooks_f18, subject, course_num, bookstore_new, amazon_new); d$price_diff <- d$bookstore_new - d$amazon_new; d <- subset(d, !is.na(bookstore_new) & !is.na(amazon_new)); rownames(d) <- NULL; xtable(d[c(1:3, nrow(d) - 1:0),])
  1110: 
> 1111: \subsection{Paired observations}
  1112: 
  1113: Each textbook has two corresponding prices in the data set:

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1158)
  message: Should this be "Inference for Paired Data"? Follow your preferred style guide and register as an exception if necessary.
  1156: 
  1157: 
> 1158: \subsection{Inference for paired data}
  1159: 
  1160: To analyze a paired data set,

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1362)
  message: Should this be "Confidence Interval for a Difference of Means"? Follow your preferred style guide and register as an exception if necessary.
  1360: 
  1361: 
> 1362: \subsection{Confidence interval for a difference of means}
  1363: 
  1364: \index{data!stem cells, heart function|(}

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1612)
  message: Should this be "Hypothesis Tests for the Difference of Two Means"? Follow your preferred style guide and register as an exception if necessary.
  1610: %\D{\newpage}
  1611: 
> 1612: \subsection{Hypothesis tests for the difference of two means}
  1613: 
  1614: \index{data!baby\_smoke|(}

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1836)
  message: Should this be "Case Study: Two Versions of a Course Exam"? Follow your preferred style guide and register as an exception if necessary.
  1834: \D{\newpage}
  1835: 
> 1836: \subsection{Case study: two versions of a course exam}
  1837: 
  1838: \index{data!two exam comparison|(}

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 1972)
  message: Should this be "Examining the Standard Error Formula (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  1970: 
  1971: 
> 1972: %\subsection{Examining the standard error formula (special topic)}
  1973: %
  1974: %The formula for the standard error of the difference in two means is similar to the formula for other standard errors. Recall that the standard error of a single mean, $\bar{x}_1$, can be approximated by

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2005)
  message: Should this be "Pooled Standard Deviation Estimate (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  2003: %\D{\newpage}
  2004: 
> 2005: \subsection{Pooled standard deviation estimate (special topic)}
  2006: \label{pooledStandardDeviations}
  2007: 

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2086)
  message: Should this be "Going Through the Motions of a Test"? Follow your preferred style guide and register as an exception if necessary.
  2084: 
  2085: 
> 2086: \subsection{Going through the motions of a test}
  2087: 
  2088: We're going to go through the motions of a hypothesis test.

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2299)
  message: Should this be "Determining a Proper Sample Size"? Follow your preferred style guide and register as an exception if necessary.
  2297: \D{\newpage}
  2298: 
> 2299: \subsection{Determining a proper sample size}
  2300: 
  2301: In the last example, we found that if we have a sample size

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2606)
  message: Should this be "Core Ideas of ANOVA"? Follow your preferred style guide and register as an exception if necessary.
  2604: 
  2605: 
> 2606: \subsection{Core ideas of ANOVA}
  2607: 
  2608: In this section, we will learn a new method called

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 2692)
  message: Should this be "Is Batting Performance Related to Player Position in MLB?"? Follow your preferred style guide and register as an exception if necessary.
  2690: 
  2691: 
> 2692: \subsection{Is batting performance related to player position in MLB?}
  2693: 
  2694: \index{data!MLB batting|(}

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 3072)
  message: Should this be "Reading an ANOVA Table From Software"? Follow your preferred style guide and register as an exception if necessary.
  3070: 
  3071: 
> 3072: \subsection{Reading an ANOVA table from software}
  3073: 
  3074: The calculations required to perform an ANOVA by hand are

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 3110)
  message: Should this be "Graphical Diagnostics for an ANOVA Analysis"? Follow your preferred style guide and register as an exception if necessary.
  3108: \D{\newpage}
  3109: 
> 3110: \subsection{Graphical diagnostics for an ANOVA analysis}
  3111: 
  3112: There are three conditions we must check for an ANOVA analysis:

- file: sample\submodules\openintro-statistics\ch_inference_for_means\TeX\ch_inference_for_means.tex (line 3168)
  message: Should this be "Multiple Comparisons and Controlling Type~1 Error Rate"? Follow your preferred style guide and register as an exception if necessary.
  3166: \D{\newpage}
  3167: 
> 3168: \subsection{Multiple comparisons and controlling Type~1 Error rate}
  3169: \label{multipleComparisonsAndControllingTheType1ErrorRate}
  3170: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 38)
  message: Should this be "Defining Probability"? Follow your preferred style guide and register as an exception if necessary.
    36: 
    37: 
>   38: \section{Defining probability}
    39: \label{basicsOfProbability}
    40: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 691)
  message: Should this be "Conditional Probability"? Follow your preferred style guide and register as an exception if necessary.
   689: 
   690: %_________________
>  691: \section{Conditional probability}
   692: \label{conditionalProbabilitySection}
   693: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1615)
  message: Should this be "Sampling From a Small Population"? Follow your preferred style guide and register as an exception if necessary.
  1613: 
  1614: %_________________
> 1615: \section{Sampling from a small population}
  1616: \label{smallPop}
  1617: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1713)
  message: Should this be "Random Variables"? Follow your preferred style guide and register as an exception if necessary.
  1711: 
  1712: %_________________
> 1713: \section{Random variables}
  1714: \label{randomVariablesSection}
  1715: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 2198)
  message: Should this be "Continuous Distributions"? Follow your preferred style guide and register as an exception if necessary.
  2196: 
  2197: %_________________
> 2198: \section{Continuous distributions}
  2199: \label{contDist}
  2200: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 48)
  message: Should this be "Introductory Examples"? Follow your preferred style guide and register as an exception if necessary.
    46: 
    47: 
>   48: \subsection{Introductory examples}
    49: 
    50: Before we get into technical ideas, let's walk through

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 143)
  message: Should this be "Disjoint or Mutually Exclusive Outcomes"? Follow your preferred style guide and register as an exception if necessary.
   141: \index{random process|)}
   142: 
>  143: \subsection{Disjoint or mutually exclusive outcomes}
   144: 
   145: \index{disjoint|(}

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 276)
  message: Should this be "Probabilities When Events Are Not Disjoint"? Follow your preferred style guide and register as an exception if necessary.
   274: \D{\newpage}
   275: 
>  276: \subsection{Probabilities when events are not disjoint}
   277: 
   278: Let's consider calculations for two events that are not disjoint in the context of a \indexthis{regular deck of 52 cards}{deck of cards}, represented in Figure~\ref{deckOfCards}. If you are unfamiliar with the cards in a regular deck, please see the footnote.\footnote{The 52 cards are split into four \term{suits}: $\clubsuit$ (club), {\color{redcards}$\diamondsuit$} (diamond), {\color{redcards}$\heartsuit$} (heart), $\spadesuit$ (spade). Each suit has its 13 cards labeled: \resp{2}, \resp{3}, ..., \resp{10}, \resp{J} (jack), \resp{Q} (queen), \resp{K} (king), and \resp{A} (ace). Thus, each card is a unique combination of a suit and a label, e.g. {\color{redcards}\resp{4$\heartsuit$}} and \resp{J$\clubsuit$}. The 12 cards represented by the jacks, queens, and kings are called \termsub{\resp{face cards}}{face card}. The cards that are {\color{redcards}$\diamondsuit$} or {\color{redcards}$\heartsuit$} are typically colored {\color{redcards}red} while the other two suits are typically colored black.}

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 396)
  message: Should this be "Probability Distributions"? Follow your preferred style guide and register as an exception if necessary.
   394: \D{\newpage}
   395: 
>  396: \subsection{Probability distributions}
   397: 
   398: A \termsub{probability distribution}{probability!distribution} is a table of all disjoint outcomes and their associated probabilities. Figure~\ref{diceProb} shows the probability distribution for the sum of two dice. 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 470)
  message: Should this be "Complement of an Event"? Follow your preferred style guide and register as an exception if necessary.
   468: In these bar plots, the bar heights represent the probabilities of outcomes. If the outcomes are numerical and discrete, it is usually (visually) convenient to make a bar plot that resembles a histogram, as in the case of the sum of two dice. Another example of plotting the bars at their respective locations is shown in Figure~\ref{bookCostDist} on page~\pageref{bookCostDist}.
   469: 
>  470: \subsection{Complement of an event}
   471: 
   472: Rolling a die produces a value in the set $\{$\resp{1}, \resp{2}, \resp{3}, \resp{4}, \resp{5}, \resp{6}$\}$. This set of all possible outcomes is called the \term{sample space} ($S$)\index{S@$S$} for rolling a die. We often use the sample space to examine the scenario where an event does not occur.

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 703)
  message: Should this be "Exploring Probabilities With a Contingency Table"? Follow your preferred style guide and register as an exception if necessary.
   701: 
   702: 
>  703: \subsection{Exploring probabilities with a contingency table}
   704: 
   705: \index{data!photo\_classify|(}

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 815)
  message: Should this be "Marginal and Joint Probabilities"? Follow your preferred style guide and register as an exception if necessary.
   813: \end{examplewrap}
   814: 
>  815: \subsection{Marginal and joint probabilities}
   816: \label{marginalAndJointProbabilities}
   817: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 947)
  message: Should this be "Defining Conditional Probability"? Follow your preferred style guide and register as an exception if necessary.
   945: 
   946: 
>  947: \subsection{Defining conditional probability}
   948: 
   949: \index{conditional probability|(}

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1196)
  message: Should this be "General Multiplication Rule"? Follow your preferred style guide and register as an exception if necessary.
  1194: 
  1195: 
> 1196: \subsection{General multiplication rule}
  1197: 
  1198: Section~\ref{probabilityIndependence} introduced the Multiplication Rule for independent processes. Here we provide the \term{General Multiplication Rule} for events that might not be independent.

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1278)
  message: Should this be "Independence Considerations in Conditional Probability"? Follow your preferred style guide and register as an exception if necessary.
  1276: %\D{\newpage}
  1277: 
> 1278: \subsection{Independence considerations in conditional probability}
  1279: 
  1280: If two events are independent, then knowing the outcome of one should provide no information about the other. We can show this is mathematically true using conditional probabilities.

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1317)
  message: Should this be "Tree Diagrams"? Follow your preferred style guide and register as an exception if necessary.
  1315: \D{\newpage}
  1316: 
> 1317: \subsection{Tree diagrams}
  1318: 
  1319: \index{data!smallpox|)}

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1843)
  message: Should this be "Variability in Random Variables"? Follow your preferred style guide and register as an exception if necessary.
  1841: \D{\newpage}
  1842: 
> 1843: \subsection{Variability in random variables}
  1844: 
  1845: Suppose you ran the university bookstore. Besides how much revenue you expect to generate, you might also want to know the volatility (variability) in your revenue. 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 1922)
  message: Should this be "Linear Combinations of Random Variables"? Follow your preferred style guide and register as an exception if necessary.
  1920: \end{center}}
  1921: 
> 1922: \subsection{Linear combinations of random variables}
  1923: 
  1924: So far, we have thought of each variable as being a complete story in and of itself. Sometimes it is more appropriate to use a combination of variables. For instance, the amount of time a person spends commuting to work each week can be broken down into several daily commutes. Similarly, the total gain or loss in a stock portfolio is the sum of the gains and losses in its components.

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 2053)
  message: Should this be "Variability in Linear Combinations of Random Variables"? Follow your preferred style guide and register as an exception if necessary.
  2051: \D{\newpage}
  2052: 
> 2053: \subsection{Variability in linear combinations of random variables}
  2054: \label{var_lin_combo_of_RVs}
  2055: 

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 2254)
  message: Should this be "From Histograms to Continuous Distributions"? Follow your preferred style guide and register as an exception if necessary.
  2252: \D{\newpage}
  2253: 
> 2254: \subsection{From histograms to continuous distributions}
  2255: 
  2256: Examine the transition from a boxy hollow histogram in the top-left of Figure~\ref{fdicHistograms} to the much smoother plot in the lower-right. In this last plot, the bins are so slim that the hollow histogram is starting to resemble a smooth curve. This suggests the population height as a \emph{continuous} numerical variable might best be explained by a curve that represents the outline of extremely slim bins.

- file: sample\submodules\openintro-statistics\ch_probability\TeX\ch_probability.tex (line 2275)
  message: Should this be "Probabilities From Continuous Distributions"? Follow your preferred style guide and register as an exception if necessary.
  2273: \D{\newpage}
  2274: 
> 2275: \subsection{Probabilities from continuous distributions}
  2276: 
  2277: We computed the proportion of individuals with heights \resp{180} to \resp{185} cm in Example~\ref{contDistProb} as a fraction:

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 29)
  message: Should this be "Fitting a Line, Residuals, and Correlation"? Follow your preferred style guide and register as an exception if necessary.
    27: 
    28: %__________
>   29: \section{Fitting a line, residuals, and correlation}
    30: % \section{Using a line to model data}
    31: \label{fitting_line_to_data_section}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 30)
  message: Should this be "Using a Line to Model Data"? Follow your preferred style guide and register as an exception if necessary.
    28: %__________
    29: \section{Fitting a line, residuals, and correlation}
>   30: % \section{Using a line to model data}
    31: \label{fitting_line_to_data_section}
    32: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 540)
  message: Should this be "Least Squares Regression"? Follow your preferred style guide and register as an exception if necessary.
   538: 
   539: %__________________
>  540: \section{Least squares regression}
   541: \label{fittingALineByLSR}
   542: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1218)
  message: Should this be "Types of Outliers in Linear Regression"? Follow your preferred style guide and register as an exception if necessary.
  1216: 
  1217: %__________________
> 1218: \section{Types of outliers in linear regression}
  1219: \label{typesOfOutliersInLinearRegression}
  1220: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1326)
  message: Should this be "Inference for Linear Regression"? Follow your preferred style guide and register as an exception if necessary.
  1324: 
  1325: %__________________
> 1326: \section{Inference for linear regression}
  1327: \label{inferenceForLinearRegression}
  1328: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 40)
  message: Should this be "Fitting a Line to Data"? Follow your preferred style guide and register as an exception if necessary.
    38: 
    39: 
>   40: \subsection{Fitting a line to data}
    41: 
    42: Figure~\ref{perfLinearModel} shows two variables whose

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 150)
  message: Should this be "Using Linear Regression to Predict Possum Head Lengths"? Follow your preferred style guide and register as an exception if necessary.
   148: 
   149: 
>  150: \subsection{Using linear regression to predict possum head lengths}
   151: 
   152: \index{data!possum|(}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 430)
  message: Should this be "Describing Linear Relationships With Correlation"? Follow your preferred style guide and register as an exception if necessary.
   428: 
   429: 
>  430: \subsection{Describing linear relationships with correlation}
   431: 
   432: \index{correlation|(}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 551)
  message: Should this be "Gift Aid for Freshman at Elmhurst College"? Follow your preferred style guide and register as an exception if necessary.
   549: 
   550: 
>  551: \subsection{Gift aid for freshman at Elmhurst College}
   552: 
   553: This section considers family income and gift aid data from

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 583)
  message: Should this be "An Objective Measure for Finding the Best Line"? Follow your preferred style guide and register as an exception if necessary.
   581: 
   582: 
>  583: \subsection{An objective measure for finding the best line}
   584: 
   585: We begin by thinking about what we mean by ``best''.

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 632)
  message: Should this be "Conditions for the Least Squares Line"? Follow your preferred style guide and register as an exception if necessary.
   630: 
   631: 
>  632: \subsection{Conditions for the least squares line}
   633: 
   634: \noindent%

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 724)
  message: Should this be "Finding the Least Squares Line"? Follow your preferred style guide and register as an exception if necessary.
   722: \D{\newpage}
   723: 
>  724: \subsection{Finding the least squares line}
   725: \label{findingTheLeastSquaresLineSection}
   726: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 938)
  message: Should this be "Interpreting Regression Model Parameter Estimates"? Follow your preferred style guide and register as an exception if necessary.
   936: 
   937: 
>  938: \subsection{Interpreting regression model parameter estimates}
   939: 
   940: \index{least squares regression!interpreting parameters|(}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 995)
  message: Should this be "Extrapolation Is Treacherous"? Follow your preferred style guide and register as an exception if necessary.
   993: \D{\newpage}
   994: 
>  995: \subsection{Extrapolation is treacherous}
   996: 
   997: \index{least squares regression!extrapolation|(}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1116)
  message: Should this be "Categorical Predictors With Two Levels"? Follow your preferred style guide and register as an exception if necessary.
  1114: 
  1115: 
> 1116: \subsection{Categorical predictors with two levels}
  1117: \label{categoricalPredictorsWithTwoLevels}
  1118: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1336)
  message: Should this be "Midterm Elections and Unemployment"? Follow your preferred style guide and register as an exception if necessary.
  1334: 
  1335: 
> 1336: \subsection{Midterm elections and unemployment}
  1337: 
  1338: \index{data!midterm elections|(}

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1432)
  message: Should this be "Understanding Regression Output From Software"? Follow your preferred style guide and register as an exception if necessary.
  1430: 
  1431: 
> 1432: \subsection{Understanding regression output from software}
  1433: \label{testStatisticForTheSlope}
  1434: 

- file: sample\submodules\openintro-statistics\ch_regr_simple_linear\TeX\ch_regr_simple_linear.tex (line 1608)
  message: Should this be "Confidence Interval for a Coefficient"? Follow your preferred style guide and register as an exception if necessary.
  1606: \newpage
  1607: 
> 1608: \subsection{Confidence interval for a coefficient}
  1609: 
  1610: \index{confidence interval!regression|(}%

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 27)
  message: Should this be "Introduction to Multiple Regression"? Follow your preferred style guide and register as an exception if necessary.
    25: 
    26: 
>   27: \section{Introduction to multiple regression}
    28: \label{introductionToMultipleRegression}
    29: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 797)
  message: Should this be "Model Selection"? Follow your preferred style guide and register as an exception if necessary.
   795: 
   796: %__________________
>  797: \section{Model selection}
   798: \label{model_selection_section}
   799: \label{modelSelection}

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1229)
  message: Should this be "Checking Model Conditions Using Graphs"? Follow your preferred style guide and register as an exception if necessary.
  1227: 
  1228: %%%%%
> 1229: \section{Checking model conditions using graphs}
  1230: \label{multipleRegressionModelAssumptions}
  1231: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1581)
  message: Should this be "Multiple Regression Case Study: Mario Kart"? Follow your preferred style guide and register as an exception if necessary.
  1579: 
  1580: %_____________________
> 1581: \section{Multiple regression case study: Mario Kart}
  1582: \label{mario_kart_case_study}
  1583: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2056)
  message: Should this be "Introduction to Logistic Regression"? Follow your preferred style guide and register as an exception if necessary.
  2054: 
  2055: %__________________
> 2056: \section{Introduction to logistic regression}
  2057: \label{logisticRegression}
  2058: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 147)
  message: Should this be "Indicator and Categorical Variables as Predictors"? Follow your preferred style guide and register as an exception if necessary.
   145: \newpage
   146: 
>  147: \subsection{Indicator and categorical variables as predictors}
   148: \label{ind_and_cat_vars_as_predictors}
   149: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 421)
  message: Should this be "Including and Assessing Many Variables in a Model"? Follow your preferred style guide and register as an exception if necessary.
   419: 
   420: 
>  421: \subsection{Including and assessing many variables in a model}
   422: \label{includingAndAssessingManyVariablesInAModel}
   423: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 819)
  message: Should this be "Identifying Variables in the Model That May
    Not Be Helpful"? Follow your preferred style guide and register as an exception if necessary.
   817: 
   818: 
>  819: \subsection{Identifying variables in the model that may
   820:     not be helpful}
   821: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 909)
  message: Should this be "Two Model Selection Strategies"? Follow your preferred style guide and register as an exception if necessary.
   907: 
   908: 
>  909: \subsection{Two model selection strategies}
   910: 
   911: Two common strategies for adding or removing variables

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1253)
  message: Should this be "Diagnostic Plots"? Follow your preferred style guide and register as an exception if necessary.
  1251: 
  1252: 
> 1253: \subsection{Diagnostic plots}
  1254: \label{diagnostic_plots_subsection}
  1255: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1397)
  message: Should this be "Options for Improving the Model Fit"? Follow your preferred style guide and register as an exception if necessary.
  1395: \D{\newpage}
  1396: 
> 1397: \subsection{Options for improving the model fit}
  1398: 
  1399: There are several options for improvement of a model,

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1603)
  message: Should this be "Data Set and the Full Model"? Follow your preferred style guide and register as an exception if necessary.
  1601: 
  1602: 
> 1603: \subsection{Data set and the full model}
  1604: 
  1605: The \data{mariokart} data set includes results

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1818)
  message: Should this be "Model Selection"? Follow your preferred style guide and register as an exception if necessary.
  1816: 
  1817: 
> 1818: \subsection{Model selection}
  1819: 
  1820: \noindent%

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 1938)
  message: Should this be "Checking Model Conditions Using Graphs"? Follow your preferred style guide and register as an exception if necessary.
  1936: 
  1937: 
> 1938: \subsection{Checking model conditions using graphs}
  1939: 
  1940: \noindent%

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2087)
  message: Should this be "Resume Data"? Follow your preferred style guide and register as an exception if necessary.
  2085: %In Section~\ref{logisticRegression} we will revisit the \data{email} data set from Chapter~\ref{introductionToData}. These emails were collected from a single email account, and we will work on developing a basic spam filter using these data. The response variable, \var{spam}, has been encoded to take value~0 when a message is not spam and~1 when it is spam. Our task will be to build an appropriate model that classifies messages as spam or not spam using email characteristics coded as predictor variables. While this model will not be the same as those used in large-scale spam filters, it shares many of the same features. 
  2086: 
> 2087: \subsection{Resume data}
  2088: 
  2089: \index{data!resume|(}

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2278)
  message: Should this be "Modeling the Probability of an Event"? Follow your preferred style guide and register as an exception if necessary.
  2276: 
  2277: 
> 2278: \subsection{Modeling the probability of an event}
  2279: \label{modelingTheProbabilityOfAnEvent}
  2280: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2447)
  message: Should this be "Building the Logistic Model With Many Variables"? Follow your preferred style guide and register as an exception if necessary.
  2445: 
  2446: 
> 2447: \subsection{Building the logistic model with many variables}
  2448: 
  2449: We used statistical software to fit the logistic regression

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2703)
  message: Should this be "Diagnostics for the Callback Rate Model"? Follow your preferred style guide and register as an exception if necessary.
  2701: 
  2702: 
> 2703: \subsection{Diagnostics for the callback rate model}
  2704: \label{logistic_regr_diagnostics_subsection}
  2705: 

- file: sample\submodules\openintro-statistics\ch_regr_mult_and_log\TeX\ch_regr_mult_and_log.tex (line 2832)
  message: Should this be "Exploring Discrimination Between Groups
    of Different Sizes"? Follow your preferred style guide and register as an exception if necessary.
  2830: \D{\newpage}
  2831: 
> 2832: \subsection{Exploring discrimination between groups
  2833:     of different sizes}
  2834:     % An exercise in critical thinking around a hypothetical setting

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 26)
  message: Should this be "Examining Numerical Data"? Follow your preferred style guide and register as an exception if necessary.
    24: 
    25: %%%%%
>   26: \section{Examining numerical data}
    27: \label{numericalData}
    28: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1323)
  message: Should this be "Considering Categorical Data"? Follow your preferred style guide and register as an exception if necessary.
  1321: 
  1322: 
> 1323: \section{Considering categorical data}
  1324: \label{categoricalData}
  1325: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2145)
  message: Should this be "Exploratory Data Analysis"? Follow your preferred style guide and register as an exception if necessary.
  2143: 
  2144: %%___________________________________________
> 2145: %\section{Exploratory data analysis}
  2146: %\label{eda_section}
  2147: %

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2166)
  message: Should this be "Case Study: Malaria Vaccine"? Follow your preferred style guide and register as an exception if necessary.
  2164: 
  2165: %___________________________________________
> 2166: \section{Case study: malaria vaccine}
  2167: \label{caseStudyMalariaVaccine}
  2168: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 73)
  message: Should this be "Scatterplots for Paired Data"? Follow your preferred style guide and register as an exception if necessary.
    71: 
    72: 
>   73: \subsection{Scatterplots for paired data}
    74: \label{scatterPlots}
    75: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 167)
  message: Should this be "Dot Plots and the Mean"? Follow your preferred style guide and register as an exception if necessary.
   165: 
   166: 
>  167: \subsection{Dot plots and the mean}
   168: \label{dotPlot}
   169: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 436)
  message: Should this be "Histograms and Shape"? Follow your preferred style guide and register as an exception if necessary.
   434: 
   435: 
>  436: \subsection{Histograms and shape}
   437: \label{histogramsAndShape}
   438: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 650)
  message: Should this be "Variance and Standard Deviation"? Follow your preferred style guide and register as an exception if necessary.
   648: \D{\newpage}
   649: 
>  650: \subsection{Variance and standard deviation}
   651: \label{variability}
   652: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 819)
  message: Should this be "Box Plots, Quartiles, and the Median"? Follow your preferred style guide and register as an exception if necessary.
   817: \D{\newpage}
   818: 
>  819: \subsection{Box plots, quartiles, and the median}
   820: 
   821: A \term{box plot} summarizes a data set using five

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 986)
  message: Should this be "Robust Statistics"? Follow your preferred style guide and register as an exception if necessary.
   984: \D{\newpage}
   985: 
>  986: \subsection{Robust statistics}
   987: 
   988: How are the \indexthis{sample statistics}{sample statistic}

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1095)
  message: Should this be "Transforming Data (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  1093: \D{\newpage}
  1094: 
> 1095: \subsection{Transforming data (special topic)}
  1096: \label{transformingDataSubsection}
  1097: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1207)
  message: Should this be "Mapping Data (Special Topic)"? Follow your preferred style guide and register as an exception if necessary.
  1205: \D{\newpage}
  1206: 
> 1207: \subsection{Mapping data (special topic)}
  1208: 
  1209: \index{data!county|(}

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1344)
  message: Should this be "Contingency Tables and Bar Plots"? Follow your preferred style guide and register as an exception if necessary.
  1342: 
  1343: 
> 1344: \subsection{Contingency tables and bar plots}
  1345: 
  1346: \newcommand{\loanapphomeAA}{3496}

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1461)
  message: Should this be "Row and Column Proportions"? Follow your preferred style guide and register as an exception if necessary.
  1459: \D{\newpage}
  1460: 
> 1461: \subsection{Row and column proportions}
  1462: 
  1463: Sometimes it is useful to understand the fractional breakdown

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1701)
  message: Should this be "Using a Bar Plot With Two Variables"? Follow your preferred style guide and register as an exception if necessary.
  1699: \D{\newpage}
  1700: 
> 1701: \subsection{Using a bar plot with two variables}
  1702: \label{bar_plots_subsection}
  1703: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1872)
  message: Should this be "Mosaic Plots"? Follow your preferred style guide and register as an exception if necessary.
  1870: %than if only one bar plot variant is reviewed.
  1871: 
> 1872: \subsection{Mosaic plots}
  1873: \label{mosaic_plots_subsection}
  1874: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 1970)
  message: Should this be "The Only Pie Chart You Will See in This Book"? Follow your preferred style guide and register as an exception if necessary.
  1968: 
  1969: 
> 1970: \subsection{The only pie chart you will see in this book}
  1971: 
  1972: A \term{pie chart} is shown in

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2003)
  message: Should this be "Comparing Numerical Data Across Groups"? Follow your preferred style guide and register as an exception if necessary.
  2001: \D{\newpage}
  2002: 
> 2003: \subsection{Comparing numerical data across groups}
  2004: \label{comparingAcrossGroups}
  2005: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2187)
  message: Should this be "Variability Within Data"? Follow your preferred style guide and register as an exception if necessary.
  2185: 
  2186: 
> 2187: \subsection{Variability within data}
  2188: \label{variabilityWithinData}
  2189: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2362)
  message: Should this be "Simulating the Study"? Follow your preferred style guide and register as an exception if necessary.
  2360: 
  2361: 
> 2362: \subsection{Simulating the study}
  2363: \label{simulatingTheStudy}
  2364: 

- file: sample\submodules\openintro-statistics\ch_summarizing_data\TeX\ch_summarizing_data.tex (line 2439)
  message: Should this be "Checking for Independence"? Follow your preferred style guide and register as an exception if necessary.
  2437: 
  2438: 
> 2439: \subsection{Checking for independence}
  2440: 
  2441: We computed one possible difference under the

- file: sample\submodules\openintro-statistics\extraTeX\preamble\preface.tex (line 31)
  message: Should this be "Is This a Data Science Book?"? Follow your preferred style guide and register as an exception if necessary.
    29: 
    30: 
>   31: %\subsection*{Is this a data science book?}
    32: %
    33: %\noindent%

- file: sample\submodules\openintro-statistics\extraTeX\preamble\review_copy.tex (line 10)
  message: Should this be "What *Not* to Watch For"? Follow your preferred style guide and register as an exception if necessary.
     8: 
     9: 
>   10: \subsection*{What *not* to watch for}
    11: 
    12: \noindent%

- file: sample\submodules\openintro-statistics\extraTeX\preamble\review_copy.tex (line 40)
  message: Should this be "We Will Send a Survey for You to Complete"? Follow your preferred style guide and register as an exception if necessary.
    38: 
    39: 
>   40: \subsection*{We will send a survey for you to complete}
    41: 
    42: \noindent%

- file: sample\submodules\openintro-statistics\extraTeX\preamble\review_copy.tex (line 49)
  message: Should this be "Sending Feedback as You Read"? Follow your preferred style guide and register as an exception if necessary.
    47: 
    48: 
>   49: \subsection*{Sending feedback as you read}
    50: 
    51: \noindent%

- file: sample\submodules\openintro-statistics\extraTeX\preamble\review_copy.tex (line 116)
  message: Should this be "Some of the Changes Already Implemented"? Follow your preferred style guide and register as an exception if necessary.
   114: 
   115: 
>  116: \subsection*{Some of the changes already implemented}
   117: 
   118: \noindent%

- file: sample\submodules\openintro-statistics\extraTeX\preamble\review_copy.tex (line 185)
  message: Should this be "Changes in Progress or That Will Be Completed"? Follow your preferred style guide and register as an exception if necessary.
   183: 
   184: 
>  185: \subsection*{Changes in progress or that will be completed}
   186: 
   187: \noindent%

- file: sample\submodules\OpenLogic\content\model-theory\basics\nonstandard-arithmetic.tex (line 10)
  message: Should this be "Non-Standard Models of Arithmetic"? Follow your preferred style guide and register as an exception if necessary.
     8: 
     9: \olfileid{mod}{bas}{nsa}
>   10: \section{Non-standard Models of Arithmetic}
    11: 
    12: \begin{defn}

- file: sample\arxiv_sources\1407.2927v2\JustMathPERC.revised.tex (line 44)
  message: Should this be "Just Math: a New Epistemic Frame"? Follow your preferred style guide and register as an exception if necessary.
    42: 
    43: \begin{document}
>   44: \title{Just Math: A New Epistemic Frame}
    45: 
    46: \author{Steven F.~Wolf}{

- file: sample\arxiv_sources\1101.2623v9\CaratheodoryGibbsMeasures4_Erratum.tex (line 99)
  message: Should this be " Erratum: Dynamically Defined Measures and Equilibrium States"? Follow your preferred style guide and register as an exception if necessary.
    97: 
    98: 
>   99: \title{ Erratum: Dynamically defined measures and equilibrium states}
   100: \author{Ivan Werner}
   101: \email  { ivan\_werner@mail.ru}

- file: sample\arxiv_sources\1609.03457v1\appendix-nifty-tools.tex (line 8)
  message: Should this be "Math Tools: a Sample of Interesting Tools"? Follow your preferred style guide and register as an exception if necessary.
     6: This appendix covers a sample of interesting math tools, and gives references to a few good databases and lists of tools.  These were discovered along the course of this research, and the author thought them nifty: the list is by no means exhaustive.
     7: 
>    8: \section{Math tools: A Sample of Interesting Tools}
     9: 
    10: Below is a subset of Mathematical software tools: it includes a few which I thought might be of interest to physicists, but is intended to be a sample only.  In the next section (section \ref{sec:finding-tools}), some resources for finding other math software are given.

- file: sample\arxiv_sources\1609.03457v1\appendix-nifty-tools.tex (line 44)
  message: Should this be "Resources to Find Other Tools"? Follow your preferred style guide and register as an exception if necessary.
    42: Many modeling tools are listed on swMath.org.  A few examples are the modeling-oriented coding language Modelica (thank you to Erik Schnetter for pointing out this tool) \cite{modelica}, and Wolfram's Systems Modeler  platform \cite{Wolfram-System-Modeler}.
    43: 
>   44: \section{Resources to find other tools}
    45: \label{sec:finding-tools}
    46: 

- file: sample\arxiv_sources\1609.03457v1\appendix-nifty-tools.tex (line 24)
  message: Should this be "Exploration And/or Lookup"? Follow your preferred style guide and register as an exception if necessary.
    22: This site is like the Online Encyclopedia of Integer Sequences, except that it focuses on sequences which are relevant to decomposable combinatorial structures.  Search options include: the first few terms from a sequence, keyword, generating function, or closed form. \cite{combinatorial-encyc}
    23: 
>   24: \subsection{Exploration and/or Lookup}
    25: 
    26: \subsubsection{The KnotPlot Site}

- file: sample\arxiv_sources\1609.03457v1\appendix-nifty-tools.tex (line 36)
  message: Should this be "Special and Elementary Function Databases"? Follow your preferred style guide and register as an exception if necessary.
    34: Mathematical proof assistants include the semi-interactive theorem prover Coq \cite{Coqweb} and the coding language Mizar \cite{Mizar-web}. \cite{Guidi-Cohen-2015}
    35: 
>   36: \subsection{Special and Elementary Function databases}
    37: Aside from the equation-searchable special function databases, which were mentioned in the main paper (DLMF, Wolfram Alpha), there are some keyword-searchable special function databases.  One example is the Wolfram Functions website, where a special function's entry can contain many different definitions and written forms.  A keyword by which to search for more such sites is ``Digital Mathematics Library'' (DML).
    38: 

- file: sample\arxiv_sources\1609.03457v1\appendix-nifty-tools.tex (line 41)
  message: Should this be "Modeling Tools"? Follow your preferred style guide and register as an exception if necessary.
    39: There is also an in-development upgrade to searching special functions and orthogonal polynomials, which includes the content of the DLMF and a number of special functions textbooks.  It is planned to be easily searchable \cite{DRMF-CohlEtAl}; since it aims to improve upon the DLMF, hopefully this will include a math-aware search engine which can parse equation queries.  Community comments on each formula's page will also be possible.  A demo of it is available at \cite{DRMF-web-Xsede} or \cite{DRMF-web-wmflabs}.
    40: 
>   41: \subsection{Modeling tools}
    42: Many modeling tools are listed on swMath.org.  A few examples are the modeling-oriented coding language Modelica (thank you to Erik Schnetter for pointing out this tool) \cite{modelica}, and Wolfram's Systems Modeler  platform \cite{Wolfram-System-Modeler}.
    43: 

- file: sample\arxiv_sources\1101.2623v9\CaratheodoryGibbsMeasures4.tex (line 88)
  message: Should this be " Dynamically Defined Measures and Equilibrium States"? Follow your preferred style guide and register as an exception if necessary.
    86: 
    87: 
>   88: \title{ Dynamically defined measures and equilibrium states}
    89: \author{Ivan Werner\\
    90:    {\small Email: ivan\_werner@mail.ru}}

- file: sample\arxiv_sources\1101.2623v9\CaratheodoryGibbsMeasures4.tex (line 108)
  message: Should this be "Dynamically Defined Measures"? Follow your preferred style guide and register as an exception if necessary.
   106: 
   107: 
>  108: \section{Dynamically defined measures}
   109: 
   110: 

- file: sample\arxiv_sources\1101.2623v9\CaratheodoryGibbsMeasures4.tex (line 450)
  message: Should this be "Equilibrium States"? Follow your preferred style guide and register as an exception if necessary.
   448: 
   449: 
>  450:      \section{Equilibrium states}
   451: 
   452:      In this section, we intend to show that construction of $\Phi$ allows to obtain equilibrium states for some energy function $u: \Sigma\longrightarrow[-\infty,0]$.

- file: sample\arxiv_sources\1101.2623v9\CaratheodoryGibbsMeasures4.tex (line 499)
  message: Should this be "Equilibrium States for Random Dynamical Systems"? Follow your preferred style guide and register as an exception if necessary.
   497: 
   498: 
>  499:        \subsection{Equilibrium states for random dynamical systems}
   500: 
   501:        Now, we are going to apply the theory developed in this paper to some random dynamical systems introduced in \cite{Wer1} as {\it Markov systems}.

- file: sample\arxiv_sources\1609.03457v1\avail-engines.tex (line 25)
  message: Should this be "Keeping Up-to-Date"? Follow your preferred style guide and register as an exception if necessary.
    23: Architectures which were discovered, but not included due to absent web-availability, are listed here in case the reader comes accross them elsewhere.  They may be in early stages of development, or old enough to be discontinued.  They include: EgoMath2, Ego-Math, Physikerwelt, WikiMirs, Formula Search Engine, MathDex (formerly MathFind), LeActiveMath, ActiveMath, Math Go!, and Math Aware Search Engine (MASE). \cite{SojkaEtAl2011, Oviedo-Th, Liska-Th, Liska-PhD-Prop, WikiMirs-Main-pub, ActiveMath-workings, Wangari-Th, Pres-vs-Content-2014}
    24: 
>   25: \section{Keeping Up-To-Date}
    26: 
    27: Keywords to help researchers keep abreast of newly-developed math-aware search engines include:

- file: sample\arxiv_sources\1609.03457v1\avail-engines.tex (line 144)
  message: Should this be "Ready for ArXiV Deployment: Needs Server Space"? Follow your preferred style guide and register as an exception if necessary.
   142: 
   143: %---------------------------------------------------------------
>  144: \section{Ready for ArXiV deployment: Needs Server Space}
   145: 
   146: The developer of the equation-based search engine MathWebSearch, Michael Kohlhase, states on his webpage that MathWebSearch is ready for deployment on arXiv.org.  To do so, he needs 128GB of additional server space, and that their restriction comes especially from the RAM; donations of server space are invited. \cite{MathWebSearch-info}

- file: sample\arxiv_sources\1609.03457v1\avail-engines.tex (line 151)
  message: Should this be "In Development for Physics"? Follow your preferred style guide and register as an exception if necessary.
   149: 
   150: %---------------------------------------------------------------
>  151: \section{In development for physics}
   152: 
   153: \subsection{$5e^{x+y}$}

- file: sample\arxiv_sources\1601.01850v2\Cexp_-_November_2017.tex (line 729)
  message: Should this be "Notation, Main Results and Layout of This Paper"? Follow your preferred style guide and register as an exception if necessary.
   727: 
   728: 
>  729: \section{Notation, main results and layout of this paper}
   730: 
   731: \label{s:mainResults}

- file: sample\arxiv_sources\1601.01850v2\Cexp_-_November_2017.tex (line 1202)
  message: Should this be "Preparation of Subanalytic and Constructible Functions"? Follow your preferred style guide and register as an exception if necessary.
  1200: \end{figure}
  1201: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
> 1202: \section{Preparation of subanalytic and constructible Functions}
  1203: \label{s:prepSubConstr}
  1204: 

- file: sample\arxiv_sources\1601.01850v2\Cexp_-_November_2017.tex (line 1605)
  message: Should this be "Integrating Superintegrable Generators"? Follow your preferred style guide and register as an exception if necessary.
  1603: \end{rems}
  1604: 
> 1605: \section{Integrating superintegrable generators}
  1606: 
  1607: \label{s:integGen}

- file: sample\arxiv_sources\1609.03457v1\introduction.tex (line 12)
  message: Should this be "What Is Math-Aware Search?"? Follow your preferred style guide and register as an exception if necessary.
    10: So far, their databases include journal articles, encyclopedias, and math forums. \cite{MWS-05-2012, zbMath-database-about, EuDML-web-base, Springer-LatexSearch-post, DLMF-website, DLMF-AMS-notice, Weisstein-Alpha, Wolfram-Alpha-web, Tangent-pub-2015, uniquationWeb}. 
    11: 
>   12: \section{What is math-aware search?}
    13: 
    14: The goal of these math-aware search engines is to retrieve mathematical formulae which are relevant to a queried formula. \cite{Guidi-Cohen-2015, ZY_math-sim-search, Kohlhase-Sucan-early-MWS, Tangent-technical-v0.3}

- file: sample\arxiv_sources\1609.03457v1\introduction.tex (line 20)
  message: Should this be "Ability to Recognize and Compare Math"? Follow your preferred style guide and register as an exception if necessary.
    18: The search engines are still developing, having been made primarily in the past decade or so. \cite{Guidi-Cohen-2015}  They are well-enough developed to be useful, by providing a new window into our existing research.  As an encyclopedia editor said: ``we don't even know how much we don't know we know''. \cite{Hazewinkel-MKM-is-needed} These search engines help us find what we already know, by enabling us to search in one of our main languages: that of math.
    19: 
>   20: \section{Ability to recognize and compare math}
    21: 
    22: Presentation-based search might match, for instance, $\log(\sqrt{z})$ and $\log(b)$.  They allow variables' names to be changed, constants and variables to be exchanged, expressions to be substituted for variables, and algebraic terms to be added or removed. \cite{Guidi-Cohen-2015, DLMF-AMS-notice, Pres-vs-Content-2014, Liska-Th ,Liska-PhD-Prop}

- file: sample\arxiv_sources\1609.03457v1\introduction.tex (line 26)
  message: Should this be "Database Coverage"? Follow your preferred style guide and register as an exception if necessary.
    24: Meaning-based search, on the other hand, could ideally match $\sin(x)$ to $(1/2) i (e^{-iz}-e^{iz})$. \cite{Liska-PhD-Prop, Oviedo-Th, Wolfram-Alpha-web}  However, at present, search engines' knowledge of such math equivalencies vary \cite{Guidi-Cohen-2015} and all fall short of being able to match formulas based just on their meaning, ignoring their notation. \cite{Liska-PhD-Prop, MWS-05-2012} A clear delimitation of what they can recognize would require a full understanding of their mathematics parsing algorithms, and is beyond the scope of this paper.  However, a few limitations and examples are explicitly stated in the search engines' publications, and are included in this paper (Chapter \ref{chap:extent-abilities}).  One simple example of what they can parse is commutativity: $ab$ equals $ba$.  Beyond that simple relation, the two web-available meaning-based search engines vary in their abilities.  One can parse all mathematical equivalencies which \emph{Mathematica} can (Wolfram Alpha) \cite{Weisstein-Alpha}, which is still limited when trying to recognize special functions (such as that $T_n(z) = \frac{\delta_{n,0}}{2} + \frac{n}{2}\sum^{\lfloor (n/2) \rfloor}_{k=1} \frac{(-1)^k (n-k-1)! (2 z)^{n-2k}}{k! (n-2 k)!} + 2^{n-1} z^n /; n \in \mathbb{N}$ \cite{Cheb-I-WF} and $T_n(x) = \cos(n \cos^{-1}(x))$ \cite{Cheb-I-WA} are the same function).  Another (MathWebSearch) allows associativity, lets variables' names vary using wildcards, and generalizes some functions to $f(x)$ notation. \cite{MWS-thesis-hasegan, IancuEtAl2014, MWS-05-2012}  However, this engine does not parse all math to a standardized, mathematically-equivalent form: a search for $\lambda x (1 - x + 1 - 1)$ retrieves different results, for example, than does a search for $\lambda x (1 - x)$.  Math-aware search developers are investigating improving their mathematical comparison abilities with Computer Algebra Systems (such as \emph{Mathematica}): the CAS could be used to simplify all database and queried expressions to a standard notation, using rules of math and definitions of functions, so that equations with different writings but the same meaning could be much better found.  \cite{Oviedo-Th, Liska-PhD-Prop}
    25: 
>   26: \section{Database coverage}
    27: 
    28: The databases covered include physics and math papers \cite{zbMath-database-about, EuDML-web-base, Springer-LatexSearch-post}, special function compendiums \cite{DLMF-website, DLMF-AMS-notice}, encyclopedias \cite{Weisstein-Alpha, Wolfram-Alpha-web}, and math forums \cite{uniquationWeb}.  Not all physics publications are included, yet, but one math-aware search architecture is stated to be ready for full deployment on the arXiv.org content. \cite{MathWebSearch-info}  Some of Springer's articles are covered \cite{Springer-LatexSearch-post, Springer-main-page}, and many European math and mathematical physics journals are math-searchable \cite{EuDML-web-base}.

- file: sample\arxiv_sources\1609.03457v1\introduction.tex (line 34)
  message: Should this be "Paper Layout"? Follow your preferred style guide and register as an exception if necessary.
    32: It has been said, prior to the start of engines' development (roughly a decade ago), that it is easier to re-derive a medium-difficulty result in math than it is to find it in the literature. \cite{Hazewinkel-MKM-is-needed} The author commented that the same could probably be said for applied mathematics disciplines, of which physics is one.  There is much lying around in the literature which each researcher knows little or nothing about.  To find out what we already know, find connections between systems, discover solutions, and target searches and collaborations, the math-aware search engines fill a long-empty niche.  Interdisciplinary and intra-field information finding becomes simpler, because researchers don't have to know the field's jargon to find information: we can search using formulae, instead, to get a starting point.
    33: 
>   34: \section{Paper layout}
    35: 
    36: Applications to the research of physics, from these search engines, are numerous - some proposed ones are included in Chapter \ref{chap:physics-applications}.  Readers who just want to use the engines can skip Chapter \ref{chap:extent-abilities}, which details the engines' math comparison abilities, limitations, and future developments.  Successful searches and choice of engine are among the subjects overviewed in Chapter \ref{chap:guide-to-use}, which is a quick ``Guide to Use''.  Following that is a usage-oriented summary of each math-aware search engine which is presently web-hosted, in Chapter \ref{chap:avail-SEs}.  That chapter also summarizes the web-available engines' downloadable versions (when applicable), from which custom databases can be created.  Furthermore, it presents a CERN project which is underway, to create math-aware search which is catered to physics' particular needs.  In chapter \ref{chap:screenshots}, screenshots of searches with each search engine are included.

- file: sample\arxiv_sources\1912.00839v1\AAAI-YuanK.6564.tex (line 463)
  message: Should this be "Jointly Modeling Quality"? Follow your preferred style guide and register as an exception if necessary.
   461: 
   462: \subsection{Quality Analysis}
>  463: \subsubsection{Jointly modeling quality}
   464: 
   465: The heatmap in Figure~\ref{fig:attention} visualizes the attention weights from MathSum.

- file: sample\arxiv_sources\1912.00839v1\AAAI-YuanK.6564.tex (line 469)
  message: Should this be "Case Study"? Follow your preferred style guide and register as an exception if necessary.
   467: %Moreover, it can well align the textual token ``in" to ``to", since they are both prepositions. 
   468: %Thus, MathSum can jointly study and align word tokens and math tokens, even they are in different types.
>  469: \subsubsection{Case study}
   470: To gain an insightful understanding regarding the generation quality of our method, we present three typical examples in Table~\ref{tab:examples}. The first two are selected from EXEQ-300k\footnote{https://math.stackexchange.com/questions/2431575}$^,$\footnote{ https://math.stackexchange.com/questions/752067} and the last one is selected from OFEQ-10k\footnote{https://mathoverflow.net/questions/291434}. From the examples, we see that the generated headlines and the human-written headlines have comparability and similarity. Generally, the generated headlines are coherent, grammatical, and informative. 
   471: %This also explains why MathSum performs well on the {\task} task.

- file: sample\arxiv_sources\1807.00200v1\comment.tex (line 69)
  message: Should this be "Comments on ``Comment on ``Finiteness of Corner Vortices" [ Z. Angew. Math. Phys. (2018) 69:37]"[Z. Angew. Math. Phys. (2018) 69:64]"? Follow your preferred style guide and register as an exception if necessary.
    67: \begin{document}
    68: 
>   69: \title{Comments on ``Comment on ``Finiteness of corner vortices" [ Z. Angew. Math. Phys. (2018) 69:37]"[Z. Angew. Math. Phys. (2018) 69:64]}
    70: %\thanks{Grants or other notes
    71: %about the article that should go on the front page should be

- file: sample\arxiv_sources\1101.2623v9\SecondCaratheodoryGibbsMeasures4_Erratum.tex (line 105)
  message: Should this be " Erratum II: Dynamically Defined Measures and Equilibrium States"? Follow your preferred style guide and register as an exception if necessary.
   103: 
   104: 
>  105: \title{ Erratum II: Dynamically defined measures and equilibrium states}
   106: \author{Ivan Werner}
   107: \email  { ivan\_werner@mail.ru}

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 1095)
  message: Should this be "A Limit Space and Quasi-Interpolation"? Follow your preferred style guide and register as an exception if necessary.
  1093: 
  1094: 
> 1095: \section{A limit space and quasi-interpolation}
  1096: \label{sec:limit}
  1097: In this section we shall first introduce a new limit space $\V_\infty$ of the sequence of

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 2217)
  message: Should this be "(Almost) Best Approximation Property"? Follow your preferred style guide and register as an exception if necessary.
  2215: 
  2216: 
> 2217: \section{(Almost) best approximation property}
  2218: \label{sec:uinfty}
  2219: 

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 2837)
  message: Should this be "Proof of the Main Result"? Follow your preferred style guide and register as an exception if necessary.
  2835: 
  2836: 
> 2837: \section{Proof of the main result}
  2838: \label{sec:convergence-est}
  2839: 

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 615)
  message: Should this be "Discontinuous Galerkin Method"? Follow your preferred style guide and register as an exception if necessary.
   613: $u$ exists and is unique.
   614: 
>  615: \subsection{Discontinuous Galerkin method}
   616:   \label{secdgfem}
   617: 

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 938)
  message: Should this be "A Posteriori Error Bound"? Follow your preferred style guide and register as an exception if necessary.
   936: 
   937: 
>  938: \subsection{A posteriori error bound}
   939: \label{sec:aposteriori}
   940: 

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 1074)
  message: Should this be "The Main Result"? Follow your preferred style guide and register as an exception if necessary.
  1072: i.e., each marked element is refined at least once. 
  1073: 
> 1074: \subsection{The main result}
  1075: \label{sec:main-result}
  1076: 

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 1106)
  message: Should this be "Sequence of Partitions"? Follow your preferred style guide and register as an exception if necessary.
  1104: 
  1105: 
> 1106: \subsection{Sequence of partitions}
  1107: \label{sec:prop-gridk}
  1108: The \ADGM produces a sequence $\{\gridk\}_{k\in\N_0}$ of nested

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 1243)
  message: Should this be "The Limit Space"? Follow your preferred style guide and register as an exception if necessary.
  1241: 
  1242: 
> 1243: \subsection{The limit space}
  1244: \label{sec:space-limit}
  1245: In this section, we shall investigate the limit of the finite element

- file: sample\arxiv_sources\1909.12665v2\ADGFEM_corrected.tex (line 1608)
  message: Should this be "Quasi-Interpolation"? Follow your preferred style guide and register as an exception if necessary.
  1606: Section~\ref{sec:quasi-ipol}.
  1607: 
> 1608: \subsection{Quasi-interpolation}
  1609: \label{sec:quasi-ipol}
  1610: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 13)
  message: Should this be "Choosing Which Engine to Use"? Follow your preferred style guide and register as an exception if necessary.
    11: 
    12: %---------------------------------------------------------------
>   13: \section{Choosing which Engine to Use}
    14: \label{sec:choose-engine}
    15: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 74)
  message: Should this be "Making the Query"? Follow your preferred style guide and register as an exception if necessary.
    72: Successful and efficient querying is the goal of this section.
    73: 
>   74: \subsection{Making the query}
    75: 
    76: \subsubsection{Copy and paste an equation from a publication}

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 152)
  message: Should this be "Easing the Search, in Results Stage"? Follow your preferred style guide and register as an exception if necessary.
   150: 
   151: 
>  152: \subsection{Easing the search, in results stage}
   153: 
   154: \subsubsection{Result as a new query}

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 44)
  message: Should this be "Complexity of Equation: a Consideration"? Follow your preferred style guide and register as an exception if necessary.
    42: Meaning-based searches, alone, can hit directly upon the deep connections which math notation hides.  In this sense, they are far more useful for branching between fields of physics and/or math, and for (eventually) algorithmically searching for patterns between the phenomena which math represents.  They help researchers to gain better understanding of what the system is actually doing, by changing the human construct imposed upon it by the math: this can help the researcher to separate the system from the mathematical formulations.
    43: 
>   44: \subsubsection{Complexity of equation: A consideration}
    45: A small experiment \cite{Pres-vs-Content-2014} found that presentation-based search engines provided better results than did meaning-based engines for the following types of equations: elementary functions (such as logarithm), and equations which have only one way of being written (excluding, for example, certain trigonometric expressions).  Special functions which have a standardized representation, such as the Legendre-Q function, were suggested to be equally well-matched by presentation-based and meaning-based search engines.  Equations which have multiple written forms were found to be better-matched by meaning-based search engines; examples include trigonometric expressions and certain special functions (e.g. Hermite-H, Poly-Gamma).
    46: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 62)
  message: Should this be "Mutli-Equation Queries: Initial Conditions Inclusion"? Follow your preferred style guide and register as an exception if necessary.
    60: In the literature, ``query variables'' is another term which is used to describe wildcards. \cite{ntcir-10-overview, Liska-PhD-Prop}
    61: 
>   62: \subsubsection{Mutli-equation queries: Initial conditions inclusion}
    63: Some search engines allow the user to search for multiple equations at once. \cite{SojkaEtAl2011, Tangent-article-2015, Tangent-pub-2015, DLMF-website}  This allows initial conditions to be added to a search, among other things.  The searched equations do not have to occur in the same portion of the paper.  As with Google, these equation-based search engines may relax the query if the equations can not be found to occur in the same document: as does MIaS \cite{SojkaEtAl2011}, they might require only one or more of the multiple query equations to be found in the paper.
    64: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 76)
  message: Should this be "Copy and Paste an Equation From a Publication"? Follow your preferred style guide and register as an exception if necessary.
    74: \subsection{Making the query}
    75: 
>   76: \subsubsection{Copy and paste an equation from a publication}
    77: If the equation query is a complex equation from an existing publication, then it is sometimes possible to access its LaTeX code.  Springer articles can be found via LaTeXSearch, with their equations listed for easy review; however, this database contains a limited number of Springer's articles, so finding the equation is hit-and-miss. \cite{Springer-LatexSearch-post, LatexSearchAbout, Springer-main-page} Another route is to download the LaTeX source code from arXiv.org, if the publication is available there.
    78: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 79)
  message: Should this be "Download Code for a Special Function"? Follow your preferred style guide and register as an exception if necessary.
    77: If the equation query is a complex equation from an existing publication, then it is sometimes possible to access its LaTeX code.  Springer articles can be found via LaTeXSearch, with their equations listed for easy review; however, this database contains a limited number of Springer's articles, so finding the equation is hit-and-miss. \cite{Springer-LatexSearch-post, LatexSearchAbout, Springer-main-page} Another route is to download the LaTeX source code from arXiv.org, if the publication is available there.
    78: 
>   79: \subsubsection{Download code for a special function}
    80: If a special function is your query, it might be found in the DLMF \cite{DLMF-website} or Wolfram Functions website \cite{WolframFunctionsWebsite}.  Both are searchable by keyword (and the DLMF is also searchable by portions of equations).
    81: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 86)
  message: Should this be "Generate Equation Code"? Follow your preferred style guide and register as an exception if necessary.
    84: Wolfram Functions allows code to be downloaded in MathML, by going to a specific formula's webpage therein.  For instance, one can search for ``gamma function'', click the results titled ``gamma function'', and in the list of its (193) formulas, click on ``primary definition''.  On the page which comes up, click the equation.  The resulting webpage has MathML code for the formula, as well as \emph{Mathematica} code. \cite{WolframFunctionsWebsite}
    85: 
>   86: \subsubsection{Generate equation code}
    87: \label{sec:template-editors}
    88: Input of an equation query is usually done in LaTeX or MathML.  Generating code in either language is simple with the aid of online template-based editors.  Drawing an equation or uploading its image are both possibilities \cite{min_Sasarak-et-al_2012}, although image upload is currently being fixed. \cite{min-developer-email}  Translators also exist between the two languages.

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 154)
  message: Should this be "Result as a New Query"? Follow your preferred style guide and register as an exception if necessary.
   152: \subsection{Easing the search, in results stage}
   153: 
>  154: \subsubsection{Result as a new query}
   155: The LaTeX text of results can be accessed in LaTeXSearch, making re-use of a result easy. \cite{LatexSearchAbout}  In addition, $m_{in}$ allows images of equations to be used as search queries \cite{Min-instructions}, making it much easier to re-use results from any search engine's query;  however, this feature is currently in-operational, and is expected to be fixed shortly \cite{min-developer-email}.  Tangent provides a direct link from each result to open its equation in $m_{in}$ (section \ref{sec:min-description}), where users can edit it via drawing or text, then generate LaTeX or MathML code. \cite{min-video}
   156: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 158)
  message: Should this be "Filter Results"? Follow your preferred style guide and register as an exception if necessary.
   156: 
   157: 
>  158: \subsubsection{Filter results}
   159: Results can be filtered or sorted by publication year, author, journal, and other subjects, in some search interfaces.
   160: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 92)
  message: Should this be "Draw Equation"? Follow your preferred style guide and register as an exception if necessary.
    90: Examples of tools are given here; they create or translate LaTeX or MathML code for equations.
    91: 
>   92: \paragraph{Draw equation}
    93: The online editor $m_{in}$ allows users to draw equations, then send them as queries to various search engines or download their code as TeX or MathML. \cite{min_Sasarak-et-al_2012} To copy the code for a drawn expression, right-click on the expression's image in the small window near the top right corner of the screen; a drop-down menu with ``save math as'' will appear. \cite{min-video}
    94: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 95)
  message: Should this be "Upload Equation's Image"? Follow your preferred style guide and register as an exception if necessary.
    93: The online editor $m_{in}$ allows users to draw equations, then send them as queries to various search engines or download their code as TeX or MathML. \cite{min_Sasarak-et-al_2012} To copy the code for a drawn expression, right-click on the expression's image in the small window near the top right corner of the screen; a drop-down menu with ``save math as'' will appear. \cite{min-video}
    94: 
>   95: \paragraph{Upload equation's image}
    96: LaTeX code can be generated from an image or PDF file of an equation.  This is not only useful for grabbing equations from academic papers, but also for extracting equations from online services such as the Wolfram (special) Functions website.
    97: 

- file: sample\arxiv_sources\1609.03457v1\guide-to-use.tex (line 102)
  message: Should this be "Template Editors"? Follow your preferred style guide and register as an exception if necessary.
   100: The web-hosted tool $m_{in}$, which has been discussed elsewhere in this document, also allows images to be uploaded for translation to LaTeX; however, that feature is under repair at the moment, and is expected to be fixed in late 2016 \cite{min-developer-email}.  Equations which are uploaded in this way enter into $m_{in}$'s drawing board, where they can be edited.  The final equation can then be sent to various math-aware search engines as a query, or its LaTeX code can be downlaoded. \cite{min_Sasarak-et-al_2012, min-video}
   101: 
>  102: \paragraph{Template editors}
   103: \textbf{LaTeX:} At least a few template-based editors are available which generate LaTeX code from a template editor.  One online version is Springer's LaTeX Sandbox. \cite{Latex-sandbox}
   104: \textbf{MathML:} A good list of equation editors and viewers (``renderers''), for MathML, is provided at \cite{MathML-tools}.  Equation editors include downloadable interfaces (such as fMath and MathMagic) and plugins (such as FireMath, a Firefox plugin). \cite{MathML-tools}  A good renderer for MathML equations, which generates a math equation image from the code, is Wolfram Research's MathML renderer. \cite{MathMLrenderWolfram}

- file: sample\arxiv_sources\2011.14059v1\DiscreteMathProg.tex (line 87)
  message: Should this be "Discrete Math With Programming: a Principled Approach"? Follow your preferred style guide and register as an exception if necessary.
    85: 
    86: 
>   87: \title{Discrete Math with Programming: A Principled Approach}
    88: 
    89: \sigcse{}

- file: sample\arxiv_sources\2011.14059v1\DiscreteMathProg.tex (line 208)
  message: Should this be "Related Work"? Follow your preferred style guide and register as an exception if necessary.
   206: 
   207: 
>  208: \section{Related work}
   209: \label{sec-related}
   210: 

- file: sample\arxiv_sources\2011.14059v1\DiscreteMathProg.tex (line 502)
  message: Should this be "Predicate Logic With Programming"? Follow your preferred style guide and register as an exception if necessary.
   500: 
   501: 
>  502: \section{Predicate logic with programming}
   503: \label{sec-logic}
   504: 

- file: sample\arxiv_sources\2011.14059v1\DiscreteMathProg.tex (line 699)
  message: Should this be "Other Topics"? Follow your preferred style guide and register as an exception if necessary.
   697: 
   698: 
>  699: \section{Other topics}
   700: \label{sec-others}
   701: 

- file: sample\arxiv_sources\2011.14059v1\DiscreteMathProg.tex (line 802)
  message: Should this be "Results, Analysis, and Adoption"? Follow your preferred style guide and register as an exception if necessary.
   800: 
   801: 
>  802: \section{Results, analysis, and adoption}
   803: \label{sec-results}
   804: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 20)
  message: Should this be "Now Available (Although They Improve With Time)"? Follow your preferred style guide and register as an exception if necessary.
    18: This section is divided into those applications which are possible now, and those which require some significant developments.  Most of the applications herein are the ideas of this author, except when noted otherwise, although it is questionable whether some of them are \emph{implied} in other publications which are cited elsewhere in this work.  Ideas included here are intended to give physicists a start of an idea on how these math-aware search engines can be used in everyday research.
    19: 
>   20: \section{Now Available (Although they improve with time)}
    21: 
    22: \subsection{Solve Math Problems}

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 27)
  message: Should this be "Design Models and Match Them With Physical Systems"? Follow your preferred style guide and register as an exception if necessary.
    25: The development of emergent theories, fundamental physics, effective theories, applied physics, experiments, and phenomenology can all benefit from such improvements.
    26: 
>   27: \subsection{Design Models and Match them with Physical Systems}
    28: Finding mathematical models which are useful for a case can be done by first coming up with a model which is reasonable but hard to solve, then researching ways to make it more tractable.  The first model which one comes up with need not, then, be the best model: searching the literature can locate refinements which make it more solvable.  This might include avoiding the equation in question by changing the modeling setup, rewriting the equation into an equivalent but manageable format, or making approximations which other researchers have found to work well.  Context will need to be considered, of course, but having this start at discovering better models is priceless.  Keyword-based search engines can help with this, but they are inherently limited by varying terminologies between fields (i.e. jargon) and the need to know what kind of systems one wants to find.  These equation-based search engines enable researchers to find mathematical models using the most appropriate language: that of math.  They already know some of the ``synonyms'' of math (such as $a+b = b+a$), and will only improve with time.
    29: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 33)
  message: Should this be "Pattern-Find Within Physics"? Follow your preferred style guide and register as an exception if necessary.
    31: Other times, we find it useful to experiment with analogous systems to ones which we can not directly observe.  For instance, an investigation occurred into Black Holes and their particle production via an analogous system: dumb holes. \cite{Unruh-Dumb-Holes}  These sound-based analogues of black holes were experimented upon to better understand and predict black holes' behaviours. \cite{Experiment-Dumb-Holes, Carroll-Dumb-Holes}  Another set of experiments has been pursued in order to explore additional fundamental predictions of quantum field theory, such as the Sauter-Schwinger effect; \cite{Schuetzhold-fund-experiments} discusses them in a colloquium.
    32: 
>   33: \subsection{Pattern-find within physics}
    34: Another application of finding analogous systems is to explore what physical theories might connect systems which are found to be analogous.  For instance, one might find patterns for merging gravitation with quantum physics, by searching physics publications for quantum or gravity equations.  While this application is limited, so far (because the math-aware search engines are not yet advanced enough to identify mathematically-equivalent notation), it still provides an excellent start.
    35: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 36)
  message: Should this be "Find a Specific Format of an Equation"? Follow your preferred style guide and register as an exception if necessary.
    34: Another application of finding analogous systems is to explore what physical theories might connect systems which are found to be analogous.  For instance, one might find patterns for merging gravitation with quantum physics, by searching physics publications for quantum or gravity equations.  While this application is limited, so far (because the math-aware search engines are not yet advanced enough to identify mathematically-equivalent notation), it still provides an excellent start.
    35: 
>   36: \subsection{Find a specific format of an equation}
    37: The form in which an equation is written can have significance.  For example, writing the Schrodinger equation as a probability current indicates that it might be under study as a fluid flow. While this particular format has a name (``probability current''), not all significant formats of equations have a name.  These un-named equations can be difficult to look up - as can some of the named ones - without knowing the jargon of the field.  Math-language search engines let researchers get around the jargon, during the search phase.
    38: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 46)
  message: Should this be "Look Up Partially-Remembered Theorems/laws"? Follow your preferred style guide and register as an exception if necessary.
    44: For now, using a search engine of this type to identify special functions is limited: it can provide a positive identification, but can not tell a researcher that a given function is \emph{not} a special function.  As math-aware search engines get better at translating between different math notations, this application will be more complete.
    45: 
>   46: \subsection{Look up partially-remembered theorems/laws}
    47: Long-ago learned equations might be remembered for their application, but the formula and name can be difficult to fully bring to mind.  If enough of an formula is remembered, it can be looked up in a math-aware search engine to (hopefully) find the full version of that formula. \cite{MWS-05-2012}
    48: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 57)
  message: Should this be "Look Up the Meaning of Unfamiliar Math Notation"? Follow your preferred style guide and register as an exception if necessary.
    55: 
    56: 
>   57: \subsection{Look up the meaning of unfamiliar math notation}
    58: Especially when doing interdisciplinary research, it is easy for a researcher to come across notation which he or she is unfamiliar with.  The context is not always explained adequately, in the text, for that researcher to easily find the notation's meaning: field's conventions and ``common knowledge'' are often not stated in publications. \cite{DavenportEtAl2003, Rec-and-retrieval-rev}  Math-aware search engines which use equations' structure (i.e. ``Presentation-based'') to search for results can be used to find more information about the unfamiliar notation.  For example, the search engine ``Tangent'' proposes this application as a use of its software for both students and researchers \cite{Tangent-thesis}; for students, they give the example that the binomial coefficient's notation ($^4_2$) could be drawn in $m_{in}$ (section \ref{sec:min-description}) and subsequently searched for \cite{Tangent-pub-2015,Wangari-et-al_2014_paper}.  For researchers, an application might be to look up why $\pi(2) = 1$, which applies when discussing the ``prime counting function''. \cite{Wangari-et-al_2014_paper}
    59: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 83)
  message: Should this be "Discover New Solution Methods via Different Equation Formats"? Follow your preferred style guide and register as an exception if necessary.
    81: As math-aware search engines are able to recognize more of math's equivalencies, this application becomes better.  However, a researcher using the present-day math-aware search engines would have a very difficult time finding these connections using them.
    82: 
>   83: \subsection{Discover new solution methods via Different Equation Formats}
    84: Writing an equation in a new way can also elucidate paths towards solving it.  A simple example of this in everyday research is the use of substitutions in integrals, or integration by parts.  Finding other researchers' writings of an equation gives the researcher an opportunity to see what other forms of writing other researchers might have found useful: it gives them direction towards finding a potential solution.
    85: 

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 90)
  message: Should this be "Speed Up Computer Programs' Run-Time"? Follow your preferred style guide and register as an exception if necessary.
    88: Improvements to this application are possible with certain feature developments in the math-aware search engine.  For instance, if the results could be \emph{ranked according to solvability} - that is, whether an equation can and/or has been solved analytically (or numerically, in an efficient manner) - then researchers could find ways of writing their equation such that solutions fall out easily.  This goes beyond \emph{Mathematica}, since even \emph{Mathematica} (and similar software) sometimes needs equations to be written in different representations in order to solve them.  Furthermore, \emph{Mathematica} can not change how the mathematical model is attached to the physical world (e.g. is $x$ the linear distance from a point, or the distance along a curved wire?), which a researcher who views equation results could do.  When a researcher searches existing models, the searcher can also see what assumptions were useful to those models, and decide whether they can apply to the system at hand; \emph{Mathematica} requires many such assumptions to be included as input to the equation.  Finding information in the literature can therefore be of benefit beyond what \emph{Mathematica}-like systems provide, for solving equations.  If these search engines could determine whether a given equation format is solvable, or read that data from the document which includes it, then finding solvable mathematical models (or just equations) in the literature becomes easier.
    89: 
>   90: \subsection{Speed up computer programs' run-time}
    91: Some analytic equations run faster than others, either due to the number of steps required to compute them or to the run-time engine's specific architecture.  As a simple example, rewriting
    92: \begin{multline}

- file: sample\arxiv_sources\1609.03457v1\physics-applications.tex (line 107)
  message: Should this be "Custom ``Alerts'' When New Publications Contain a Specific Equation"? Follow your preferred style guide and register as an exception if necessary.
   105: 
   106: 
>  107: \subsection{Custom ``alerts'' when new publications contain a specific equation}
   108: Routing of results - that is, updating users when new documents are available which includes their equation query - is one proposed use of math-aware search engines, by \cite{Youssef-Roles}.  When journal articles comprise the database, this would mean that researchers can set up ``alerts'' to be sent to them when a new article with a certain equation is published (and is indexed into the search system's database).
   109: 

- file: sample\arxiv_sources\1609.01657v1\main.tex (line 193)
  message: Should this be "The Visitors' Impressions"? Follow your preferred style guide and register as an exception if necessary.
   191: \end{figure}
   192: 
>  193: \section{The visitors' impressions} \label{sec4} Multimedia installations and interwoven threads were not the only factors of success for the first set-up of the exhibition \textit{MadeInMath}. The animators were of crucial importance because they were mediators between organizers and visitors. Master students in various degrees in science (Mathematics, Biology, Physics, etc.) have been trained on the topics covered by the exhibition to accompany the many school-groups, but also to follow individual visitors, or small groups of hesitant visitors. For animators it was undoubtedly a formative moment for their training and their personal growth. Each of them, in fact, was free to propose their reading of the contents of the exhibition because the exhibition has various interpretations and visits had different cuts. People reported that they visited it twice and had different impressions each time. The ability to create connections between seemingly unrelated issues is one of the most powerful activity of mathematics, which gave the show an edge. It was thanks to all these facets that each visitor could grasp interesting aspects depending on their age, their training and their own interests. As commented in \cite{tg} by one of the animators, Maurizio Giaffredo, each of us animators took away a wealth of meetings and reflections whose value derives from the diversity of people and ideas that we had the chance to meet. In just two weeks the exhibition was visited by over 40,000 visitors. Of these, about 18,000 were students, mostly from middle and  high school. This means that more than half of the visitors fall into the category `general public`, which was quite a success. Beyond the figures, it was impressive to experience a high level of satisfaction by visitors. An initial indicator in this regard was to see students on a visit with the class during the week and then see them again at the weekend with their parents or other friends to illustrate some of the content of the exhibition as if they were young guides. A second indicator comes from the evidence left by visitors. Let us quote some of the thousands that people delighted in leaving. One of them says: "We knew the beauty of mathematics, but we did not suspect that  it was so beautiful. Thank you also for the love and attention to the teacher's figure". In fact, part of the exhibition gave space to the admirable work done every day by teachers, in this case those of mathematics. We were particularly pleased that this aspect has been apprehended and appreciated. Further evidence comes from some foreign visitors, who wrote: "I wish I had paid more attention to math class!" indicating the fact that the exhibition has managed to somehow overcome the misconception regarding mathematics and bring in the foreground some of the fundamental aspects of the teaching of mathematics (but not only), such as curiosity, wonder and the transmission of important ideas and not only tedious techniques. In this regard, a visitor wrote that he/she discovered a new world. In this sense, the initial disorientation was overcome in an unexpected and positive way because the exhibition succeeded in unveiling the potential of mathematics, which previously seemed unattainable. Another witness is grateful for the many ideas and so many hints that would be used at school for events on the subject of mathematics. There have also been some criticism, sometimes because of the difficulty in understanding certain topics. For this, as we discussed before, the guides were really fundamental because they played a role as a cultural mediator. The comments regarding some guides have been very positive, as, for example, "The exhibition is very beautiful but the enthusiasm of our guide was exceptional". Finally, we would like to quote a comment by a visitor, probably very young, that after the visit wrote that the exhibition was better than \textit {Gardaland} (an amusement park)!
   194: 
   195: \section{Conclusions}\label{final}

- file: sample\arxiv_sources\1609.03457v1\appendix-glossary.tex (line 7)
  message: Should this be "Math-Aware Search Engine / Math-Language Search Engine"? Follow your preferred style guide and register as an exception if necessary.
     5: Terms used in this discussion of math-aware search engines are defined here.  Many of these terms are not yet set into conventions, in this field.  Some of the definitions may seem very straightforward, but can have varying definitions between and within research fields.
     6: 
>    7: \paragraph{Math-Aware Search Engine / Math-language search engine}
     8: A software which searches a database of mathematical texts, using a mathematical equation as at least part of its search query.  It accounts, at least partially, for the mathematical equivalencies between different writings of equations.
     9: 

- file: sample\arxiv_sources\1609.03457v1\appendix-glossary.tex (line 16)
  message: Should this be "Equation Match"? Follow your preferred style guide and register as an exception if necessary.
    14: A collection of data.  For equation-based search engines, it might consist of journal articles, wikis, forums, encyclopedias, or other documents.
    15: 
>   16: \paragraph{Equation match}
    17: An equation which matches another equation, within the search engines criteria.  For example, the following equations might match: $a x+5 = b$, and $s x + 5 = t$.
    18: 

- file: sample\arxiv_sources\1609.03457v1\appendix-glossary.tex (line 22)
  message: Should this be "Rank of a Result"? Follow your preferred style guide and register as an exception if necessary.
    20: The items from the database (e.g. equations, pieces of text) which match the search query given the algorithms of the search engine.
    21: 
>   22: \paragraph{Rank of a result}
    23: The relevance of a database equation, relative to the query.  It is described by a number. Results with a higher rank are located higher in the list of results. \cite{Guidi-Cohen-2015, Tangent-pub-2015, SojkaEtAl2011,  Rec-and-retrieval-rev}
    24: 

- file: sample\arxiv_sources\1609.03457v1\appendix-glossary.tex (line 28)
  message: Should this be "Meaning-Based Search"? Follow your preferred style guide and register as an exception if necessary.
    26: Pieces of a formula.  For example, $a+b^{2+c}$ has two subformulae: $b^{2+c}$ and $2+c$.  The expression $a+b^{2+c}$ is itself a subformula of $2 / (a+b^{2+c})$. \cite{Oviedo-Th, SojkaEtAl2011}
    27: 
>   28: \paragraph{Meaning-based search}
    29: Searches based on the true mathematical meaning of an equation, with the goal of identifying all equations which have equivalent or similar meanings to the query equation.  For example, the meaning of $\sinh(x)$ and $(1/2)(e^z-e^{-z})$ are equal.  \cite{Guidi-Cohen-2015}  Meaning-based search engines which are now web-ready obtain only part of this goal, but they do account for some mathematical meaning. \cite{Pres-vs-Content-2014, MWS-05-2012, AizawaEtAl2014}
    30: 

- file: sample\arxiv_sources\1609.03457v1\appendix-glossary.tex (line 31)
  message: Should this be "Presentation-Based Search"? Follow your preferred style guide and register as an exception if necessary.
    29: Searches based on the true mathematical meaning of an equation, with the goal of identifying all equations which have equivalent or similar meanings to the query equation.  For example, the meaning of $\sinh(x)$ and $(1/2)(e^z-e^{-z})$ are equal.  \cite{Guidi-Cohen-2015}  Meaning-based search engines which are now web-ready obtain only part of this goal, but they do account for some mathematical meaning. \cite{Pres-vs-Content-2014, MWS-05-2012, AizawaEtAl2014}
    30: 
>   31: \paragraph{Presentation-based search}
    32: Bases search results on the visual appearance of an equation.  For example, $1 + x^2$ is visually different from $x^2 + 1$.  The equations $1+ x^2 /2$ and $1+ y^2 /2$ match visually, so would count as similar equations in a presentation-based search.  Some presentation-based search engines account for algebraic rearrangement of terms (e.g., $1 + x^2$ versus $x^2 + 1$), and others do not. \cite{Tangent-technical-v0.3, TangentSE, Liska-Th, Pres-vs-Content-2014}

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 27)
  message: Should this be "Database Coverage"? Follow your preferred style guide and register as an exception if necessary.
    25: 
    26: 
>   27: \section{Database coverage}
    28: 
    29: Academic papers (such as journal articles), a curated encyclopedia, Wikipedia, and mathematics forums are all accessible via math-aware search engines. \cite{Springer-LatexSearch-post, EuDML-web-base, zbMath-database-about, Weisstein-Alpha, dprl-descriptions, uniquationWeb}

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 38)
  message: Should this be "Extent of Abilities to: Extract Math In-Context"? Follow your preferred style guide and register as an exception if necessary.
    36: 
    37: 
>   38: \section{Extent of abilities to: extract math in-context}
    39: \label{sec:extent-abilities-extract-math-in-context}
    40: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 57)
  message: Should this be "Extent of Abilities to: Match Formulae"? Follow your preferred style guide and register as an exception if necessary.
    55: 
    56: 
>   57: \section{Extent of abilities to: match formulae}
    58: \label{sec:math-meaning-limitations}
    59: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 67)
  message: Should this be "Mathematical Meaning-Based Comparisons"? Follow your preferred style guide and register as an exception if necessary.
    65: 
    66: 
>   67: \subsection{Mathematical meaning-based comparisons}
    68: 
    69: Meaning-based search algorithms attempt to find equations which math the mathematical meaning of the searched-for (``queried'') equation. \cite{Pres-vs-Content-2014, Liska-PhD-Prop, MWS-05-2012} Each uses a different approach, and all fall short of being able to fully identify mathematical equivalencies given different writings of the math (including Wolfram Alpha).  Nevertheless, they are able to identify mathematical equivalencies to varying degrees.

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 118)
  message: Should this be "Presentation-Based (Structural) Comparisons"? Follow your preferred style guide and register as an exception if necessary.
   116: 
   117: 
>  118: \subsection{Presentation-based (Structural) Comparisons}
   119: 
   120: These engines find equations which are structurally similar to the query.  The results retrieved might differ from the query by changed variable names; added, dropped, or re-arranged terms; subexpressions substituted for variables; or other visual-based criteria. \cite{DLMF-AMS-notice, Liska-PhD-Prop, Tangent-technical-v0.3}

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 168)
  message: Should this be "Field's Identified Directions"? Follow your preferred style guide and register as an exception if necessary.
   166: Ideas of this author's, which are specific to physics applications, are also included for discussion and/or development.
   167: 
>  168: \subsection{Field's identified directions}
   169: 
   170: \subsubsection{Algorithms for Search}

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 187)
  message: Should this be "New Tools Proposed by Developers"? Follow your preferred style guide and register as an exception if necessary.
   185: 
   186: 
>  187: \subsection{New tools proposed by developers}
   188: 
   189: Developers have proposed a few tools which use the math-aware search engines, or similar algorithms.

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 173)
  message: Should this be "Database Expansion"? Follow your preferred style guide and register as an exception if necessary.
   171: Field experts have indicated that more of the search engines need to focus on extracting mathematical meaning (including context and symbols' meanings) from documents. \cite{AizawaEtAl2014} Algorithms with which to extract theorems from publications, and to restrict searches to formulas which are consistent with a query's mathematical assumptions, are also desired. \cite{MWS-05-2012}  It is being explored to allow the user to define which parts of a formula should be kept fixed, when searching for results, and which are allowed to bring up ``similar'' results (see ``simto'' regions, \cite{ntcir12mathIR}).  There is also work being done to improve the identification of equations which share the same mathematical meaning, but are written differently. \cite{Liska-PhD-Prop, Oviedo-Th} Precision of results and recall speeds are other areas of improvement; the recall speed is only a few seconds at most, but that is still slower than standard text-based search engines.  \cite{Guidi-Cohen-2015} Unbiased evaluation metrics are also recommended, to allow rigorous comparison of the math-aware search engines. \cite{Guidi-Cohen-2015} Finally, scalability is a target area of advancement, with the eventual goal of covering the entire web. \cite{Tangent-pub-2015}
   172: 
>  173: \subsubsection{Database expansion}
   174: 
   175: Future databases are planned to include the arXiv \cite{liskaEtAl2015ComboTF, MathWebSearch-info}, the digital math library DML-CZ \cite{WebMIaS-descr-pub-2014}, and other added journal articles \cite{WebMIaS-descr-pub-2014, RakosnikEtAl2014}.  The DLMF is also exploring ways to improve or enlarge their special function content (for which they are soliciting community feedback - see ``news'' section of \cite{DLMF-website}). Formalized math libraries (e.g. Mizar) and theorem proving libraries (e.g. Thousands of Problems for Theorem Proving) are also having math-aware search added to them. \cite{MWS-05-2012}

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 182)
  message: Should this be "User Experience"? Follow your preferred style guide and register as an exception if necessary.
   180: 
   181: 
>  182: \subsubsection{User experience}
   183: The user-experience is another focus in development.  This includes re-visiting the subjective rules for which results are presented at the top of the results list, as well as the appearance of the results. \cite{AizawaEtAl2014} Other considerations include ease of use and learning curve. \cite{AizawaEtAl2014}
   184: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 191)
  message: Should this be "Alerts for New Publications Containing a Specific Equation"? Follow your preferred style guide and register as an exception if necessary.
   189: Developers have proposed a few tools which use the math-aware search engines, or similar algorithms.
   190: 
>  191: \subsubsection{Alerts for new publications containing a specific equation}
   192: Routing of results - that is, updating users when new documents are available which includes their equation query - is one proposed use of math-aware search engines, by \cite{Youssef-Roles}.  When journal articles comprise the database, this would mean that researchers can set up ``alerts'' to be sent to them when a new article with a certain equation is published (and is indexed into the search system's database).
   193: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 194)
  message: Should this be "New Kind of Search: Use Diagrams"? Follow your preferred style guide and register as an exception if necessary.
   192: Routing of results - that is, updating users when new documents are available which includes their equation query - is one proposed use of math-aware search engines, by \cite{Youssef-Roles}.  When journal articles comprise the database, this would mean that researchers can set up ``alerts'' to be sent to them when a new article with a certain equation is published (and is indexed into the search system's database).
   193: 
>  194: \subsubsection{New kind of search: Use Diagrams}
   195: The group \cite{Tangent-pub-2015} want to enable search queries to contain diagrams, as well as text and equations.
   196: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 201)
  message: Should this be "Rank According to Solvability"? Follow your preferred style guide and register as an exception if necessary.
   199: \subsection{For Physics: Ideas for Useful Directions}
   200: 
>  201: \subsubsection{Rank according to Solvability}
   202: When using these search engines to solve equations, it would be a big help if results were ranked according to whether the equation therein had been solved (exactly or approximately), and how quick it is to solve (computationally or by a skilled mathematician).
   203: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 206)
  message: Should this be "Downloading Results for Post-Processing"? Follow your preferred style guide and register as an exception if necessary.
   204: Doing so would require first obtaining this information, likely by adding a step to the pre-processing of documents in these databases.  One possible, but probably time-intensive, way to do so would simply be to attempt to solve every one of the database documents' equations in Mathematica, or a similar program.  However, the choice of input parameters would need to be decided upon.  Even an approximate measure of how solvable an equation is would - in general - be better than having a list of unranked equation search results.  Another possible method is to try to extract the information about an equation's solvability from the text or equations of any document which contains that exact written form of the equation; this includes searching mathematical encyclopedias, educational resources, and any other available documents.  This, too, would require a lot of development to be fully implemented.
   205: 
>  206: \subsubsection{Downloading results for post-processing}
   207: None of the search engines allow users to download search results, so that post-processing of equations may occur.
   208: 

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 217)
  message: Should this be "Computational Speedup: Replace Slow Equations as They Occur"? Follow your preferred style guide and register as an exception if necessary.
   215: 
   216: 
>  217: \subsubsection{Computational speedup: replace slow equations as they occur}
   218: \label{sssec:comp-speedup-future-dev}
   219: Some computations can be done analytically, using Mathematica or similar software.  (Which ones can be done this way is limited by the computation time and ability of the software platform.)  Computations which are done this way often produce secondary equations during run-time: that is, they combine or solve a set of equations, then try to combine it with a second set of equations.  One of the secondary equations can slow down the program's run-time enough that it becomes impractical.  If that equation can be replaced, during run-time, with a faster-solving rewriting of it, then the problem of its slow-down can be fixed.  That replacement could be done by making a run-time call to a ``search engine'' for math equations, which obtains a faster-solving mathematical representation for the problematic equation.

- file: sample\arxiv_sources\1609.03457v1\extent-abilities.tex (line 225)
  message: Should this be "Algorithmically Search for Patterns, to Help Direct New Research"? Follow your preferred style guide and register as an exception if necessary.
   223: Note that this application requires one or both of the above proposed applications to be done.
   224: 
>  225: \subsubsection{Algorithmically search for patterns, to help direct new research}
   226: 
   227: Already done in Mathematics, this application involves algorithmically predicting ``probable links'' between known concepts using their mathematical relations, axioms, etc.  These links can then be investigated, and used to help direct new cutting-edge research. \cite{NevzorovaEtAl2014} 

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 201)
  message: Should this be "Group Theoretical Formulation of SLEs"? Follow your preferred style guide and register as an exception if necessary.
   199: 
   200: %group_theoretical
>  201: \section{Group theoretical formulation of SLEs}
   202: \label{sect:group_theoretical}
   203: In this section, we recall the group theoretical formulation of {{SLEs}} corresponding to the Virasoro algebra {{originally proposed}} by Bauer and Bernard.\cite{BauerBernard2002, BauerBernard2003a,BauerBernard2003b}

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 587)
  message: Should this be "Affine Lie Algebras and Their Representations"? Follow your preferred style guide and register as an exception if necessary.
   585: 
   586: %affine_lie_algebra
>  587: \section{Affine Lie algebras and their representations}
   588: \label{sect:rep_aff_alg}
   589: In this section, we recall the notion of affine Lie algebras and their representation theory.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 666)
  message: Should this be "Internal Symmetry"? Follow your preferred style guide and register as an exception if necessary.
   664: 
   665: %internal_symmetry
>  666: \section{Internal symmetry}
   667: \label{sect:internal_symmetry}
   668: We again assume that $\mfrak{g}$ is a {{finite-dimensional}} complex Lie algebra that is simple or commutative.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 864)
  message: Should this be "Construction of a Random Process"? Follow your preferred style guide and register as an exception if necessary.
   862: 
   863: %random_process
>  864: \section{Construction of a random process}
   865: \label{sect:random_process}
   866: In this section, we construct a random process on the {{infinite-dimensional}} Lie group $\mrm{Aut}_{+}\mcal{O}\ltimes G_{+}(\mcal{O})$,

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1004)
  message: Should this be "Annihilating Operator of a Highest Weight Vector"? Follow your preferred style guide and register as an exception if necessary.
  1002: 
  1003: %annihilating_operator
> 1004: \section{Annihilating operator of a highest weight vector}
  1005: \label{sect:annihilator}
  1006: We have assumed in Sect.\ref{sect:random_process} that the highest weight vector $v_{\Lambda}$ of $L_{\mfrak{g}}(\Lambda,k)$

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1104)
  message: Should this be "Local Martingales"? Follow your preferred style guide and register as an exception if necessary.
  1102: 
  1103: %local_martingale
> 1104: \section{Local martingales}
  1105: As an application of construction of a random process $\scr{G}_{t}$ on an {{infinite-dimensional}} Lie group presented in Sect. \ref{sect:random_process},
  1106: we compute several local martingales associated with the solution of {{SLEs}} with internal degrees of freedom

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1306)
  message: Should this be "Symmetry of the Space of Local Martingales"? Follow your preferred style guide and register as an exception if necessary.
  1304: 
  1305: %symmetry
> 1306: \section{Symmetry of the space of local martingales}
  1307: \label{sect:affine_symmetry}
  1308: In the previous section, we saw that a local martingale $\scr{G}_{t}\ket{v_{\Lambda}}$ that takes its value in $\overline{L_{\mfrak{sl}_{2}}(\Lambda,k)}$

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1824)
  message: Should this be "Ito Process on a Lie Group"? Follow your preferred style guide and register as an exception if necessary.
  1822: 
  1823: %app_ito_process
> 1824: \section{Ito process on a Lie group}
  1825: \label{sect:app_ito_lie_group}
  1826: This appendix is devoted to a short description of Ito processes on Lie groups.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 206)
  message: Should this be "Virasoro Algebra and Its Representations"? Follow your preferred style guide and register as an exception if necessary.
   204: The main purpose of this section is to introduce the {{infinite-dimensional}} Lie group $\mrm{Aut}_{+}\mcal{O}$ and a random process on it.
   205: 
>  206: \subsection{Virasoro algebra and its representations}
   207: Virasoro algebra is an {{infinite-dimensional}} Lie algebra $\mrm{Vir}=\bigoplus_{n\in\mbb{Z}}\mbb{C}L_{n}\oplus\mbb{C}C$
   208: with Lie brackets defined by

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 251)
  message: Should this be "Conformal Transformation"? Follow your preferred style guide and register as an exception if necessary.
   249: It is {{well known}} that such a bilinear form uniquely exists under the normalization $\braket{c,h|c,h}=1$.
   250: 
>  251: \subsection{Conformal transformation}
   252: Here we review how to implement a conformal transformation as an operator on a VOA or its module following {{Frenkel and Ben-Zvi}}.\cite{FrenkelBen-Zvi2004}
   253: Let $\mcal{O}=\mbb{C}[[w]]=\varprojlim \mbb{C}[w]/(w^{n})$ be a complete topological $\mbb{C}$-algebra and $D=\mrm{Spec}\mcal{O}$ be the formal {{disk}}.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1502)
  message: Should this be "Acknowledgements"? Follow your preferred style guide and register as an exception if necessary.
  1500: when we do not know they have a good Lie subalgebra.
  1501: 
> 1502: \subsection*{acknowledgements}
  1503: The author is grateful to K. Sakai for leading him to this field of research,
  1504: and to R. Sato for discussions and helpful advice.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1518)
  message: Should this be "Definition of Vertex Algebras, Modules and Intertwining Operators"? Follow your preferred style guide and register as an exception if necessary.
  1516: The appendix of the book by Iohara and Koga\cite{IoharaKoga2011} is also useful.
  1517: 
> 1518: \subsection{Definition of vertex algebras, modules and intertwining operators}
  1519: Let $V$ be a vector space.
  1520: A field on $V$ is a series $a(z)=\sum_{n\in\mathbb{Z}}a_{(n)}z^{-n-1}$ in a formal variable $z$ with coefficients $a_{(n)}$ being in $\mathrm{End}(V)$

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1800)
  message: Should this be "Frenkel-Kac Construction"? Follow your preferred style guide and register as an exception if necessary.
  1798: It is also clear that $V_{L+\varpi}$ depends only on the equivalence class $[\varpi]$ of $\varpi$ in $L^{\ast}/L$.
  1799: 
> 1800: \subsection{Frenkel-Kac construction}
  1801: \label{subsect:app_frenkel_kac}
  1802: One of the most significant examples of lattice vertex algebras is one associated with a root lattice of ADE type,

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1661)
  message: Should this be "Virasoro Vertex Algebra"? Follow your preferred style guide and register as an exception if necessary.
  1659: 
  1660: \subsection{Examples}
> 1661: \subsubsection{Virasoro vertex algebra}
  1662: In Sect. \ref{sect:group_theoretical}, we have introduced two types of representations of the Virasoro algebra,
  1663: Verma modules and their simple quotients.

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1704)
  message: Should this be "Affine Vertex Algebra"? Follow your preferred style guide and register as an exception if necessary.
  1702: \end{equation}
  1703: 
> 1704: \subsubsection{Affine vertex algebra}
  1705: Representations $\what{L(0)}_{k}$ and $L_{\mfrak{g},k}$ of an affine Lie algebra $\what{\mfrak{g}}$ introduced in Sect.\ref{sect:rep_aff_alg}
  1706: are also equipped with VOA structure by the following data:

- file: sample\arxiv_sources\1803.06808v3\SLE_martingale_arXiv.tex (line 1725)
  message: Should this be "Lattice Vertex Algebra"? Follow your preferred style guide and register as an exception if necessary.
  1723: \end{thm}
  1724: 
> 1725: \subsubsection{Lattice vertex algebra}
  1726: Let $L$ be a nondegenerate even lattice of rank $\ell$; namely, it is a free $\mbb{Z}$-module of rank $\ell$
  1727: endowed with a nondegenerate $\mbb{Z}$-bilinear form $(\cdot|\cdot):L\times L\to \mbb{Z}$,

- file: sample\arxiv_sources\1710.03835v3\sle_wzw_corresp_arxiv_ver3.tex (line 146)
  message: Should this be "Affine Lie Algebras and WZW Theories"? Follow your preferred style guide and register as an exception if necessary.
   144: 
   145: %Section: wzw_ theory
>  146: \section{Affine Lie algebras and WZW theories}
   147: \label{sect:wzw_theory}
   148: Let $\mfrak{g}$ be a finite-dimensional simple Lie algebra.

- file: sample\arxiv_sources\1710.03835v3\sle_wzw_corresp_arxiv_ver3.tex (line 294)
  message: Should this be "Ito Process on a Lie Group"? Follow your preferred style guide and register as an exception if necessary.
   292: The multiplet of them is regarded as an $L(\Lambda)^{\ast}\otimes \mrm{End}(V_{\mfrak{g},k})$-valued field.
   293: %Section: ito_process
>  294: \section{Ito process on a Lie group}
   295: \label{sect:Ito_process}
   296: In this section, we formally introduce an Ito process on a Lie group, which is needed in the following.

- file: sample\arxiv_sources\1710.03835v3\sle_wzw_corresp_arxiv_ver3.tex (line 441)
  message: Should this be "Derivations of Stochastic Differential Equations"? Follow your preferred style guide and register as an exception if necessary.
   439: 
   440: %SDE
>  441: \section{Derivations of stochastic differential equations}
   442: \label{sect:sde}
   443: Let $\{X_{r}\}_{r\in I_{\mfrak{g}}}$ be an orthonormal basis of $\mfrak{g}$

- file: sample\arxiv_sources\1710.03835v3\sle_wzw_corresp_arxiv_ver3.tex (line 527)
  message: Should this be "Null Vectors and Martingale Conditions"? Follow your preferred style guide and register as an exception if necessary.
   525: 
   526: %null vectors
>  527: \section{Null vectors and martingale conditions}
   528: \label{sect:null_vectors}
   529: For a certain vector $w\in (L_{\mfrak{g},k}(\Lambda))_{h_{\Lambda}}$, $\scr{G}_{t}w$ is an Ito process on the representation $L_{\mfrak{g},k}(\Lambda)$.

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 48)
  message: Should this be "The Determined Property of Baire in Reverse Math"? Follow your preferred style guide and register as an exception if necessary.
    46: 
    47: 
>   48: \title{The determined property of Baire in reverse math}
    49: 
    50: 

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 1103)
  message: Should this be "Completely Determined Borel Codes"? Follow your preferred style guide and register as an exception if necessary.
  1101: $$X \text{ is $\Delta^1_1(Z)$-generic } \iff \forall Y \in \Delta^1_1(Z) [ X \text{ is 1-generic relative to $Y$}].$$
  1102: 
> 1103:  \section{Completely determined Borel codes}
  1104: 
  1105: We propose the following variation on the definition of a Borel code.  We

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 1670)
  message: Should this be "Decorating Trees"? Follow your preferred style guide and register as an exception if necessary.
  1668:   
  1669: 
> 1670: \section{Decorating trees}
  1671: 
  1672: In order to show that $\DPB$ is strictly stronger than

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 2316)
  message: Should this be "Application to the Borel Dual Ramsey Theorem"? Follow your preferred style guide and register as an exception if necessary.
  2314: 
  2315: 
> 2316: \section{Application to the Borel dual Ramsey theorem}\label{sec:bdrt}
  2317: 
  2318: As an application of Theorem \ref{thm:1}, we identify a natural 

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 266)
  message: Should this be "Notation, Borel Sets and Borel Codes"? Follow your preferred style guide and register as an exception if necessary.
   264: 
   265: \section{Preliminaries}
>  266: \subsection{Notation, Borel sets and Borel codes}
   267: 
   268: We typically denote elements of $\omega^{<\omega}$ by $\sigma, \tau$ 

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 312)
  message: Should this be "Reverse Mathematics"? Follow your preferred style guide and register as an exception if necessary.
   310: with two elements, context will make it clear which type is meant.
   311: 
>  312: \subsection{Reverse mathematics}
   313: 
   314: We assume the reader is familiar with the program of reverse

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 358)
  message: Should this be "Ordinal Notations and Pseudo-Ordinals"? Follow your preferred style guide and register as an exception if necessary.
   356: reviewed in the next section.
   357: 
>  358: \subsection{Ordinal notations and pseudo-ordinals}
   359: 
   360: We assume the reader is familiar with ordinal notations

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 495)
  message: Should this be "Alternating and Ranked Trees"? Follow your preferred style guide and register as an exception if necessary.
   493: believes all pseudo-ordinals are ordinals.  
   494: 
>  495: \subsection{Alternating and ranked trees}\label{sec:breakapart}
   496: 
   497: The following definition of a ranking for a tree is looser 

- file: sample\arxiv_sources\1809.03940v3\DPBpaper.tex (line 569)
  message: Should this be "Borel Sets in Reverse Mathematics"? Follow your preferred style guide and register as an exception if necessary.
   567: 
   568: 
>  569:   \subsection{Borel sets in reverse mathematics}
   570: 
   571: In reverse mathematics, open subsets of $2^\omega$ 

- file: sample\arxiv_sources\2103.03874v2\6-appendix.tex (line 139)
  message: Should this be "Results With the BART Architecture"? Follow your preferred style guide and register as an exception if necessary.
   137: \end{figure*}
   138: 
>  139: \subsection{Results with the BART Architecture}
   140: We use BART \citep{Lewis2020BARTDS} to determine whether other existing architectures can improve performance.
   141: In the main paper we analyzed the performance of various GPT models, which are unidirectional decoder models. 

- file: sample\arxiv_sources\2103.12048v3\99_appendix.tex (line 316)
  message: Should this be "Training and Method Details"? Follow your preferred style guide and register as an exception if necessary.
   314: We used the implementation in  sklearn. In python, the code is: \texttt{`from sklearn.metrics import f1\_score}'
   315: 
>  316: \paragraph{Training and Method details}
   317: The \textbf{GCN} input features are  $768$-dimensional, and its hidden states are $100$ dimensional, and the number of convolutional layers is $3$. 
   318: 

- file: sample\arxiv_sources\2103.12048v3\main.tex (line 141)
  message: Should this be "Extracting the Unknown From  Long Math Problems"? Follow your preferred style guide and register as an exception if necessary.
   139: 
   140: 
>  141: \title{Extracting the Unknown from  Long Math Problems}
   142: 
   143: \author{Ndapa Nakashole \\

- file: sample\arxiv_sources\2103.12048v3\5_experiments.tex (line 18)
  message: Should this be "Methods Under Comparison."? Follow your preferred style guide and register as an exception if necessary.
    16: 
    17: % \textsuperscript{\ref{notetrain}
>   18: \paragraph{Methods under Comparison.}Next to each learning method is the number of  parameters.
    19: 1)~\textbf{Majority.}~Assigns the most common label, $p_{u}=0$ to every sentence. 
    20: 2-4)~\textbf{$\bm n$-th Sentence}~assigns  $p_{u}=1$ to the $\bm n$-th sentence, and  $p_{u}=0$ to all others.

- file: sample\arxiv_sources\2310.09590v2\Pseudo-Dual.tex (line 56)
  message: Should this be "Solving Math Word Problems With Reexamination"? Follow your preferred style guide and register as an exception if necessary.
    54: 
    55: 
>   56: \title{Solving Math Word Problems with Reexamination}
    57: 
    58: 

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 79)
  message: Should this be "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter With Code-Based Self-Verification"? Follow your preferred style guide and register as an exception if necessary.
    77: 
    78: \newcommand{\gptcode}{GPT4-Code}
>   79: \title{Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification}
    80: % \title{Solving Challenging Math word problems Using GPT-4 Code Interpreter with Code-based Self-Verification}
    81: % \title{Achieving 84\% Accuracy on the MATH dataset with \mbox{GPT-4}  Code Interpreter Code-based \mbox{Self-Verification}}

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 80)
  message: Should this be "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter With Code-Based Self-Verification"? Follow your preferred style guide and register as an exception if necessary.
    78: \newcommand{\gptcode}{GPT4-Code}
    79: \title{Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification}
>   80: % \title{Solving Challenging Math word problems Using GPT-4 Code Interpreter with Code-based Self-Verification}
    81: % \title{Achieving 84\% Accuracy on the MATH dataset with \mbox{GPT-4}  Code Interpreter Code-based \mbox{Self-Verification}}
    82: %  \title{Exploring the Mathematical Reasoning Ability of \\GPT-4 Code Interpreter}

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 402)
  message: Should this be "Related Work"? Follow your preferred style guide and register as an exception if necessary.
   400: 
   401: 
>  402: \section{Related work}
   403: 
   404: 

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 476)
  message: Should this be "Explicit Code-Based Self-Verification Prompting"? Follow your preferred style guide and register as an exception if necessary.
   474: \end{figure}
   475: 
>  476: \subsection{Explicit Code-based Self-verification Prompting}
   477: \label{proposed method}
   478: 

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 479)
  message: Should this be "Explicit Code-Based Self-Verification Prompting"? Follow your preferred style guide and register as an exception if necessary.
   477: \label{proposed method}
   478: 
>  479: %\subsection{Explicit Code-based Self-verification Prompting}
   480: 
   481: Inspired by the observations on Code Usage Frequency analysis, we seek to harness the capabilities of \gptcode. These capabilities include the model's aptitude for generating accurate code, evaluating the outcomes of code execution, and automatically adjusting reasoning steps of solutions when needed. However, despite these advantages, \gptcode~currently falls short in assuring solution correctness. Consequently, our objective is to utilize these strengths to augment solution verification.

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 683)
  message: Should this be "Performance on Other Datasets"? Follow your preferred style guide and register as an exception if necessary.
   681:  \end{table}
   682: 
>  683: \subsection{Performance on other datasets}
   684: 
   685: 

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 749)
  message: Should this be "Code Usage Frequency of Proposed Prompts"? Follow your preferred style guide and register as an exception if necessary.
   747: 
   748: 
>  749: \subsection{Code usage frequency of proposed prompts}
   750: 
   751: Analogous to the approach taken in Sec.~\ref{pilot-experiments}, we gather data to elucidate the correlation between accuracy and Code Usage Frequency across various dimensions - prompts (proposed CSV prompt as well as prompts used in pilot experiments), subjects, and difficulty levels. As shown in Fig.~\ref{fig:code-frequency}, 

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 830)
  message: Should this be "Detailed Experiment Result on MATH Dataset"? Follow your preferred style guide and register as an exception if necessary.
   828: \section{Experiment Details}
   829: 
>  830: \subsection{Detailed experiment result on MATH dataset}
   831: \subsubsection{Confusion Matrix}
   832: \label{sec:conf}

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 905)
  message: Should this be "Detailed Experiment Result on MMLU Dataset"? Follow your preferred style guide and register as an exception if necessary.
   903: 
   904: 
>  905: \subsection{Detailed experiment result on MMLU dataset}
   906: 
   907: Fig.~\ref{fig:mmlu} illustrates that \gptcode~performs relatively poorly in certain domains, such as engineering and the humanities, with a particularly marked deficiency in virology, where it achieves a score of less than 60\%. These observations delineate specific areas that call for further investigation and refinement, thus outlining the direction for future improvements in the model.

- file: sample\arxiv_sources\2308.07921v1\iclr2023_conference.tex (line 878)
  message: Should this be "Python Package Usage Analysis"? Follow your preferred style guide and register as an exception if necessary.
   876: 
   877: 
>  878: \subsubsection{Python package usage analysis}
   879: 
   880: Tab.~\ref{tab:pythonpack} outlines the usage of various Python packages in our experiments. Among them, we found that the \texttt{sympy} package is utilized most frequently, highlighting its central role in the computational tasks performed.

- file: sample\arxiv_sources\2312.01661v2\editchatgpt.tex (line 2)
  message: Should this be "Dataset Post-Editing"? Follow your preferred style guide and register as an exception if necessary.
     1: \begin{table*}[]
>    2: \section{Dataset Post-editing}
     3: \label{daposedit}    
     4:     

- file: sample\arxiv_sources\2312.01661v2\gpt2.tex (line 1)
  message: Should this be "Nonsensical Questions Generated by GPT-2 Fine-Tuned Model"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Nonsensical questions generated by GPT-2 fine-tuned model} 
     2: Many questions generated by GPT-2 contains non alphabetical tokens, and most questions generated are "combination of words" instead of actually meaningful questions. We provide some examples in \Cref{tab:gpt2-trash}. 
     3: 

- file: sample\arxiv_sources\2401.03238v1\Using_Large.tex (line 99)
  message: Should this be "Related Work"? Follow your preferred style guide and register as an exception if necessary.
    97: Recent advances in LLMs offer a host of possibilities aimed to enhance learning, including furnishing explanatory feedback to learners \citep{dai2023can}, with prompt engineering of models leaning towards more of an art than a science \citep{wei2022chain}. Among these, Generative Pre-trained Transformer (GPT) models, particularly the latest iteration, GPT-4, exhibits notable improvements over GPT-3.5. GPT-4 excels in tackling more complex tasks, learns faster, and demonstrates reduced potential for biased or offensive responses \citep{openai}. However, it suffers from slower response and generation times, presenting a notable challenge in handling large transcriptions. Despite its advancements, GPT-4 comes at a considerably higher cost of \$0.03/1K tokens compared to GPT-3.5, which costs \$0.0015/1K tokens for input, marking a 20-fold increase in expense \citep{openai}. Considering the speed and cost-effectiveness of GPT-3.5, our focus lies in evaluating its suitability for assessing tutor performance in practical, real-world tutoring settings. To this end, we aim to investigate the following research questions: \textbf{RQ1}: Can large language models accurately assess components of effective human tutors responses to students making errors? \textbf{RQ2}: What is the comparative accuracy and performance between GPT-3.5-Turbo and GPT-4 in assessing tutoring dialogues for how tutors respond to students making errors? 
    98: %\SetSinglespace{}
>   99: \section{Related work}
   100: % \begin{Related work}
   101: Human tutors are particularly effective when trained on building relationships and fostering rapport with students \citep{marshall2021national}. The online tutor lesson \textit{Reacting to Errors} (Appendix A) is an inspiration for this work \citep{thomas2023tutor}. In this brief, scenario-based lesson, tutors practice responding to a student who has made a math mistake. \textit{Reacting to Errors} and the associated criteria for responding to the student are described.  

- file: sample\arxiv_sources\2401.03238v1\Using_Large.tex (line 195)
  message: Should this be "Figure 1: Scenario From Reacting to Errors Lesson"? Follow your preferred style guide and register as an exception if necessary.
   193: 
   194: 
>  195: \section{Figure 1: Scenario from Reacting to Errors Lesson}\label{apd:first}
   196: 
   197: \begin{figure}[htbp] % [htbp] specifies the preferred placement (here: "here," "top," "bottom," "page")

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 154)
  message: Should this be "Pre-Training"? Follow your preferred style guide and register as an exception if necessary.
   152: InternLM-Math achieves state-of-the-art few-shot performances on MiniF2F \citep{zheng2021minif2f} which shows potential in building a strong math prover.
   153: 
>  154: \section{Pre-training}
   155: 
   156: In this section, we first describe our pre-training data composition. Then, we outline our data post-processing method we perform on the training data. Finally, we dive into the details of our training strategy.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 228)
  message: Should this be "Supervised Fine-Tuning"? Follow your preferred style guide and register as an exception if necessary.
   226: \end{figure}
   227: 
>  228: \section{Supervised Fine-tuning}
   229: Dislike other math-specialized LLMs that focus on solving math problems, our models are targeted to be math solvers and also be ready for self-improving which requires abilities including problem augmentation, reward modeling, self-verifying, formal reasoning, and code interpreters. 
   230: Our SFT data contains high-quality human-written, rule-generated, and LLM-generated data for the abovementioned abilities,

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 897)
  message: Should this be "Detailed Performance on MATH Benchmark"? Follow your preferred style guide and register as an exception if necessary.
   895: 
   896: 
>  897: \section{Detailed performance on MATH benchmark}
   898: We list detailed performance on the MATH benchmark in Table~\ref{tab:category} and Table~\ref{tab:diffculty}.
   899: We list reranking performance on GSM8K and MATH in Table~\ref{tab:rm_rerank}.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 981)
  message: Should this be "Case Studies"? Follow your preferred style guide and register as an exception if necessary.
   979: 
   980: 
>  981: \section{Case studies}
   982: We list cases generated by InternLM-Math-7B.
   983: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 158)
  message: Should this be "Pretrain Data Composition"? Follow your preferred style guide and register as an exception if necessary.
   156: In this section, we first describe our pre-training data composition. Then, we outline our data post-processing method we perform on the training data. Finally, we dive into the details of our training strategy.
   157: 
>  158: \subsection{Pretrain data composition}
   159: 
   160: To achieve a competitive performance in mathematical domains, we collected a diverse collection of high-quality data. 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 180)
  message: Should this be "Data Post-Processing"? Follow your preferred style guide and register as an exception if necessary.
   178: To prevent the model from overfitting to specific templates, we diversely constructed templates to ensure the model's numerical computing capabilities generalize to some extent. This part includes 0.2B tokens.
   179: 
>  180: \subsection{Data post-processing}
   181: 
   182: To enhance the quality of the training data, we follow the approach of Query of CC\citep{2024arXiv240114624F} and implement a series of data post-processing strategies. Specifically, we trained a scoring model to identify high-quality datasets. Subsequently, We used the Minhash-LSH method for deduplication of the training data. In our practice, we filtered out duplicate data with a similarity exceeding 0.7.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 213)
  message: Should this be "Training Strategy"? Follow your preferred style guide and register as an exception if necessary.
   211: \label{table_1}
   212: \end{table}
>  213: \subsection{Training strategy}
   214: 
   215: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 314)
  message: Should this be "Pre-Train Performance"? Follow your preferred style guide and register as an exception if necessary.
   312: 
   313: 
>  314: \subsection{Pre-train Performance}
   315: To validate the performances of our pretrained base models, we use the standard benchmark for math informal reasoning: GSM8K \citep{gsm8k} and MATH \citep{MATHbenchmark} and evaluate them using in-context learning. We adopt the few-shot templates from OpenCompass \citep{2023opencompass}. We use majority voting \citep{wang2023selfconsistency} accuracy as the metric. The results are listed in Table~\ref{table:pretrain_icl}. InternLM2-Math-Base models outperform their initial checkpoints InternLM2-Base on both benchmarks which shows the effectiveness of continue pre-training. InternLM2-Math-Base-7B obtains 21.5 on MATH which outperforms Llemma-7B with 18.0. InternLM2-Math-Base-20B obtains 27.3 on MATH which outperforms Llemma-34B and performs similarly with Minerva-62B with a smaller size.
   316: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 649)
  message: Should this be "Compare Pretrain Performance With Pretraining Token Amount"? Follow your preferred style guide and register as an exception if necessary.
   647: \section{Discussion}
   648: 
>  649: \subsection{Compare Pretrain Performance with Pretraining Token Amount}
   650: We pre-train on InternLM-Base-7B for 200B tokens to evaluate how many epochs should we pretrain. We evaluate our models' performance every 40B tokens using ICL and SFT on MetaMath in Table~\ref{tab:pretrain_ablation}.
   651: We find that after 80B tokens, the performance does not improve significantly. When training longer to 200B (approximate 7 epochs) tokens, the performances start to degenerate.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 750)
  message: Should this be "False Positive in MATH BenchMark"? Follow your preferred style guide and register as an exception if necessary.
   748: \end{table*}
   749: 
>  750: \subsection{False positive in MATH BenchMark}
   751: For a math problem that requires an answer, one can always try some special cases to guess the correct answers with incorrect processes. If the question is about counting, generated answers may be sampled wrongly, and obtain a correct answer by chance.
   752: This could lead us to overestimate the math reasoning ability of our models and other LLMs. We randomly sample 5 samples for each difficulty level where the InternLM2-Math-20B gives a correct answer in the MATH test set and human-labeled the predicted process of these 25 problems to report this issue. Table \ref{tab:Table processs} shows the results. One of the false positive cases writes:

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 598)
  message: Should this be "Other Abilities"? Follow your preferred style guide and register as an exception if necessary.
   596: \end{table}
   597: 
>  598: \subsubsection{Other abilities}
   599: 
   600: \paragraph{Game of 24}

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 118)
  message: Should this be "Math Pre-Training"? Follow your preferred style guide and register as an exception if necessary.
   116: 
   117: \section{Related Work}
>  118: \paragraph{Math Pre-training} Pre-training helps LLMs acquire computational and mathematical knowledge from various sources, such as math corpora \citep{pact,Minerva,openwebmath,wang2023generative}, problem sets \citep{lightman2023lets}, and synthetic data \citep{hendrycks2021measuring,goat,mathglm}.
   119: ArXiv with abundant math contents is usually used in math pre-training \citep{lewkowycz2022solving,GAL,azerbayev2023proofnet}.
   120: \cite{openwebmath} extracts math web pages from common crawl which can be complementary to arXiv.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 125)
  message: Should this be "Math Fine-Tuning"? Follow your preferred style guide and register as an exception if necessary.
   123: InternLM-Math collects pre-train data from math corpora and synthetic data which establish its math ability.
   124: 
>  125: \paragraph{Math Fine-tuning} 
   126: % Language models show better math reasoning performance with SFT compared to in-context learning \citep{rft}.
   127: Building a stronger augmented chain-of-thought dataset \citep{yu2023metamath,yue2023mammoth,mugglemath,liu2024augmenting} for SFT to improve math reasoning performance has received lots of interest.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 237)
  message: Should this be "Chain-of-Thought"? Follow your preferred style guide and register as an exception if necessary.
   235: 
   236: 
>  237: \paragraph{Chain-of-thought}
   238: 
   239: We utilize MetaMath \citep{yu2023metamath} as our fundamental English chain-of-thought data resource which brings consistent reasoning improvement to various LLMs.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 286)
  message: Should this be "Augmentation Helper"? Follow your preferred style guide and register as an exception if necessary.
   284: We utilize the MathLib-train dataset \citep{mathlib} extracted from \cite{pact} as the prover training data.
   285: 
>  286: \paragraph{Augmentation helper}
   287: Another important aspect of our data is to help construct synthesized data for self-improving. By rephrasing or augmenting a question, one can easily obtain an enlarged question diversity \citep{luo2023wizardmath,yu2023metamath,mugglemath}. Translating question-answer pairs into a natural language statement is a requirement of using formal math language for proving. 
   288: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 515)
  message: Should this be "Using LEAN to Solve GSM8K"? Follow your preferred style guide and register as an exception if necessary.
   513: \end{table}
   514: 
>  515: \paragraph{Using LEAN to solve GSM8K}
   516: \label{para:lean-gsm8k}
   517: % Here we introduce to utilize LEAN to solve math word problems like GSM8K.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 625)
  message: Should this be "Prime Checker"? Follow your preferred style guide and register as an exception if necessary.
   623: 
   624: 
>  625: \paragraph{Prime checker}
   626: 
   627: For prime number verification, we sampled a test dataset containing 20 numbers for each digit number from 2 to 10 containing 10 prime and 10 composite numbers. Our model can judge correctly for almost all the numbers, whatever their digits, this is better than GPT-4 which performs worse when digits become bigger.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 807)
  message: Should this be "Chain-of-Thought Reasoning"? Follow your preferred style guide and register as an exception if necessary.
   805: \section*{Limitations}
   806: 
>  807: \paragraph{Chain-of-thought reasoning}
   808: We match and rewrite the formulation in the spirit of scratchpad during COT while it introduces the following problems.
   809: The first problem is we cannot easily match all equations and calculations that need to be rewritten (e.g. We solve $x^3-3x^2+3x-1=0$, and obtain $x=1$).

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 814)
  message: Should this be "No Self-Critique Ability"? Follow your preferred style guide and register as an exception if necessary.
   812: We will solve such problems in the future work.
   813: 
>  814: \paragraph{No self-critique ability} Although our model can conduct ORM or PRM. We do not contain any SFT data to let the model apply self-critique since such data can be hard to generate and verify by any means. We will research how to generate self-critique SFT data with verification. 
   815: 
   816: \paragraph{Process reward modeling}

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 816)
  message: Should this be "Process Reward Modeling"? Follow your preferred style guide and register as an exception if necessary.
   814: \paragraph{No self-critique ability} Although our model can conduct ORM or PRM. We do not contain any SFT data to let the model apply self-critique since such data can be hard to generate and verify by any means. We will research how to generate self-critique SFT data with verification. 
   815: 
>  816: \paragraph{Process reward modeling}
   817: We find that our model does not have a significant PRM performance which may be due to the confusing format among PRM and SFT and the unbalanced distribution between positive processes and negative processes. 
   818: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 819)
  message: Should this be "Code-Switch"? Follow your preferred style guide and register as an exception if necessary.
   817: We find that our model does not have a significant PRM performance which may be due to the confusing format among PRM and SFT and the unbalanced distribution between positive processes and negative processes. 
   818: 
>  819: \paragraph{Code-switch} Due to our SFT data distribution, English data is larger than Chinese data which will cause code-switch during some instructions or problem formats.
   820: 
   821: \paragraph{SFT data is using LEAN 3} We use LEAN 3 as our SFT data since GPT-4 can only generate LEAN 3 codes for GSM8K (even if you require it to apply LEAN 4). Furthermore, we find the data of translating between formal and informal from MathLib is preprocessed in LEAN 3.

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 821)
  message: Should this be "SFT Data Is Using LEAN 3"? Follow your preferred style guide and register as an exception if necessary.
   819: \paragraph{Code-switch} Due to our SFT data distribution, English data is larger than Chinese data which will cause code-switch during some instructions or problem formats.
   820: 
>  821: \paragraph{SFT data is using LEAN 3} We use LEAN 3 as our SFT data since GPT-4 can only generate LEAN 3 codes for GSM8K (even if you require it to apply LEAN 4). Furthermore, we find the data of translating between formal and informal from MathLib is preprocessed in LEAN 3.
   822: We will move our SFT data to LEAN 4 in the future version.
   823: 

- file: sample\arxiv_sources\2402.06332v2\main.tex (line 824)
  message: Should this be "Data Contamination on LEAN-Repo"? Follow your preferred style guide and register as an exception if necessary.
   822: We will move our SFT data to LEAN 4 in the future version.
   823: 
>  824: \paragraph{Data contamination on LEAN-repo} We use LEAN codes introduced from AlgebraicStack \citep{llemma}, and we do not check the contamination of AlgebraicStack on MiniF2F. 
   825: AlgebraicStack may or may not contain MiniF2F solutions.
   826: However, the comparison between Llemma and our model is fair.

- file: sample\arxiv_sources\2312.01661v2\sample-sigconf.tex (line 58)
  message: Should this be "ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-University Math Questions"? Follow your preferred style guide and register as an exception if necessary.
    56: 
    57: \begin{document}
>   58: \title{ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions} 
    59:   
    60: \renewcommand{\shorttitle}{SIG Proceedings Paper in LaTeX Format}

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 34)
  message: Should this be "Context-Aware Methodology"? Follow your preferred style guide and register as an exception if necessary.
    32: \paragraph{$\bullet$ Context-unaware} The absence of context $C$ poses a unique challenge for assessing ChatGPT's math problem generation capabilities. Nonetheless, this scenario is essential, as teachers often seek to prompt language models like ChatGPT for math questions without prior context. To address this, we manually collect math curricula for three pre-university levels and propose a prompting framework to create \dataset, a novel dataset with $16K$ question-answer pairs spanning $121$ pre-university math topics and $428$ lessons. Our evaluation of \dataset\ provides valuable insights into ChatGPT's math question generation capability.
    33: 
>   34: \section{Context-aware Methodology}
    35: \subsection{Fine-tuning Baselines} We fine-tune the baselines to generate the question $Q$, given the context $C$ with or without the expected answer $A$ by concatenating the input in the format: \texttt{Context: C} [with/without] \texttt{Answer: A}. The model then learns to generate $Q$.
    36: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 62)
  message: Should this be "Context-Unaware Methodology"? Follow your preferred style guide and register as an exception if necessary.
    60: \end{table*}
    61: 
>   62: \section{Context-unaware Methodology} 
    63: \subsection{\topicmath{} Creation}
    64: \label{subsec:curri}

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 725)
  message: Should this be "Data Pre-Processing"? Follow your preferred style guide and register as an exception if necessary.
   723: % 
   724: 
>  725: % \section{Data Pre-processing}
   726: % \label{appdx:datapp}
   727: % Before training the fine-tuning baseline models for evaluation, we first split the problems in SVAMP, GSM8K and MATH datasets into two parts which are context and question, see \Cref{data-proc}. \textcolor{white}{-------------}

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 759)
  message: Should this be "Comparisons Between Performances of ChatGPT With and Without Contraints"? Follow your preferred style guide and register as an exception if necessary.
   757: % \Cref{alg:answer-unaware-qa-generation} proposes a method to generate math questions for various topics. It involves creating question-answer pairs for each lesson, constructing prompts with relevant information, and using ChatGPT to generate new QA pairs that are accepted only if their question is sufficiently distinct from existing questions.
   758: 
>  759: % \section{Comparisons between performances of ChatGPT with and without contraints} 
   760: % \label{GG}
   761: % We conducted an experiment using various types of prompts and found that incorporating specific constraints, such as Contextual Independence, Tense Matching, and Word Limit, greatly enhances ChatGPT's performance in the task of math question generation. Our empirical results in \Cref{constraints_compa} demonstrate the effectiveness of these constraints in guiding ChatGPT to generate high-quality math questions.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 813)
  message: Should this be "Results of Adding Constraints"? Follow your preferred style guide and register as an exception if necessary.
   811: 
   812: % \begin{table}[ht]
>  813: % % \section{Results of adding constraints}
   814: %     \centering
   815: %     \small

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 1034)
  message: Should this be "Prompt Templates for Context-Aware Setting"? Follow your preferred style guide and register as an exception if necessary.
  1032: % \input{vda.tex}
  1033: 
> 1034: % \section{Prompt templates for context-aware setting}
  1035: % \label{appdx:context-aware}
  1036: % \input{basepromptaware.tex}

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 1039)
  message: Should this be "Prompt Templates for Context-Unaware Setting"? Follow your preferred style guide and register as an exception if necessary.
  1037: % \input{basepromptunaware.tex}
  1038: 
> 1039: % \section{Prompt templates for context-unaware setting}
  1040: % \label{appdx:prompt-template-context-unaware}
  1041: % \input{basepromptcontextunaware}

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 1047)
  message: Should this be "Variety of ChatGPT's Performance in Different Topics"? Follow your preferred style guide and register as an exception if necessary.
  1045: 
  1046: % \begin{table*}[htbp]
> 1047: % \section{Variety of ChatGPT's performance in different topics}
  1048: %   \centering
  1049:   

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 20)
  message: Should this be "Pre-University Math Problems Generation"? Follow your preferred style guide and register as an exception if necessary.
    18: Recently, LLMs have shown remarkable zero-shot and few-shot abilities in various language generation contexts \cite{brown2020language, wei2022finetuned, ouyang2022training}. However, they still face challenges in more complex tasks like mathematical reasoning \cite{gao2022pal, imani2023mathprompter}, often requiring expensive computational resources for fine-tuning. To address this, researchers have been exploring novel prompting methods to instruct LLMs in these tasks, including chain-of-thought (CoT) prompting \cite{weichain}. This enables LLMs to perform intermediate reasoning steps, significantly enhances LLMs' reasoning abilities, especially for complex mathematical and decision-making tasks.
    19: 
>   20: \subsection{Pre-university Math Problems Generation}\label{ssec:related-math-problem}
    21: Pre-university math problems have received increasing attention from the AI research community, with benchmarks such as SVAMP \cite{svamp} for elementary-level math, secondary school-level GSM8K \cite{cobbe2021training} offers diverse solution templates, and the MATH \cite{hendrycks2021measuring} dataset provides complex reasoning for tertiary/olympiad problems along with step-by-step solutions. Recently, interest has grown in other tertiary math topics like geometry problems and mathematical theorem proving \cite{sachan-etal-2019-discourse, chen-etal-2022-unigeo}. Additionally, automatic question generation (QG) in education has gained attention for enhancing teaching activities \cite{Kurdi2019ASR}. Additionally, in education, QG has gained attention with the use of LLMs, particularly ChatGPT, has gained significant interest for generating practice questions in various subjects \cite{Wang2022TowardsHE, Kasneci2023ChatGPTFG}. However, its potential for generating pre-university mathematics problems remains largely unexplored. This study, therefore, evaluates ChatGPT's performance using three well-established datasets: SVAMP, GSM8K, and MATH, covering pre-university grades and various difficulty levels.
    22: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 35)
  message: Should this be "Fine-Tuning Baselines"? Follow your preferred style guide and register as an exception if necessary.
    33: 
    34: \section{Context-aware Methodology}
>   35: \subsection{Fine-tuning Baselines} We fine-tune the baselines to generate the question $Q$, given the context $C$ with or without the expected answer $A$ by concatenating the input in the format: \texttt{Context: C} [with/without] \texttt{Answer: A}. The model then learns to generate $Q$.
    36: 
    37: \subsection{Prompting ChatGPT}  

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 129)
  message: Should this be "Prompting ChatGPT to Generate Educational Questions From Math Topics"? Follow your preferred style guide and register as an exception if necessary.
   127: 
   128: 
>  129: \subsection{Prompting ChatGPT to Generate Educational Questions from Math Topics}
   130: \vspace{-3mm}
   131: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 225)
  message: Should this be "Context-Aware Experimentation"? Follow your preferred style guide and register as an exception if necessary.
   223: \label{sec:experimentation}
   224: 
>  225: \subsection{Context-aware Experimentation}
   226: 
   227: \begin{table*}[t!]

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 296)
  message: Should this be "Context-Unaware Experimentation"? Follow your preferred style guide and register as an exception if necessary.
   294: % \textbf{Grammaticality} is rated using a 3-point scale in both settings. In addition,  \textbf{Answerability} is rated using a 2-point and 3-point scale in the \emph{answer-unaware} and \emph{answer-aware} settings respectively. 
   295: 
>  296: \subsection{Context-unaware Experimentation} \label{sec:context-unaware-experimentation}
   297: 
   298: In the context-unaware setting, since there are no ground-truth questions, we only rely on human evaluations. We perform human evaluation on 500 randomly selected samples, with 100 questions coming from each {\it prompted} difficulty. We hire three educators who are native English speakers to evaluate ChatGPT on 5 criteria: \textbf{(1) Grammaticality} to assess the grammatical accuracy of the generated question; \textbf{(2) Answerability} measuring the answerable plausibility of the generated question; \textbf{(3) Topic Alignment} assessing question relevancy to the topic; \textbf{(4) Difficulty Alignment} to compare the expected and generated difficulty; \textbf{(5) Usefulness} to assess the mathematical usefulness of the generated question to the education generally. The scoring criteria for metrics are provided in \Cref{appdx:human-rating}.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 424)
  message: Should this be "Context-Aware Human Evaluation"? Follow your preferred style guide and register as an exception if necessary.
   422: % \paragraph{$\bullet$ ChatGPT analysis}In the zero-shot setting, GPT-3.5 consistently outperforms GPT-3 and ChatGPT across all datasets and metrics. GPT-3.5 achieves significantly higher scores, indicating that it has a better understanding of the context and can generate more relevant and coherent questions.
   423: 
>  424: \subsection{Context-aware Human Evaluation} \label{subsec:context-aware-human-eval}
   425: 
   426: % %%%%%%%%%%%%%%%%%%%%%%%%%%%% Context unaware human evaluation

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 594)
  message: Should this be "Context-Unaware Human Evaluation"? Follow your preferred style guide and register as an exception if necessary.
   592: 
   593: 
>  594: \subsection{Context-unaware Human Evaluation} \label{subsec:context-unaware-human-eval}
   595: 
   596: % Table contains examples for context unaware human evaluation

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 312)
  message: Should this be "Step-by-Step and Chain-of-Thought Prompting"? Follow your preferred style guide and register as an exception if necessary.
   310: % \llong{Merge 5.2 to this and say prompting method is presented in \Cref{sec:context-unaware-experimentation}.}.
   311: 
>  312: % \paragraph{Step-by-step and Chain-of-thought prompting} For grade 1-8, we observed that many examples from Khan Academy only contains one sentence for the solution (due to the type of question
   313: % ) \vda{doubt that, too risky}. ChatGPT tends to mimic the demonstration and only generates one-sentence solution, even for questions it generated that requires chain-of-thought. So we encouraged it to give clearer solutions by prompting in the style of \emph{"Let's think step by step"} proposed by \citet{kojima2023large}. Meanwhile, for tertiary classes, since the demonstrating QA pairs are already sophisticated enough (in Chain-of-thought style), we do not need to add this sentence in the prompt.
   314: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 315)
  message: Should this be "Token Diversity Promoting"? Follow your preferred style guide and register as an exception if necessary.
   313: % ) \vda{doubt that, too risky}. ChatGPT tends to mimic the demonstration and only generates one-sentence solution, even for questions it generated that requires chain-of-thought. So we encouraged it to give clearer solutions by prompting in the style of \emph{"Let's think step by step"} proposed by \citet{kojima2023large}. Meanwhile, for tertiary classes, since the demonstrating QA pairs are already sophisticated enough (in Chain-of-thought style), we do not need to add this sentence in the prompt.
   314: 
>  315: % \paragraph{Token diversity promoting} We also used different techniques to encourage generating more diverse tokens in different classes. For grade 1-8, we prompt the LLM to add objects and stories for a richer context. This context will complement the simple problems and make them easier to learn. {\color{red} Seems like this variation promoting thing is also shown in the SVAMP paper, I need help in verifying this} \vda{paper SVAMP only replace numbers with numbers to test reasoning ability and question sensitivity, not context} For tertiary classes, the complicated problems require more rigorous and abstract thinking, so we do not require a real-life context. Instead, we propose the model to introduce more variables and be flexible in naming them, so the abstract contexts could be generalized.
   316: 
   317: % \paragraph{Demonstration} A demonstration is given in order to control the topic alignment of the generated question. Experimentations also show that, giving two demonstrations, without diversifying them, would reduce ChatGPT's ability to generate diverse questions

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 454)
  message: Should this be "(1) ChatGPT Generates Questions With Minimal Grammatical Errors."? Follow your preferred style guide and register as an exception if necessary.
   452: Through our careful manual evaluations, we have obtained 6 insightful findings.
   453: 
>  454: \paragraph{(1) ChatGPT generates questions with minimal grammatical errors.} 
   455: As shown in \Cref{tab:human-evaluation-context-aware}, ChatGPT consistently attains grammaticality scores exceeding $>4.9$, underscoring its proficiency in generating grammatically correct texts across all pre-university levels. Notably, we observe that grammatical errors predominantly emerge when ChatGPT attempts to generate highly complex problems.
   456: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 457)
  message: Should this be "(2) ChatGPT Generates Questions That Are Highly Relevant to the Input Context."? Follow your preferred style guide and register as an exception if necessary.
   455: As shown in \Cref{tab:human-evaluation-context-aware}, ChatGPT consistently attains grammaticality scores exceeding $>4.9$, underscoring its proficiency in generating grammatically correct texts across all pre-university levels. Notably, we observe that grammatical errors predominantly emerge when ChatGPT attempts to generate highly complex problems.
   456: 
>  457: \paragraph{(2) ChatGPT generates questions that are highly relevant to the input context.} Our manual evaluations reveal that the questions generated by ChatGPT are highly relevant to the input contexts. Remarkably, these questions exhibit minimal presence of unrelated characters or variables not found in the context, resulting in nearly perfect relevancy scores across most datasets and sub-settings (see \Cref{tab:human-evaluation-context-aware}). However, an intriguing observation emerges with a lower relevancy score in the answer-aware setting for MATH compared to its answer-unaware counterpart.
   458: 
   459: \paragraph{(3) ChatGPT frequently repeats information from the context} 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 459)
  message: Should this be "(3) ChatGPT Frequently Repeats Information From the Context"? Follow your preferred style guide and register as an exception if necessary.
   457: \paragraph{(2) ChatGPT generates questions that are highly relevant to the input context.} Our manual evaluations reveal that the questions generated by ChatGPT are highly relevant to the input contexts. Remarkably, these questions exhibit minimal presence of unrelated characters or variables not found in the context, resulting in nearly perfect relevancy scores across most datasets and sub-settings (see \Cref{tab:human-evaluation-context-aware}). However, an intriguing observation emerges with a lower relevancy score in the answer-aware setting for MATH compared to its answer-unaware counterpart.
   458: 
>  459: \paragraph{(3) ChatGPT frequently repeats information from the context} 
   460: Despite explicit constraints outlined in the prompt template regarding repetition, the model occasionally reiterates random segments (tertiary-level) or the whole context (lower-levels). This repetition leads to the generation of overly lengthy questions, as exemplified by instances such as: ``Context: \emph{A football team played 22 games. They won 8 more than they lost.''}, ``Generated Question: \emph{How many games did the football team win if they played 22 games and won 8 more than they lost?''}. Subsequent human evaluations unveil that this issue predominantly afflicts the GSM8K dataset, occurring about 50\% of the time.
   461: 

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 574)
  message: Should this be "(4) With an Expected Answer, ChatGPT Tends to Generate Answerable Questions Whilst, Without It, This Likelihood Is Lower."? Follow your preferred style guide and register as an exception if necessary.
   572: % \end{table}
   573: 
>  574: \paragraph{(4) With an expected answer, ChatGPT tends to generate answerable questions whilst, without it, this likelihood is lower.} When additional hypotheses are required to construct a complete question (e.g., ``Context: \emph{Mary is two years younger than Joan, who is five years older than Jessa''}), our empirical evaluation indicates that ChatGPT tends to struggle in the absence of an expected answer as a reference. For instance, within the answer-unaware setup and considering the context mentioned, ChatGPT only asks \emph{``How old is Jessa?''}.
   575: 
   576: \paragraph{(5) Without an expected answer, ChatGPT frequently generates trivial questions} In the \textit{answer-unaware} scenario, ChatGPT often exhibits a combination of the aforementioned behaviors (2) and (4), where it redundantly repeats information from the context and formulates it as a question. This behavior occurs irrespective of the context's complexity, resulting in the generation of simplistic questions that merely require looking up information in the context itself. For instance, when the context is as straightforward as \emph{``Darrell and Allen's ages are in the ratio of 7:11''}, ChatGPT redundantly repeats the entire context and asks, \emph{``What is the ratio of Darrells age to Allens age?''}. While this phenomenon occurs less frequently than (4), about 5\% of the generated questions.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 576)
  message: Should this be "(5) Without an Expected Answer, ChatGPT Frequently Generates Trivial Questions"? Follow your preferred style guide and register as an exception if necessary.
   574: \paragraph{(4) With an expected answer, ChatGPT tends to generate answerable questions whilst, without it, this likelihood is lower.} When additional hypotheses are required to construct a complete question (e.g., ``Context: \emph{Mary is two years younger than Joan, who is five years older than Jessa''}), our empirical evaluation indicates that ChatGPT tends to struggle in the absence of an expected answer as a reference. For instance, within the answer-unaware setup and considering the context mentioned, ChatGPT only asks \emph{``How old is Jessa?''}.
   575: 
>  576: \paragraph{(5) Without an expected answer, ChatGPT frequently generates trivial questions} In the \textit{answer-unaware} scenario, ChatGPT often exhibits a combination of the aforementioned behaviors (2) and (4), where it redundantly repeats information from the context and formulates it as a question. This behavior occurs irrespective of the context's complexity, resulting in the generation of simplistic questions that merely require looking up information in the context itself. For instance, when the context is as straightforward as \emph{``Darrell and Allen's ages are in the ratio of 7:11''}, ChatGPT redundantly repeats the entire context and asks, \emph{``What is the ratio of Darrells age to Allens age?''}. While this phenomenon occurs less frequently than (4), about 5\% of the generated questions.
   577: 
   578: \paragraph{(6) Even with good contextual understanding, ChatGPT struggles to understand the relationship between mathematical objects.} This problem manifests in both the \emph{answer-aware} and \emph{answer-unaware} settings. In the \emph{answer-aware} mode, ChatGPT tends to inaccurately order subtraction operations while in the \emph{answer-unaware}, it exhibits reluctance in generating questions related to the relationships between objects. This phenomenon occurs about 2\% of the time.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 578)
  message: Should this be "(6) Even With Good Contextual Understanding, ChatGPT Struggles to Understand the Relationship Between Mathematical Objects."? Follow your preferred style guide and register as an exception if necessary.
   576: \paragraph{(5) Without an expected answer, ChatGPT frequently generates trivial questions} In the \textit{answer-unaware} scenario, ChatGPT often exhibits a combination of the aforementioned behaviors (2) and (4), where it redundantly repeats information from the context and formulates it as a question. This behavior occurs irrespective of the context's complexity, resulting in the generation of simplistic questions that merely require looking up information in the context itself. For instance, when the context is as straightforward as \emph{``Darrell and Allen's ages are in the ratio of 7:11''}, ChatGPT redundantly repeats the entire context and asks, \emph{``What is the ratio of Darrells age to Allens age?''}. While this phenomenon occurs less frequently than (4), about 5\% of the generated questions.
   577: 
>  578: \paragraph{(6) Even with good contextual understanding, ChatGPT struggles to understand the relationship between mathematical objects.} This problem manifests in both the \emph{answer-aware} and \emph{answer-unaware} settings. In the \emph{answer-aware} mode, ChatGPT tends to inaccurately order subtraction operations while in the \emph{answer-unaware}, it exhibits reluctance in generating questions related to the relationships between objects. This phenomenon occurs about 2\% of the time.
   579: 
   580: % \begin{table}[ht]

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 637)
  message: Should this be "(1) ChatGPT Generates Questions With High Diversity in Terms of Context."? Follow your preferred style guide and register as an exception if necessary.
   635: Along with the same observation about question grammaticality, we provide 5 more findings in the {\it context-unaware} setting.
   636: 
>  637: \paragraph{(1) ChatGPT generates questions with high diversity in terms of context.} Across all three class levels, ChatGPT consistently excels at crafting real-life scenarios that seamlessly integrate with the context. Notably, at the secondary and tertiary school levels, ChatGPT demonstrates its versatility by drawing connections to other subjects, such as Physics and Biology. For example: \emph{``A population of bacteria doubles every 3 hours. If there are initially 1000 bacteria, what will be the population after 12 hours? Is this an example of exponential growth or decay?''}
   638: 
   639: \paragraph{(2) ChatGPT sometimes generates questions that are not well-aligned with some provided topics.} ChatGPT occasionally interprets complex concepts as more familiar ones. For instance, when tasked with creating questions related to \emph{``Divide whole numbers to get a decimal quotient''}, it might generate questions whose answers are whole numbers instead of decimals. Similarly, in lessons containing the term \emph{``modeling''}, ChatGPT tends to generate Linear Programming questions. Although this misunderstanding is relatively infrequent, only about 5\% of cases, it is a noteworthy aspect to keep in mind.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 639)
  message: Should this be "(2) ChatGPT Sometimes Generates Questions That Are Not Well-Aligned With Some Provided Topics."? Follow your preferred style guide and register as an exception if necessary.
   637: \paragraph{(1) ChatGPT generates questions with high diversity in terms of context.} Across all three class levels, ChatGPT consistently excels at crafting real-life scenarios that seamlessly integrate with the context. Notably, at the secondary and tertiary school levels, ChatGPT demonstrates its versatility by drawing connections to other subjects, such as Physics and Biology. For example: \emph{``A population of bacteria doubles every 3 hours. If there are initially 1000 bacteria, what will be the population after 12 hours? Is this an example of exponential growth or decay?''}
   638: 
>  639: \paragraph{(2) ChatGPT sometimes generates questions that are not well-aligned with some provided topics.} ChatGPT occasionally interprets complex concepts as more familiar ones. For instance, when tasked with creating questions related to \emph{``Divide whole numbers to get a decimal quotient''}, it might generate questions whose answers are whole numbers instead of decimals. Similarly, in lessons containing the term \emph{``modeling''}, ChatGPT tends to generate Linear Programming questions. Although this misunderstanding is relatively infrequent, only about 5\% of cases, it is a noteworthy aspect to keep in mind.
   640: 
   641: % \begin{table}[ht]

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 685)
  message: Should this be "(3) ChatGPT Generates Questions With Difficulty Solely Depending on the Difficulty of Demonstration."? Follow your preferred style guide and register as an exception if necessary.
   683: % \end{table}
   684: 
>  685: \paragraph{(3) ChatGPT generates questions with difficulty solely depending on the difficulty of demonstration.} When presented with a straightforward example (level 3) but tasked with generating a more complex question (level 5), ChatGPT often replicates the initial demonstration and struggles to enhance the question's difficulty. We noticed that lessons with overlapping content between secondary school and high school levels were generated similarly because of the shared demonstration, despite distinct required difficulty levels in the prompt. This pattern was consistently observed in all our attempts to generate questions with varying difficulty levels from the provided demonstrations.
   686: 
   687: \paragraph{(4) If ChatGPT generates hard questions, it could not handle the complexity and generates nonsense.} ChatGPT demonstrates proficiency in introducing new objects within questions but struggles to establish meaningful connections or inquire about genuine relationships between these objects. For instance, in Geometry questions, ChatGPT often generates random points (A, B, C), states some relationships (e.g., AX is the bisector of angle BAC), and includes unrelated quantitative properties (e.g., angle AXB = angle AXC), resulting in suboptimal performance.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 687)
  message: Should this be "(4) if ChatGPT Generates Hard Questions, It Could Not Handle the Complexity and Generates Nonsense."? Follow your preferred style guide and register as an exception if necessary.
   685: \paragraph{(3) ChatGPT generates questions with difficulty solely depending on the difficulty of demonstration.} When presented with a straightforward example (level 3) but tasked with generating a more complex question (level 5), ChatGPT often replicates the initial demonstration and struggles to enhance the question's difficulty. We noticed that lessons with overlapping content between secondary school and high school levels were generated similarly because of the shared demonstration, despite distinct required difficulty levels in the prompt. This pattern was consistently observed in all our attempts to generate questions with varying difficulty levels from the provided demonstrations.
   686: 
>  687: \paragraph{(4) If ChatGPT generates hard questions, it could not handle the complexity and generates nonsense.} ChatGPT demonstrates proficiency in introducing new objects within questions but struggles to establish meaningful connections or inquire about genuine relationships between these objects. For instance, in Geometry questions, ChatGPT often generates random points (A, B, C), states some relationships (e.g., AX is the bisector of angle BAC), and includes unrelated quantitative properties (e.g., angle AXB = angle AXC), resulting in suboptimal performance.
   688: 
   689: \paragraph{(5) ChatGPT could generate questions that are not so mathy.} While instructions and demonstrations in prompts have been effective in mitigating the issue, they are not foolproof. In primary school topics such as \emph{``Measurement''}, ChatGPT occasionally generates questions that do not necessitate mathematical knowledge (e.g., \emph{``How long is a ruler?''}). However, in higher-level classes where lesson names are more math-specific, this phenomenon is notably less prevalent.

- file: sample\arxiv_sources\2312.01661v2\samplebody-conf.tex (line 689)
  message: Should this be "(5) ChatGPT Could Generate Questions That Are Not So Mathy."? Follow your preferred style guide and register as an exception if necessary.
   687: \paragraph{(4) If ChatGPT generates hard questions, it could not handle the complexity and generates nonsense.} ChatGPT demonstrates proficiency in introducing new objects within questions but struggles to establish meaningful connections or inquire about genuine relationships between these objects. For instance, in Geometry questions, ChatGPT often generates random points (A, B, C), states some relationships (e.g., AX is the bisector of angle BAC), and includes unrelated quantitative properties (e.g., angle AXB = angle AXC), resulting in suboptimal performance.
   688: 
>  689: \paragraph{(5) ChatGPT could generate questions that are not so mathy.} While instructions and demonstrations in prompts have been effective in mitigating the issue, they are not foolproof. In primary school topics such as \emph{``Measurement''}, ChatGPT occasionally generates questions that do not necessitate mathematical knowledge (e.g., \emph{``How long is a ruler?''}). However, in higher-level classes where lesson names are more math-specific, this phenomenon is notably less prevalent.
   690: 
   691: \section{Conclusions}

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 40)
  message: Should this be "Is Math Useful?"? Follow your preferred style guide and register as an exception if necessary.
    38: \begin{document}
    39: 
>   40: \title{Is math useful?}
    41: % Use \titlerunning{Short Title} for an abbreviated version of
    42: % your contribution title if the original one is too long

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 65)
  message: Should this be "Is Math Useful?"? Follow your preferred style guide and register as an exception if necessary.
    63: \end{figure}
    64: 
>   65: \section{Is math useful?}
    66: \begin{quotation}  The mass of mathematical
    67: truth is obvious and imposing; its practical applications, the

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 95)
  message: Should this be "How Is Math Used in War Time?"? Follow your preferred style guide and register as an exception if necessary.
    93: Before getting there, tough, we have a long way. We first have to understand what is the usefulness of math and how math is (and can be) used.
    94: 
>   95: \section{How is math used in war time?}
    96: \label{sec:WWII}
    97: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 161)
  message: Should this be "How Can Pure Math Be Useful?"? Follow your preferred style guide and register as an exception if necessary.
   159: 
   160: 
>  161: \section{How can pure math be useful?}
   162: \label{sec:2}
   163: % Always give a unique label

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 258)
  message: Should this be "Why Politicians Should Know Math?"? Follow your preferred style guide and register as an exception if necessary.
   256: 
   257: 
>  258: \section{Why politicians should know math?}
   259: All of the above is a bunch of examples showing what is math useful to us as a species, as a community. But of course, we may ask ourselves if math knowledge should not be simply limited to mathematicians, engineers abd other people who may use it in their work for the benefit of the community at large. After all, we do not need people know exactly how a bridge is constructed, how a TV works, or how to repair a broken engine. For that, we use people who know how to do. Why should math be different?
   260: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 312)
  message: Should this be "How Do Politicians Use Math?"? Follow your preferred style guide and register as an exception if necessary.
   310: This is why politicians should have a good base in math and know how to analyze data. Before making decisions, the least you must have is correct data and infos, and possibly understand correctly what they mean.
   311: 
>  312: \section{How do politicians use math?}
   313: You might say that politicians do not really have to know and understand math, in order not to fall into such errors, but just to have good advisors who do know math. And indeed they have. Plenty of them. And here we get to the problem.
   314: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 366)
  message: Should this be "Is Math Useful to Me?"? Follow your preferred style guide and register as an exception if necessary.
   364: All this is why it is usually forbidden to change the rules of an election (or the shape of discrits) too near to the upcoming election. But of course, regulations do not completely stop politicians to use math for their own benefit.
   365: 
>  366: \section{Is math useful to me?}
   367: 
   368: Let us now address the main point of this paper: how is math useful to \textit{me}? Why should \textit{I} learn math? Can't just a few people be knowledgeable of math for the whole society's benefit?

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 388)
  message: Should this be "Is Math Usefulness Relevant to Learners?"? Follow your preferred style guide and register as an exception if necessary.
   386: 
   387: 
>  388: \section{Is math usefulness relevant to learners?}
   389: I hope we have cleared that math is useful to everyone and to the population at large. Given that, the fact that something is useful to someone, it does not straightforwardly imply that it will be interested in learning that, much more when you are dealing with children or kids or young adults. Showing the utility of something may make want some students to learn something, but most of them will be simply bored as hell.
   390: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 423)
  message: Should this be "Is Math Popularization Useful? --- a Math Popularizer's Apology"? Follow your preferred style guide and register as an exception if necessary.
   421: \end{question}
   422: 
>  423: \section{Is math popularization useful? --- A math popularizer's apology}
   424: To end this chapter, I would like to give an apology to the activity of math popularization. Hardy had quite harsh words for this activity, and I feel most of my collegues agree with him: any amount of time spent in popularizing math is time stolen from doing actual math, and probably, if you do that, it is just because you are not good enough to do actual math.
   425: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 247)
  message: Should this be "Radon-Nikodim Antitransformation and Computed Axial Tomography"? Follow your preferred style guide and register as an exception if necessary.
   245: 
   246: 
>  247: \subsection{Radon-Nikodim antitransformation and computed axial tomography}
   248: 
   249: Looking inside a body may be a difficult task. Our body is not transparent and cutting a person in order to see what's on the inside may not always be a good idea. Radiography, using X-rays, helped in seeing bones, since the rest of the body is trasparent to X-rays, but they are not a good means to inspect soft parts of our bodies.

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 265)
  message: Should this be "Education System in the US, Covid-19 Death Toll and Simpson's Paradox"? Follow your preferred style guide and register as an exception if necessary.
   263: Our modern world is a world filled with data and numbers. Decisions must be made based on those numbers and those data. But interpreting data is far from obvious, as the "survivor's bias" example should have already clearified. An inability to correctly interpret data may turn into a disaster. Indeed statistics is quite difficult.
   264: 
>  265: \subsection{Education system in the US, covid-19 death toll and Simpson's paradox}
   266: For many years, Winsconsin's students performed consistely better than Texas' students in standardized tests (see figure \ref{overall}).
   267: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 321)
  message: Should this be "Paradoxes of Elections"? Follow your preferred style guide and register as an exception if necessary.
   319: Politicians are informed real-time about the hottest arguments of discussion (\textit{trending topics}) and on what most people think about the argument (\textit{sentiment analysis}), and so they are ready to band-wagon on the hottest topic with the coolest opinion. It almost does not matter whether the opinions expressed are coherent with one another or not: what is really important is to say something on the trending topic of the day, with their opinion being shared and viewed by the highest possible number of people. In time of election, people will recognise your name, and you'll have bigger chances of being voted, hence more votes. This is the core of marketing, applied to politics. Not so great if you think politics should be about solving the community's problems, but that's how it is. And there is a lot of math in that.
   320: 
>  321: \subsection{Paradoxes of elections}
   322: So, we have decided that politicians' biggest task is getting elected (even if they are really interested in doing their work for the benefit of the community: in order to do that, they need to be elected). Alas, the outcome of elections is far from being determined from what voters think, and the electoral system is crucial for the result. This is exactly the reason why politicans spend so much time discussing the electoral system. This subsection is mainly based on my paper \cite{SS}, on mathematical paradoxes of elections. I refer the reader to that paper  for greater details.
   323: 

- file: sample\arxiv_sources\2105.03843v1\IsMathUseful.tex (line 232)
  message: Should this be "Number Theory and Cryptography"? Follow your preferred style guide and register as an exception if necessary.
   230: The breaking of the Nazi encrypting machine \textit{Enigma} by a huge group lead by Alan Turing was a key turning point of WWII.
   231: 
>  232: \subsubsection{Number theory and cryptography}
   233: Number theory was used to solve the last and biggest problem in cryptography. Namely, number theory allows for a method in which the encryption key is public but the decryption key is private, thus allowing anyone to send messages to the receiver (e.g. your password to a website or the PIN of your credit card to your bank) without having to worry about a third party decrypting the message.
   234: 

- file: sample\arxiv_sources\2307.16112v1\3-design-space.tex (line 30)
  message: Should this be "Strategy 1. Exemplify Through Concrete Values"? Follow your preferred style guide and register as an exception if necessary.
    28: In the following sections, we discuss each design strategy and its examples in more detail. \autoref{fig:design-strategies} also illustrates the visual summary of each strategy and design component. 
    29: 
>   30: \subsection*{Strategy 1. Exemplify through Concrete Values}
    31: \subsubsection*{Explorable Values and Examples}
    32: The first strategy is to exemplify abstract and symbolic math representations with concrete values. 

- file: sample\arxiv_sources\2307.16112v1\3-design-space.tex (line 41)
  message: Should this be "Strategy 2. Visualize Through Interactive and Animated Graphs"? Follow your preferred style guide and register as an exception if necessary.
    39: By leveraging explorable examples and dynamic calculations, students can develop a better understanding of abstract concepts by visualizing them. 
    40: 
>   41: \subsection*{Strategy 2. Visualize through Interactive and Animated Graphs}
    42: \subsubsection*{Reactive Graphs}
    43: While the first strategy mainly focuses on textual representation, another common strategy leverages dynamic visual representation. 

- file: sample\arxiv_sources\2307.16112v1\3-design-space.tex (line 57)
  message: Should this be "Strategy 3. Guide Through Contextual Hints or Exercises"? Follow your preferred style guide and register as an exception if necessary.
    55: While this representation focuses more on animation than interaction, users can still manipulate parameters such as timelines. 
    56: 
>   57: \subsection*{Strategy 3. Guide through Contextual Hints or Exercises}
    58: \subsubsection*{Contextual Hints}
    59: Contextual hints provide additional information to students when they need it. 

- file: sample\arxiv_sources\2209.05238v2\main.tex (line 7)
  message: Should this be "A Characterization of Atomicity"? Follow your preferred style guide and register as an exception if necessary.
     5: \begin{document}
     6: %
>    7: \title{A characterization of atomicity}
     8: %
     9: \author{Salvatore Tringali}

- file: sample\arxiv_sources\2209.05238v2\main.tex (line 79)
  message: Should this be "Turning the ACCP to an Element-Wise Condition"? Follow your preferred style guide and register as an exception if necessary.
    77: 
    78: 
>   79: \section{Turning the ACCP to an element-wise condition}
    80: \label{sec:premonoids}
    81: 

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 48)
  message: Should this be "Examining Spoken Language Understanding From Kids for Early~Math~Learning~at~Home"? Follow your preferred style guide and register as an exception if necessary.
    46: %\title{Assessing Spoken Language Understanding for Early~Math~Learning~at~Home}
    47: %\title{Assessment of Spoken Language Understanding for Early~Math~Learning~at~Home}
>   48: %\title{Examining Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    49: %\title{Analysis of Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    50: %\title{Inspecting Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 49)
  message: Should this be "Analysis of Spoken Language Understanding From Kids for Early~Math~Learning~at~Home"? Follow your preferred style guide and register as an exception if necessary.
    47: %\title{Assessment of Spoken Language Understanding for Early~Math~Learning~at~Home}
    48: %\title{Examining Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
>   49: %\title{Analysis of Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    50: %\title{Inspecting Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    51: \title{Inspecting Spoken Language Understanding from Kids for Basic~Math~Learning~at~Home}

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 50)
  message: Should this be "Inspecting Spoken Language Understanding From Kids for Early~Math~Learning~at~Home"? Follow your preferred style guide and register as an exception if necessary.
    48: %\title{Examining Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    49: %\title{Analysis of Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
>   50: %\title{Inspecting Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    51: \title{Inspecting Spoken Language Understanding from Kids for Basic~Math~Learning~at~Home}
    52: %\title{Assessing Spoken Language Understanding Module of a Multimodal Dialogue System for Kids Learning Math at Home}

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 51)
  message: Should this be "Inspecting Spoken Language Understanding From Kids for Basic~Math~Learning~at~Home"? Follow your preferred style guide and register as an exception if necessary.
    49: %\title{Analysis of Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
    50: %\title{Inspecting Spoken Language Understanding from Kids for Early~Math~Learning~at~Home}
>   51: \title{Inspecting Spoken Language Understanding from Kids for Basic~Math~Learning~at~Home}
    52: %\title{Assessing Spoken Language Understanding Module of a Multimodal Dialogue System for Kids Learning Math at Home}
    53: %\title{Assessing Spoken Language Understanding Pipeline of a Multimodal Dialogue System for Kids Learning Math at Home}

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 763)
  message: Should this be "Tables and Figures"? Follow your preferred style guide and register as an exception if necessary.
   761: Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}
   762: 
>  763: \subsection{Tables and figures}
   764: 
   765: See Table~\ref{tab:accents} for an example of a table and its caption.

- file: sample\arxiv_sources\2306.00482v1\acl2023.tex (line 169)
  message: Should this be "Speech Recognition With Kids"? Follow your preferred style guide and register as an exception if necessary.
   167: % x T5
   168: 
>  169: \subsubsection{Speech Recognition with Kids}
   170: \label{sec:speech-rec}
   171: 

- file: sample\arxiv_sources\2307.16112v1\1-introduction.tex (line 1)
  message: Should this be "Introduction"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{introduction}
     2: 
     3: \textit{``People currently think of text as information to be consumed. I want text to be used as an environment to think in.'' --- Bret Victor~\cite{victor2011explorable}}

- file: sample\arxiv_sources\2305.15948v3\String_Math_2022_Proc__Tan_.tex (line 282)
  message: Should this be "A Novel Floer Homology From Boundary Vafa-Witten Theory"? Follow your preferred style guide and register as an exception if necessary.
   280: 
   281: 
>  282: \section{A Novel Floer Homology from Boundary Vafa-Witten Theory}\label{vwsqm}
   283: In this section, we will show how we can physically derive a novel Floer homology by considering boundary VW theory on $M_4 = M_3 \times \mathbb{R}^+$ to physically derive a VW Floer homology assigned to $M_3$.\footnote{To be precise, VW theory is still being defined on an $M_4$ with no boundary. However, to make contact with Floer theory, we will need to examine a hyper-slice of $M_4$, which we can topologically regard as $M_3 \times \mathbb{R}^- \cup_{M_3} M_3 \times \mathbb{R}^+$. 
   284: %We have exploited the topological invariance of the theory to formally bring the $-\infty$ end of $\mathbb{R}$ to zero, 

- file: sample\arxiv_sources\2305.15948v3\String_Math_2022_Proc__Tan_.tex (line 497)
  message: Should this be "Langlands Duality of Vafa-Witten Invariants, Gromov-Witten Invariants, Floer Homologies and the Abouzaid-Manolescu Hypercohomology "? Follow your preferred style guide and register as an exception if necessary.
   495: which again agrees with~\cite[Remark 6.15]{BB12}. 
   496: 
>  497: \section{Langlands Duality of Vafa-Witten Invariants, Gromov-Witten invariants, Floer Homologies and the Abouzaid-Manolescu Hypercohomology }\label{sec:langlands duality} 
   498: 
   499: It is known that $\mathcal{N}=4$ supersymmetric Yang-Mills theories has a $SL(2, \mathbb{Z})$ symmetry, with $S$- and $T$-duality, as mentioned in $\S$\ref{vwgeneral}. In particular, the theory with complex coupling $\tau$ and gauge group $G$, is $S$-dual to a theory with complex coupling $-\frac{1}{n_{\mathfrak g}\tau}$ and Langlands dual gauge group $^L G$, 

- file: sample\arxiv_sources\2305.15948v3\String_Math_2022_Proc__Tan_.tex (line 447)
  message: Should this be "A Physical Proof and Generalization of a Conjecture by Abouzaid-Manolescu About the Hypercohomology of a Perverse Sheaf of Vanishing Cycles"? Follow your preferred style guide and register as an exception if necessary.
   445: \end{equation}
   446: 
>  447: \subsection{A Physical Proof and Generalization of a Conjecture by Abouzaid-Manolescu about the Hypercohomology of a Perverse Sheaf of Vanishing Cycles}
   448: 
   449: A hypercohomology $\text{HP}^*(M_3)$ was constructed by Abouzaid-Manolescu in \cite{AM20}, where it was conjectured to be isomorphic to instanton Floer homology assigned to $M_3$ for the complex gauge group $SL(2,\mathbb{C})$.  

- file: sample\arxiv_sources\2402.14804v1\03-Datasets.tex (line 50)
  message: Should this be "Comparison With Existing Benchmarks"? Follow your preferred style guide and register as an exception if necessary.
    48:     
    49: 
>   50: \subsection{Comparison with Existing Benchmarks}
    51: We describe the differences between~\datasetname~and 2 established benchmarks: MathVista~\cite{Lu2023MathVistaEM} and MMMU~\cite{Yue2023MMMUAM}.
    52: 

- file: sample\arxiv_sources\2402.14804v1\03-Datasets.tex (line 18)
  message: Should this be "Data Collection"? Follow your preferred style guide and register as an exception if necessary.
    16: \subsection{Data Collection}
    17: 
>   18: \paragraph{Data collection}  
    19: Our benchmark collection comprises two stages. 
    20: %

- file: sample\arxiv_sources\2402.14804v1\03-Datasets.tex (line 28)
  message: Should this be "Data Curation"? Follow your preferred style guide and register as an exception if necessary.
    26: 
    27: 
>   28: \paragraph{Data curation} 
    29: To improve the quality of our data, we undergo a four-stage data curation process with the help of 10 annotators (senior college students from science-related majors). 
    30: In the first stage, we verify the alignment of text questions and images, as Mathpix might return them in an incorrect order. We also eliminate questions with missing text or incorrect images and those with private information or offensive

- file: sample\arxiv_sources\2402.14804v1\03-Datasets.tex (line 53)
  message: Should this be "Comparing With MathVista"? Follow your preferred style guide and register as an exception if necessary.
    51: We describe the differences between~\datasetname~and 2 established benchmarks: MathVista~\cite{Lu2023MathVistaEM} and MMMU~\cite{Yue2023MMMUAM}.
    52: 
>   53: \paragraph{Comparing with MathVista} 
    54: % 
    55: MathVista is a comprehensive multimodal mathematical reasoning benchmark derived from 28 existing math-related multimodal datasets and 3 newly collected ones. However, within MathVista, approximately 20 datasets exhibit a trend where questions are annotated post-image collection by annotators, resulting in a relatively limited variability of questions, as discussed in Sec.~\ref{sec:Intro}.

- file: sample\arxiv_sources\2402.14804v1\03-Datasets.tex (line 68)
  message: Should this be "Comparing With MMMU"? Follow your preferred style guide and register as an exception if necessary.
    66: 
    67: 
>   68: \paragraph{Comparing with MMMU} 
    69: Different from MathVista and our~\datasetname~, MMMU~\cite{Yue2023MMMUAM} is designed to evaluate the multi-discipline multimodal understanding and reasoning abilities of LMMs with college-level problems. 
    70: % 

- file: sample\arxiv_sources\2402.14804v1\00-main.tex (line 139)
  message: Should this be "Measuring Mathematical Reasoning in Visual Contexts With MATH-Vision Dataset"? Follow your preferred style guide and register as an exception if necessary.
   137: 
   138: \title{Measuring Multimodal Mathematical Reasoning with \\ MATH-Vision Dataset}
>  139: % \title{Measuring Mathematical Reasoning in Visual Contexts with MATH-Vision Dataset}
   140: 
   141: % Author information can be set in various styles:

- file: sample\arxiv_sources\2402.14804v1\07-EthicsStatement.tex (line 1)
  message: Should this be "Ethics Statement"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Ethics statement}
     2: All questions of \datasetname~are from publicly available sources. Although we do not commercialize \datasetname, we should like to demonstrate that we are far from the boundary for action or infringement. 
     3: 

- file: sample\arxiv_sources\2402.14804v1\08-Appendix.tex (line 161)
  message: Should this be "Examples of GPT-4 With Image Captions"? Follow your preferred style guide and register as an exception if necessary.
   159: 
   160: 
>  161: \section{Examples of GPT-4 with Image Captions}
   162: \label{appendix:examples_with_image_captions}
   163: In this section, we provide some qualitative examples of GPT-4 with image captions, in comparison to other models like GPT-4V, Gemini Pro, and Qwen-VL-Max.

- file: sample\arxiv_sources\2402.14804v1\08-Appendix.tex (line 29)
  message: Should this be "Comparing With MathVista"? Follow your preferred style guide and register as an exception if necessary.
    27: \section{Comparison Details} \label{appendix:comparison}
    28: 
>   29: \subsection{Comparing with MathVista} 
    30: \label{appendix:compa_mathvista}
    31: \input{tables/mathvista_template}

- file: sample\arxiv_sources\2402.14804v1\08-Appendix.tex (line 62)
  message: Should this be "Comparing With MMMU"? Follow your preferred style guide and register as an exception if necessary.
    60: 
    61: 
>   62: \subsection{Comparing with MMMU} \label{appendix:compa_mmmu}
    63: In this section, we showcase some examples of different subjects of MMMU demanding sophisticated college-level domain knowledge. Figure~\ref{fig:mmmu_graph_theory}, Figure~\ref{fig:mmmu_group_theory}, and Figure~\ref{fig:mmmu_operation_research} present the subject of Graph Theory, Group Theory, and Operation Research, respectively. Moreover, typical examples of Topology and Graph Theory in our~\datasetname~are displayed in Figure~\ref{fig:ours_graph_theory_3_example} and Figure~\ref{fig:ours_graph_theory_3_example}. Although both sets of subjects are intricate mathematical disciplines, they exhibit notable differences in the nature of their posed questions. Questions in the MMMU dataset often involve advanced college-level mathematical concepts such as Kruskals algorithm, alternating group structures, and DFS Spanning Tree. In contrast, the questions in our dataset predominantly comprise puzzles that are readily solvable by middle and high school students. 
    64: 

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 110)
  message: Should this be "MM-MATH Presents Substantial Challenges for Current LMMs"? Follow your preferred style guide and register as an exception if necessary.
   108: 
   109:  
>  110: \paragraph{MM-MATH presents substantial challenges for current LMMs} From the evaluation results, we find that the most representative closed-source model to date, GPT-4o, performed the best across the board, achieving an average accuracy of 31.8\%, which significantly outperformed the best open-source model, InternVL-4B-Chat-1.5, with an average accuracy of 11.6\%. However, compared to the human-level baseline of 80.4\%, this best performance of the LMM still remains substantial room for improvement by 48.6\%.
   111: 
   112: 

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 113)
  message: Should this be "LMMs Gain Limited Benefits From Visual Contexts"? Follow your preferred style guide and register as an exception if necessary.
   111: 
   112: 
>  113: \paragraph{LMMs gain limited benefits from visual contexts} Another notable observation is that LMMs with the text-only setups (\emph{i.e.,} only questions as inputs) exhibit only slight degradation in performance compared to the multimodal setups (\emph{i.e.,} questions and images as inputs). For example, there are differences of 4.2\%, 2.7\%, and 0.8\% for the models GPT-4o, GPT-4v, and Claude-3-Opus, respectively. This result suggests that current LMMs primarily rely on linguistic knowledge to solve mathematical problems, and their utilization of visual contexts is limited. Detailed case studies are provided in Appendix~\ref{text reasoning}.
   114: \begin{figure*}[!ht]
   115:     \centering

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 138)
  message: Should this be "Conclusion From Discriminative Evaluation Dimensions and Capability Distribution"? Follow your preferred style guide and register as an exception if necessary.
   136: 
   137: 
>  138: \paragraph{Conclusion from discriminative evaluation dimensions and capability distribution} In the difficulty dimension of MM-MATH, we can see the discriminative stepwise degradations in models performance on progressively challenging subsets (\emph{e.g.,} the 10.9\%, 30.0\%, and 45.8\% accuracy scores on \textit{Easy}, \textit{Medium} and \textit{Hard} subsets for GPT-4o). This result indicates that the proposed evaluation dimensions exhibit a significant differentiation across three difficulty levels, making it more beneficial for exploring the capability shortcomings of models. In addition, the three types of knowledge points also provide us with opportunities to understand the capabilities of models from different fine-grained perspectives.
   139: 
   140: 

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 154)
  message: Should this be "Weak Comprehension of Elements in Images Is a Major Cause"? Follow your preferred style guide and register as an exception if necessary.
   152: Our main findings are detailed below.
   153: 
>  154: \paragraph{Weak comprehension of elements in images is a major cause} It is evident that errors related to the recognition of image elements or their attributes constitute the highest proportion, exceeding half of the total errors.
   155: This indicates that existing LMMs cannot yet sufficiently incorporate image information into their reasoning processes, limiting their efficacy in multimodal reasoning. Intriguingly, among closed-source LMMs---GPT-4o, GPT-4V, Claude-3-Opus, Gemini-Pro-V, and Qwen-VL-Max---the proportion of errors in image recognition are highly consistent, around 57\%. 
   156: This might imply that the visual encoder modules used by these models have common issues and cannot handle certain types of images.

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 162)
  message: Should this be "Multimodal Models Exhibit Poor Use of Theorems During Reasoning"? Follow your preferred style guide and register as an exception if necessary.
   160: 
   161: 
>  162: \paragraph{Multimodal models exhibit poor use of theorems during reasoning} We find that reasoning errors in large language models (LLMs) are often due to the incorrect application of theorems, accounting for about 40\% of overall errors. Misuse or omission of theorems misleads these LMMs, leading to errors (e.g., GPT-4V misuses the cosine rule, resulting in no solution, as detailed in Appendix~\ref{Misapplication of Theorems}). 
   163: Unlike image understanding, we find that a larger model size effectively helps reduce reasoning errors in the model.
   164: For instance, while InternVL-4B-Chat-1.5 exhibits fewer image understanding errors even with smaller model size, it still encounters more reasoning errors (636) compared to larger models such as Gemini-Pro-V (480) and Qwen-VL-Max (468).

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 166)
  message: Should this be "Calculation Is Not a Primary Issue but Reflects a Capability Gap"? Follow your preferred style guide and register as an exception if necessary.
   164: For instance, while InternVL-4B-Chat-1.5 exhibits fewer image understanding errors even with smaller model size, it still encounters more reasoning errors (636) compared to larger models such as Gemini-Pro-V (480) and Qwen-VL-Max (468).
   165: 
>  166: \paragraph{Calculation is not a primary issue but reflects a capability gap} In the process evaluation of LMMs, calculation errors constitute a relatively lower proportion. However, the error in some models (e.g., GPT-4o, 51 errors) is significantly higher compared to others (e.g., GPT-4V, 29 errors). 
   167: This indicates that while calculation is not the primary problem, equipping them with more powerful numerical computation capabilities can further boost the models' problem-solving success rates.
   168: 

- file: sample\arxiv_sources\2404.05091v4\003evaluation.tex (line 170)
  message: Should this be "Models Have an Effective Understanding of the Textual Problem"? Follow your preferred style guide and register as an exception if necessary.
   168: 
   169: 
>  170: \paragraph{Models have an effective understanding of the textual problem} As shown in Figure~\ref{fig:pie}, among all nine models from both open-source and closed-source, the proportion of errors due to misunderstanding of the textual conditions is extremely small (less than 2\% of the total errors). This suggests that the text-based capabilities of LMMs are not the bottleneck in solving multimodal mathematical problems. Instead, we should focus more on fine-grained recognition and reasoning of visual content to enhance the capabilities of LMMs.
   171: 
   172: 

- file: sample\arxiv_sources\2407.13690v2\discussion.tex (line 118)
  message: Should this be "Level-Wise Performance on MATH Test Set"? Follow your preferred style guide and register as an exception if necessary.
   116: % $q_{i}$ by some agent $\pi$ (DeepSeekMath-7B-RL here).
   117: 
>  118: % \subsection{Level-wise Performance on MATH Test Set}
   119: % To better understand the effects of different distribution of
   120: % synthetic dataset on performance on queries of different difficulty

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 6)
  message: Should this be "Data Synthesis:"? Follow your preferred style guide and register as an exception if necessary.
     4: Below we summarize the key setup details, while we include more
     5: information in Appendix~\ref{app:exp_setup}.
>    6: \paragraph{Data synthesis:}
     7: We synthesize responses using the original training queries of the MATH
     8: and GSM8K datasets.

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 192)
  message: Should this be "Comparing With Vanilla Rejection Tuning:"? Follow your preferred style guide and register as an exception if necessary.
   190: \subsection{Main Results}
   191: \label{sec:res}
>  192: \paragraph{Comparing with Vanilla Rejection Tuning:}
   193: The main results are in Table~\ref{tab:main-results}.
   194: \model~based on all four different base models outperforms the VRT

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 247)
  message: Should this be "Comparison With Previous Top-Performing Methods:"? Follow your preferred style guide and register as an exception if necessary.
   245: % training on GSM8K and MATH queries.
   246: 
>  247: \paragraph{Comparison with previous top-performing methods:}
   248: \model~achieves superior or comparable performance to previous best models.
   249: Specifically, when compared with MetaMath, \model~wins greatly in all cases.

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 272)
  message: Should this be "Additional Results:"? Follow your preferred style guide and register as an exception if necessary.
   270: tuning datasets available for advancing mathematical problem-solving.}
   271: 
>  272: \paragraph{Additional results:} For additional results, such as
   273: domain-wise performance on MATH and
   274: comparison to RL, we refer readers to Appendix~\ref{app:additional_results}.

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 330)
  message: Should this be "Scaling Behaviors of Different Data Synthesis Methods:"? Follow your preferred style guide and register as an exception if necessary.
   328: \subsection{Analysis}
   329: \label{sec:analysis}
>  330: \paragraph{Scaling behaviors of different data synthesis methods:}
   331: We study the scaling behaviors of our data synthesis approach and
   332: compare it to vanilla rejection sampling.

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 360)
  message: Should this be "Effect of One-Response Coverage:"? Follow your preferred style guide and register as an exception if necessary.
   358: main bottleneck shifts to query coverage rather than the responses themselves.
   359: 
>  360: \paragraph{Effect of one-response coverage:}
   361: In \textsection\ref{sec:dars},
   362: we describe that \darsp~can cause zero synthetic responses for easy

- file: sample\arxiv_sources\2407.13690v2\exp.tex (line 429)
  message: Should this be "Synthesis Cost:"? Follow your preferred style guide and register as an exception if necessary.
   427: \end{figure*}
   428: 
>  429: \paragraph{Synthesis cost:}
   430: \method[] generally needs more sampling trials to synthesize the same
   431: size of dataset compared to vanilla rejection tuning, as discussed in

- file: sample\arxiv_sources\2407.13690v2\neurips_2024.tex (line 137)
  message: Should this be "Diving Into Response Synthesis for Mathematical Problem Solving"? Follow your preferred style guide and register as an exception if necessary.
   135: % Difficulty Distribution in Instruction Tuning}
   136: % \title{\method: \fullmethod Exploiting the Hard Part of the Data Distribution}
>  137: % \title{Diving into Response Synthesis for Mathematical Problem Solving}
   138: % \title{\method: Diving into Response Synthesis for Mathematical
   139: % Problem Solving}

- file: sample\arxiv_sources\2407.13690v2\neurips_2024.tex (line 140)
  message: Should this be "DART-Math: Difficulty-Aware Rejection Tuning For
% Mathematical Problem Solving"? Follow your preferred style guide and register as an exception if necessary.
   138: % \title{\method: Diving into Response Synthesis for Mathematical
   139: % Problem Solving}
>  140: % \title{DART-Math: Difficulty-Aware Rejection Tuning for
   141: % Mathematical Problem Solving}
   142: \title{\raisebox{-0.17em}{\includegraphics[height=1em]{figures/logo_dart.png}}

- file: sample\arxiv_sources\2408.10342v1\Math_dance_final.tex (line 69)
  message: Should this be "Ongoing Collaborations"? Follow your preferred style guide and register as an exception if necessary.
    67: \end{quote}
    68: Mathematically, how might we encompass and understand the multiple positions and relationships in this divide?
>   69: 
    70: \section*{Ongoing collaborations}
    71: We now share ideas and talk with each other regularly in the course of our professional lives. Both of us have vested interests in discovering the many connections and potentials for math and dance collaborations. For example, I (Wolfson) have collaborated with \href{https://www.math.uci.edu/~apantano/index.html}{Alessandra Pantano} (UC Irvine, Dept. of Math) and \href{https://drama.arts.uci.edu/faculty/tara-rodman}{Tara Rodman} (UC Irvine, Dept. of Drama) to design and implement \href{https://drive.google.com/file/d/1MS7GujCzuUVl9C3I1UIyt8eYAITOs5Ni/view}{lessons for middle school students on symmetry and dance} through UCI's \href{https://sites.ps.uci.edu/mathceo/}{MathCEO} program.  I (Wilson) am currently advocating for the value of what I call a choreographic way of seeing: sharing the ``How'' of training the eye to perceive what is actually there.  Last winter, I co-taught  a \href{https://africana.sas.upenn.edu/node/7963}{graduate seminar} at the University of Pennsylvania with \href{https://anthropology.sas.upenn.edu/people/deborah-a-thomas}{Deborah Thomas} (UPenn, Dept. of Anthropology) on  kinesthetic anthropology, focusing on my particular understanding of Choreographic Time, Space and Movement.  Working with scholars and scientists has clarified the value of this training and ability not only for choreographers, but also with potential application across many disciplines.

- file: sample\arxiv_sources\2407.13690v2\method.tex (line 80)
  message: Should this be "Rejection-Based Data Synthesis Biases Towards Easy Queries:"? Follow your preferred style guide and register as an exception if necessary.
    78: %  for different queries.
    79: 
>   80: \paragraph{Rejection-based data synthesis biases towards easy queries:}
    81: Across different difficulty levels, Figure~\ref{fig:bias_pass_at_k}
    82: (Left) shows the original query distribution of the MATH training

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 483)
  message: Should this be "Observations From the Question Generation Process"? Follow your preferred style guide and register as an exception if necessary.
   481: % Insufficient Inclusion of skills
   482: 
>  483: \section{Observations from the Question Generation Process}
   484: \label{sec:notable}
   485: The question generation pipeline described in Section~\ref{sec:method} was developed through an iterative process of refining prompts and design choices, and evaluating their impact on the quality of the final questions and solutions. Notably, the inclusion of the \textit{attempted solution} and \textit{question validation} steps significantly enhanced the pipeline's effectiveness. Despite the sophistication of the pipeline and prompts, we still observe instances where models fail to follow the given instructions. This section highlights prominent failure modes at various stages of the pipeline, which human raters need to be aware of. Additionally, we explore some intriguing behaviors of the models where they successfully create interesting and creative questions. Section~\ref{subsec:human-AI} details the role of human raters in improving these questions.

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 222)
  message: Should this be "Proposed Framework: AI-Assisted Generation of Difficult Math Questions"? Follow your preferred style guide and register as an exception if necessary.
   220: 
   221: \vspace{-1mm}
>  222: \subsection{Proposed Framework: AI-assisted Generation of Difficult Math Questions}
   223: \vspace{-1mm}
   224:  

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 392)
  message: Should this be "Performance Across the Two Datasets: a Surprising Pattern "? Follow your preferred style guide and register as an exception if necessary.
   390: For generating responses, we use the MAmmoTH \citep{yue2023mammoth} codebase. The responses are graded using a GPT-4 grader, where GPT-4 Omni checks the correctness of a solution response against the ground truth solution. This allows us to account for cases where incorrect reasoning traces lead to a correct final answer. Appendix~\ref{app:prompt_eval} shows the prompt used for evaluation. During response generation, we set the temperature to 0 and top\_p to 1 for all models. All necessary compute details are discussed in Appendix~\ref{app:expts}%For open source LLMs, 2 80GB A100 GPUs and 72GB of RAM to run inference facilitated by vLLM~\citep{kwon2023efficient}. For evaluating GPT-4 Omni and GPT-4 Turbo, we use 25 parallel workers to make the API calls, and for Claude-3 Opus we use 2 workers.
   391: 
>  392: \subsection{Performance across the two datasets: A surprising pattern } 
   393: \label{subsec:yX2}
   394: 

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 440)
  message: Should this be "Generated Questions Are Effective In-Context Exemplars for MATH."? Follow your preferred style guide and register as an exception if necessary.
   438: 
   439: 
>  440: \subsection{Generated Questions are Effective In-Context Exemplars for MATH.} 
   441: \label{subsec:ICLhelp}
   442: 

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 488)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
   486: 
   487: \vspace{-1mm}
>  488: \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
   489: \vspace{-1mm}
   490: \label{subsec:human-AI}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 730)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
   728: i.e, the model takes into consideration the fact that the question involves a lot of brute force computation, despite there being no explicit check for computation complexity in the prompt, and classifies the question as invalid. We attribute such out of the box thinking behavior to the role-playing nature of our prompts. Our prompts consist of a math teacher evaluating the the fitness of the given question for being used for testing students' reasoning and analytical skills in a math exam. This leaves room open for the model to detect potential problems not explicitly accounted for in the prompts which might make the question unfit for being used for evaluation.
   729: 
>  730: % \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
   731: % \label{subsec:human-AI}
   732: % The models had a nonnegligible rate of producing very interesting and creative questions. In such cases it often failed to produce the correct solution, but the failed solution had enough correct ideas to let the human quickly finish it. 

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 808)
  message: Should this be "Considerations for Human-Annotaters"? Follow your preferred style guide and register as an exception if necessary.
   806: %  Models tend to adopt brute force approach on the original question, calculating $15^{4} + 16^{4}$. After the rephrasing,  the number $23^{17} + 17^{17}$ is too large for direct computation, and they need to understand arithmetic modulo a prime.
   807: 
>  808: \subsection{Considerations for human-annotaters}
   809: \label{app:human_ann}
   810: 

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 1051)
  message: Should this be "Skills Used for Generating the Questions"? Follow your preferred style guide and register as an exception if necessary.
  1049: % \end{table}
  1050: 
> 1051: \subsection{Skills used for generating the questions}
  1052: \label{app:skills}
  1053: We use the same skills as those extracted in \cite{Didolkar2024MetacognitiveCO}. Table~\ref{tab:skills_list_appendix} lists the skills used during the question generation process.

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 1081)
  message: Should this be "Example Outputs for Each Step of the AI Pipeline"? Follow your preferred style guide and register as an exception if necessary.
  1079: \end{table}
  1080: 
> 1081: \subsection{Example outputs for each step of the AI pipeline}
  1082: \label{app:step_ex}
  1083: In section, we present an example of a question-solution pair generation using GPT-4 Turbo, by giving the \textit{extracted} output of each of the 5 steps in the AI pipeline. The skills used in this case are \texttt{sequence\_analysis} and \texttt{polynomial\_operations}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 1176)
  message: Should this be "Skill Composition Using Different Models"? Follow your preferred style guide and register as an exception if necessary.
  1174: \end{samplebox}
  1175: 
> 1176: \subsection{Skill composition using different models}
  1177: \label{app:gen_examples}
  1178: In this section, we provide examples of the responses of different models when asked to generate a question combining two different skills. We prompt GPT-4o, Claude 3 Opus, Gemini 1.5 Pro, Llama-3-70B-Instruct and Llama-3-8B-Instruct to generate a question combining the skills \texttt{area\_calculation\_skills} and \texttt{algebraic\_manipulation\_skills}. We use the same prompt used in the \textbf{Question Generation} step (Step 2) of the proposed pipeline described in Section~\ref{sec:method} (see Appendix~\ref{app:ques_gen}). Given below are the responses of each model to the prompt.

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 880)
  message: Should this be "Efficiency and Cost of the Question Generation Pipeline"? Follow your preferred style guide and register as an exception if necessary.
   878: % It is known that larger models are better at composing skills or concepts (a phenomenon known as "compositional generalization") than smaller models. This finding aligns with conclusions drawn in \cite{arora2023theory,yu2023skillmix}.
   879: 
>  880: \subsubsection{Efficiency and cost of the question generation pipeline}
   881: \label{app:eff_cost}
   882: Below, we provide some statistics on the number of questions filtered out at different stages of the pipeline for different models. Note that these numbers are representative numbers, calculated on batches of data generated using each model. Questions in the MATH$^2$ dataset do not all necessarily belong to these batches.

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 984)
  message: Should this be "Difficulty of Questions Generated by Different Models"? Follow your preferred style guide and register as an exception if necessary.
   982: 
   983: 
>  984: \subsubsection{Difficulty of questions generated by different models}
   985: Out of the 210 questions, 116 questions were generated using GPT-4
   986: Turbo, 3 using GPT-4 Omni, 51 using Claude-3 Opus and 40 using Gemini-1.5-Pro. We consider individual subsets of dataset wherein the questions were generated by GPT-4-Turbo and Gemini-1.5-Pro and evaluate GPT-4O, GPT-4 Turbo, Claude-3 Opus and Gemini-1.5-Pro on these subsets. The results are shown in Table~\ref{tab:model_subset}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 436)
  message: Should this be "Finetuned Models Suffer More Than Pre-Trained Models."? Follow your preferred style guide and register as an exception if necessary.
   434:  %Llama-3-8B-Instruct  Similarly, at the 70B parameter scale, Llama-3-70B-Instruct suffers a drop of 52.45\% whereas MetaMath-70B and MAmmoTH-70B suffer a drop of 76.74\% and 74.11\% respectively. This observation may be explained as follows - Math specialist models such as the MAmmoTH \cite{mammoth} and MetaMath \cite{metamath} series of models are often obtained by finetuning pre-trained models on large corpuses of synthetically generated data in a supervised manner. These synthetic datasets such as the MetaMathQA \cite{metamath} and MathInstruct \cite{mammoth} are seeded using smaller datasets such as Math \cite{math} and GSM8k \cite{gsm8k}, for eg. by asking generative models to generate questions \textit{similar} to the questions in these small datasets. This procedure severely limits the diversity of synthetic datasets thereby affecting the generalization abilities of the models finetuned on these datasets.
   435: 
>  436: % \paragraph{Finetuned models suffer more than pre-trained models.}
   437: 
   438: 

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 621)
  message: Should this be "Insufficient Involvement of Skills."? Follow your preferred style guide and register as an exception if necessary.
   619: Despite the sophistication of our pipeline, models frequently exhibit several failure modes: (a) \textit{Insufficient Involvement of Skills}: Models often generate questions that either miss one of the skills completely or require a very shallow application of one or both skills. For example, a geometry question may fail to involve ratio and proportion adequately, (b) \textit{Insufficient Information}: Questions may lack essential details needed for solving, making them incomplete or ambiguous. For instance, a trigonometry question might omit necessary angles or distances, (c) \textit{Unsolvable or Computationally Intractable Questions}: Some questions generated are either unsolvable or require excessive brute-force calculations, which are impractical for evaluating reasoning abilities, (d) \textit{Nonsensical Questions}: Models sometimes produce questions that are logically inconsistent, confusing, or ambiguous, such as a probability problem with unclear parameters or an impossible geometry scenario, (e) \textit{Deceitful Solutions}: Occasionally, models fabricate solutions to nonsensical or unsolvable questions, presenting incorrect logic as plausible reasoning and (f) \textit{Finding a Needle in the Haystack}: Long and complex validation prompts sometimes cause models to confuse or overlook the specified skills, leading to incorrect evaluations. 
   620: 
>  621: \paragraph{Insufficient involvement of skills.} Despite clearly specifying that solving the question should necessarily require a rigorous application of both skills, the models often generate questions that either miss one of the skills completely or require a very shallow application of one (while the other one is sufficiently involved) or both skills. This is the most prominent failure mode of the models in the context of question generation. This leads to potentially easy questions, defeating the purpose of skill composition. Consider the question given below which was generated by Claude Opus when asked to combine the skills \texttt{ratio\_and\_proportion} and \texttt{geometry}. \\
   622: 
   623: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 629)
  message: Should this be "Insufficient Information in the Questions."? Follow your preferred style guide and register as an exception if necessary.
   627: Upon careful examination of the question, we note that although the question tests \texttt{geometry}, the involvement of \texttt{ratio\_and\_proportions} is practically non-existent. Further, the question validation step in some cases also fails to identify these flaws. Supplying multi-turn human-AI interactions where the user prompts a chatbot to generate a question combining two skills, in-context during the generation step helps the models to avoid such questions to a certain extent. Further, to make the question validation step more robust to such questions, we prompt the model to ensure that the complexity of each skill application in the question being validated in similar to or more than the complexity of these skills in the reference examples present in the skill descriptions. The combination of these two techniques helps us nearly eliminate questions where the absent one of the skills is absent completely and reduce questions involving shallow application of skills to a significant extent.
   628: 
>  629: \paragraph{Insufficient information in the questions.} Another common failure mode of the pipeline is the generated questions missing information or details essential for solving the question. For example in the question given below which is supposed to combine the skills \texttt{understanding\_and\_applying\_floor\_and\_ceiling\_functions} and \texttt{basic\_trigonometry}, lacks sufficient detail about the inclinations and elevations of the paths relative to the streetlight's position which is necessary to answer the question.
   630: 
   631: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 675)
  message: Should this be "Finding a Needle in the Haystack."? Follow your preferred style guide and register as an exception if necessary.
   673: While solving this question, the model arrives at the conditions $sin(\theta) = 2$ or $sin(\theta) = -2$. Clearly, these conditions have no solutions since $-1 \leq sin(\theta) \leq 1, \forall \theta \in [0, 2\pi]$. However, the model goes on to argue that the the closest values to 2 and -2 in the range of $\sin(\theta)$ are 1 and -1, and thus, goes on to solve the question for $sin(\theta) = 1$ or $sin(\theta) = -1$.
   674: 
>  675: \paragraph{Finding a needle in the haystack.} In an attempt to make the \textit{question validation} step robust to as many failure modes as possible, we come up with a long and sophisticated prompt (see Appendix~\ref{app:prompt_val} for an example of this prompt). To elaborate, the validation prompt comprises of 1.) skill descriptions consisting of 3 exemplars for each of the 2 skills, 2.) 6 very long validation exemplars 3.) rest of the prompt consisting of the 7 conditions described in Section~\ref{sec:ques_val}. In prior iterations of the validation prompt, the names of the two skills which are supposed to be combined in the question, were mentioned only once throughout the prompt. In such a case, we observed that more often than not, model confused the pair of skills at hand, with skills mentioned in the validation exemplars. We also observed cases where the model was unable to locate the original skill names, came up with its own skill names depending on the skill exemplars provided in the skill descriptions. More specifically, while checking the question for \textbf{Dual Skill Requirement} in Section~\ref{sec:ques_val}, the models would check the question for the presence of skills distinct from the pair of skills at hand. We attribute this phenomenon to the the \textit{lost in the middle} or \textit{finding a needle in the haystack} challenges faced by LLMs. We provide an example of the phenomenon below. Notice how in Point 3 of the reasoning trace the model checks the question for the presence of two completely unrelated skills. We were able to nearly eliminate this problem by replacing referential terms (such as \textit{above given skills}, \textit{these skills}, etc.) to the two skills by the skill names.
   676: 
   677: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\example_paper.tex (line 716)
  message: Should this be "Thinking Out of the Box."? Follow your preferred style guide and register as an exception if necessary.
   714: Despite struggling with the failure modes described above, there also exist cases where the models exhibit positively surprising and creative behaviors. We talk about some of them below.
   715: 
>  716: \paragraph{Thinking out of the box.} Although rare, we observe instances where the models get creative while validating the question. Consider the question below
   717: 
   718: \begin{example}

- file: sample\arxiv_sources\2407.13690v2\appendix.tex (line 3)
  message: Should this be "Comparison to Methods Based on Non-Vanilla Rejection
Sampling"? Follow your preferred style guide and register as an exception if necessary.
     1: \appendix
     2: 
>    3: \section{Comparison to Methods Based on Non-vanilla Rejection
     4: Sampling}\label{app:comparison}
     5: 

- file: sample\arxiv_sources\2407.13690v2\appendix.tex (line 53)
  message: Should this be "Details of Re-Implementing Data Synthesis Strategies of
ToRA and MARIO"? Follow your preferred style guide and register as an exception if necessary.
    51: \input{tables/level_wise_math_coverage}
    52: 
>   53: \subsection{Details of Re-implementing Data Synthesis Strategies of
    54: ToRA and MARIO}
    55: 

- file: sample\arxiv_sources\2407.13690v2\appendix.tex (line 300)
  message: Should this be "Domain-Wise Performance on MATH"? Follow your preferred style guide and register as an exception if necessary.
   298: \section{Additional Results}\label{app:additional_results}
   299: 
>  300: \subsection{Domain-wise Performance on MATH}\label{app:domain_wise_math}
   301: 
   302: We test the domain-wise performance on MATH for rejection-tuned

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 489)
  message: Should this be "Observations From the Question Generation Process"? Follow your preferred style guide and register as an exception if necessary.
   487: % Insufficient Inclusion of skills
   488: 
>  489: \section{Observations from the Question Generation Process}
   490: \label{sec:notable}
   491: The question generation pipeline described in Section~\ref{sec:method} was developed through an iterative process of refining prompts and design choices, and evaluating their impact on the quality of the final questions and solutions. Notably, the inclusion of the \textit{attempted solution} and \textit{question validation} steps significantly enhanced the pipeline's effectiveness. Despite the sophistication of the pipeline and prompts, we still observe instances where models fail to follow the given instructions. This section highlights prominent failure modes at various stages of the pipeline, which human raters need to be aware of. Additionally, we explore some intriguing behaviors of the models where they successfully create interesting and creative questions. Section~\ref{subsec:human-AI} details the role of human raters in improving these questions.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2102)
  message: Should this be "Observations From the Question Generation Process"? Follow your preferred style guide and register as an exception if necessary.
  2100: % Insufficient Inclusion of skills
  2101: 
> 2102: \section{Observations from the Question Generation Process}
  2103: \label{sec:notable}
  2104: The question generation pipeline described in Section~\ref{sec:method} was developed through an iterative process of refining prompts and design choices, and evaluating their impact on the quality of the final questions and solutions. Notably, the inclusion of the \textit{attempted solution} and \textit{question validation} steps significantly enhanced the pipeline's effectiveness. Despite the sophistication of the pipeline and prompts, we still observe instances where models fail to follow the given instructions. This section highlights prominent failure modes at various stages of the pipeline, which human raters need to be aware of. Additionally, we explore some intriguing behaviors of the models where they successfully create interesting and creative questions. Section~\ref{subsec:human-AI} details the role of human raters in improving these questions.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 228)
  message: Should this be "Proposed Framework: AI-Assisted Generation of Difficult Math Questions"? Follow your preferred style guide and register as an exception if necessary.
   226: 
   227: \vspace{-1mm}
>  228: \subsection{Proposed Framework: AI-assisted Generation of Difficult Math Questions}
   229: \vspace{-1mm}
   230:  

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 398)
  message: Should this be "Performance Across the Two Datasets: a Surprising Pattern "? Follow your preferred style guide and register as an exception if necessary.
   396: For generating responses, we use the MAmmoTH \citep{yue2023mammoth} codebase. The responses are graded using a GPT-4 grader, where GPT-4 Omni checks the correctness of a solution response against the ground truth solution. This allows us to account for cases where incorrect reasoning traces lead to a correct final answer. Appendix~\ref{app:prompt_eval} shows the prompt used for evaluation. During response generation, we set the temperature to 0 and top\_p to 1 for all models. All necessary compute details are discussed in Appendix~\ref{app:expts}%For open source LLMs, 2 80GB A100 GPUs and 72GB of RAM to run inference facilitated by vLLM~\citep{kwon2023efficient}. For evaluating GPT-4 Omni and GPT-4 Turbo, we use 25 parallel workers to make the API calls, and for Claude-3 Opus we use 2 workers.
   397: 
>  398: \subsection{Performance across the two datasets: A surprising pattern } 
   399: \label{subsec:yX2}
   400: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 446)
  message: Should this be "Generated Questions Are Effective In-Context Exemplars for MATH."? Follow your preferred style guide and register as an exception if necessary.
   444: 
   445: 
>  446: \subsection{Generated Questions are Effective In-Context Exemplars for MATH.} 
   447: \label{subsec:ICLhelp}
   448: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 494)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
   492: 
   493: \vspace{-1mm}
>  494: \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
   495: \vspace{-1mm}
   496: \label{subsec:human-AI}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 739)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
   737: i.e, the model takes into consideration the fact that the question involves a lot of brute force computation, despite there being no explicit check for computation complexity in the prompt, and classifies the question as invalid. We attribute such out of the box thinking behavior to the role-playing nature of our prompts. Our prompts consist of a math teacher evaluating the the fitness of the given question for being used for testing students' reasoning and analytical skills in a math exam. This leaves room open for the model to detect potential problems not explicitly accounted for in the prompts which might make the question unfit for being used for evaluation.
   738: 
>  739: % \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
   740: % \label{subsec:human-AI}
   741: % The models had a nonnegligible rate of producing very interesting and creative questions. In such cases it often failed to produce the correct solution, but the failed solution had enough correct ideas to let the human quickly finish it. 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 817)
  message: Should this be "Considerations for Human-Annotaters"? Follow your preferred style guide and register as an exception if necessary.
   815: %  Models tend to adopt brute force approach on the original question, calculating $15^{4} + 16^{4}$. After the rephrasing,  the number $23^{17} + 17^{17}$ is too large for direct computation, and they need to understand arithmetic modulo a prime.
   816: 
>  817: \subsection{Considerations for human-annotaters}
   818: \label{app:human_ann}
   819: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 1060)
  message: Should this be "Skills Used for Generating the Questions"? Follow your preferred style guide and register as an exception if necessary.
  1058: % \end{table}
  1059: 
> 1060: \subsection{Skills used for generating the questions}
  1061: \label{app:skills}
  1062: We use the same skills as those extracted in \cite{Didolkar2024MetacognitiveCO}. Table~\ref{tab:skills_list_appendix} lists the skills used during the question generation process.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 1090)
  message: Should this be "Example Outputs for Each Step of the AI Pipeline"? Follow your preferred style guide and register as an exception if necessary.
  1088: \end{table}
  1089: 
> 1090: \subsection{Example outputs for each step of the AI pipeline}
  1091: \label{app:step_ex}
  1092: In section, we present an example of a question-solution pair generation using GPT-4 Turbo, by giving the \textit{extracted} output of each of the 5 steps in the AI pipeline. The skills used in this case are \texttt{sequence\_analysis} and \texttt{polynomial\_operations}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 1185)
  message: Should this be "Skill Composition Using Different Models"? Follow your preferred style guide and register as an exception if necessary.
  1183: \end{samplebox}
  1184: 
> 1185: \subsection{Skill composition using different models}
  1186: \label{app:gen_examples}
  1187: In this section, we provide examples of the responses of different models when asked to generate a question combining two different skills. We prompt GPT-4o, Claude 3 Opus, Gemini 1.5 Pro, Llama-3-70B-Instruct and Llama-3-8B-Instruct to generate a question combining the skills \texttt{area\_calculation\_skills} and \texttt{algebraic\_manipulation\_skills}. We use the same prompt used in the \textbf{Question Generation} step (Step 2) of the proposed pipeline described in Section~\ref{sec:method} (see Appendix~\ref{app:ques_gen}). Given below are the responses of each model to the prompt.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 1841)
  message: Should this be "Proposed Framework: AI-Assisted Generation of Difficult Math Questions"? Follow your preferred style guide and register as an exception if necessary.
  1839: 
  1840: \vspace{-1mm}
> 1841: \subsection{Proposed Framework: AI-assisted Generation of Difficult Math Questions}
  1842: \vspace{-1mm}
  1843:  

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2011)
  message: Should this be "Performance Across the Two Datasets: a Surprising Pattern "? Follow your preferred style guide and register as an exception if necessary.
  2009: For generating responses, we use the MAmmoTH \citep{yue2023mammoth} codebase. The responses are graded using a GPT-4 grader, where GPT-4 Omni checks the correctness of a solution response against the ground truth solution. This allows us to account for cases where incorrect reasoning traces lead to a correct final answer. Appendix~\ref{app:prompt_eval} shows the prompt used for evaluation. During response generation, we set the temperature to 0 and top\_p to 1 for all models. All necessary compute details are discussed in Appendix~\ref{app:expts}%For open source LLMs, 2 80GB A100 GPUs and 72GB of RAM to run inference facilitated by vLLM~\citep{kwon2023efficient}. For evaluating GPT-4 Omni and GPT-4 Turbo, we use 25 parallel workers to make the API calls, and for Claude-3 Opus we use 2 workers.
  2010: 
> 2011: \subsection{Performance across the two datasets: A surprising pattern } 
  2012: \label{subsec:yX2}
  2013: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2059)
  message: Should this be "Generated Questions Are Effective In-Context Exemplars for MATH."? Follow your preferred style guide and register as an exception if necessary.
  2057: 
  2058: 
> 2059: \subsection{Generated Questions are Effective In-Context Exemplars for MATH.} 
  2060: \label{subsec:ICLhelp}
  2061: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2107)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
  2105: 
  2106: \vspace{-1mm}
> 2107: \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
  2108: \vspace{-1mm}
  2109: \label{subsec:human-AI}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2349)
  message: Should this be "Creative Questions: Examples of Synergy From Human-AI Interaction "? Follow your preferred style guide and register as an exception if necessary.
  2347: i.e, the model takes into consideration the fact that the question involves a lot of brute force computation, despite there being no explicit check for computation complexity in the prompt, and classifies the question as invalid. We attribute such out of the box thinking behavior to the role-playing nature of our prompts. Our prompts consist of a math teacher evaluating the the fitness of the given question for being used for testing students' reasoning and analytical skills in a math exam. This leaves room open for the model to detect potential problems not explicitly accounted for in the prompts which might make the question unfit for being used for evaluation.
  2348: 
> 2349: % \subsection{Creative questions: Examples of Synergy from Human-AI interaction } 
  2350: % \label{subsec:human-AI}
  2351: % The models had a nonnegligible rate of producing very interesting and creative questions. In such cases it often failed to produce the correct solution, but the failed solution had enough correct ideas to let the human quickly finish it. 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2427)
  message: Should this be "Considerations for Human-Annotaters"? Follow your preferred style guide and register as an exception if necessary.
  2425: %  Models tend to adopt brute force approach on the original question, calculating $15^{4} + 16^{4}$. After the rephrasing,  the number $23^{17} + 17^{17}$ is too large for direct computation, and they need to understand arithmetic modulo a prime.
  2426: 
> 2427: \subsection{Considerations for human-annotaters}
  2428: \label{app:human_ann}
  2429: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2670)
  message: Should this be "Skills Used for Generating the Questions"? Follow your preferred style guide and register as an exception if necessary.
  2668: % \end{table}
  2669: 
> 2670: \subsection{Skills used for generating the questions}
  2671: \label{app:skills}
  2672: We use the same skills as those extracted in \cite{Didolkar2024MetacognitiveCO}. Table~\ref{tab:skills_list_appendix} lists the skills used during the question generation process.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2700)
  message: Should this be "Example Outputs for Each Step of the AI Pipeline"? Follow your preferred style guide and register as an exception if necessary.
  2698: \end{table}
  2699: 
> 2700: \subsection{Example outputs for each step of the AI pipeline}
  2701: \label{app:step_ex}
  2702: In section, we present an example of a question-solution pair generation using GPT-4 Turbo, by giving the \textit{extracted} output of each of the 5 steps in the AI pipeline. The skills used in this case are \texttt{sequence\_analysis} and \texttt{polynomial\_operations}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2795)
  message: Should this be "Skill Composition Using Different Models"? Follow your preferred style guide and register as an exception if necessary.
  2793: \end{samplebox}
  2794: 
> 2795: \subsection{Skill composition using different models}
  2796: \label{app:gen_examples}
  2797: In this section, we provide examples of the responses of different models when asked to generate a question combining two different skills. We prompt GPT-4o, Claude 3 Opus, Gemini 1.5 Pro, Llama-3-70B-Instruct and Llama-3-8B-Instruct to generate a question combining the skills \texttt{area\_calculation\_skills} and \texttt{algebraic\_manipulation\_skills}. We use the same prompt used in the \textbf{Question Generation} step (Step 2) of the proposed pipeline described in Section~\ref{sec:method} (see Appendix~\ref{app:ques_gen}). Given below are the responses of each model to the prompt.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 889)
  message: Should this be "Efficiency and Cost of the Question Generation Pipeline"? Follow your preferred style guide and register as an exception if necessary.
   887: % It is known that larger models are better at composing skills or concepts (a phenomenon known as "compositional generalization") than smaller models. This finding aligns with conclusions drawn in \cite{arora2023theory,yu2023skillmix}.
   888: 
>  889: \subsubsection{Efficiency and cost of the question generation pipeline}
   890: \label{app:eff_cost}
   891: Below, we provide some statistics on the number of questions filtered out at different stages of the pipeline for different models. Note that these numbers are representative numbers, calculated on batches of data generated using each model. Questions in the MATH$^2$ dataset do not all necessarily belong to these batches.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 993)
  message: Should this be "Difficulty of Questions Generated by Different Models"? Follow your preferred style guide and register as an exception if necessary.
   991: 
   992: 
>  993: \subsubsection{Difficulty of questions generated by different models}
   994: Out of the 210 questions, 116 questions were generated using GPT-4
   995: Turbo, 3 using GPT-4 Omni, 51 using Claude-3 Opus and 40 using Gemini-1.5-Pro. We consider individual subsets of dataset wherein the questions were generated by GPT-4-Turbo and Gemini-1.5-Pro and evaluate GPT-4O, GPT-4 Turbo, Claude-3 Opus and Gemini-1.5-Pro on these subsets. The results are shown in Table~\ref{tab:model_subset}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2499)
  message: Should this be "Efficiency and Cost of the Question Generation Pipeline"? Follow your preferred style guide and register as an exception if necessary.
  2497: % It is known that larger models are better at composing skills or concepts (a phenomenon known as "compositional generalization") than smaller models. This finding aligns with conclusions drawn in \cite{arora2023theory,yu2023skillmix}.
  2498: 
> 2499: \subsubsection{Efficiency and cost of the question generation pipeline}
  2500: \label{app:eff_cost}
  2501: Below, we provide some statistics on the number of questions filtered out at different stages of the pipeline for different models. Note that these numbers are representative numbers, calculated on batches of data generated using each model. Questions in the MATH$^2$ dataset do not all necessarily belong to these batches.

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2603)
  message: Should this be "Difficulty of Questions Generated by Different Models"? Follow your preferred style guide and register as an exception if necessary.
  2601: 
  2602: 
> 2603: \subsubsection{Difficulty of questions generated by different models}
  2604: Out of the 210 questions, 116 questions were generated using GPT-4
  2605: Turbo, 3 using GPT-4 Omni, 51 using Claude-3 Opus and 40 using Gemini-1.5-Pro. We consider individual subsets of dataset wherein the questions were generated by GPT-4-Turbo and Gemini-1.5-Pro and evaluate GPT-4O, GPT-4 Turbo, Claude-3 Opus and Gemini-1.5-Pro on these subsets. The results are shown in Table~\ref{tab:model_subset}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 442)
  message: Should this be "Finetuned Models Suffer More Than Pre-Trained Models."? Follow your preferred style guide and register as an exception if necessary.
   440:  %Llama-3-8B-Instruct  Similarly, at the 70B parameter scale, Llama-3-70B-Instruct suffers a drop of 52.45\% whereas MetaMath-70B and MAmmoTH-70B suffer a drop of 76.74\% and 74.11\% respectively. This observation may be explained as follows - Math specialist models such as the MAmmoTH \cite{mammoth} and MetaMath \cite{metamath} series of models are often obtained by finetuning pre-trained models on large corpuses of synthetically generated data in a supervised manner. These synthetic datasets such as the MetaMathQA \cite{metamath} and MathInstruct \cite{mammoth} are seeded using smaller datasets such as Math \cite{math} and GSM8k \cite{gsm8k}, for eg. by asking generative models to generate questions \textit{similar} to the questions in these small datasets. This procedure severely limits the diversity of synthetic datasets thereby affecting the generalization abilities of the models finetuned on these datasets.
   441: 
>  442: % \paragraph{Finetuned models suffer more than pre-trained models.}
   443: 
   444: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 630)
  message: Should this be "Insufficient Involvement of Skills."? Follow your preferred style guide and register as an exception if necessary.
   628: Despite the sophistication of our pipeline, models frequently exhibit several failure modes: (a) \textit{Insufficient Involvement of Skills}: Models often generate questions that either miss one of the skills completely or require a very shallow application of one or both skills. For example, a geometry question may fail to involve ratio and proportion adequately, (b) \textit{Insufficient Information}: Questions may lack essential details needed for solving, making them incomplete or ambiguous. For instance, a trigonometry question might omit necessary angles or distances, (c) \textit{Unsolvable or Computationally Intractable Questions}: Some questions generated are either unsolvable or require excessive brute-force calculations, which are impractical for evaluating reasoning abilities, (d) \textit{Nonsensical Questions}: Models sometimes produce questions that are logically inconsistent, confusing, or ambiguous, such as a probability problem with unclear parameters or an impossible geometry scenario, (e) \textit{Deceitful Solutions}: Occasionally, models fabricate solutions to nonsensical or unsolvable questions, presenting incorrect logic as plausible reasoning and (f) \textit{Finding a Needle in the Haystack}: Long and complex validation prompts sometimes cause models to confuse or overlook the specified skills, leading to incorrect evaluations. 
   629: 
>  630: \paragraph{Insufficient involvement of skills.} Despite clearly specifying that solving the question should necessarily require a rigorous application of both skills, the models often generate questions that either miss one of the skills completely or require a very shallow application of one (while the other one is sufficiently involved) or both skills. This is the most prominent failure mode of the models in the context of question generation. This leads to potentially easy questions, defeating the purpose of skill composition. Consider the question given below which was generated by Claude Opus when asked to combine the skills \texttt{ratio\_and\_proportion} and \texttt{geometry}. \\
   631: 
   632: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 638)
  message: Should this be "Insufficient Information in the Questions."? Follow your preferred style guide and register as an exception if necessary.
   636: Upon careful examination of the question, we note that although the question tests \texttt{geometry}, the involvement of \texttt{ratio\_and\_proportions} is practically non-existent. Further, the question validation step in some cases also fails to identify these flaws. Supplying multi-turn human-AI interactions where the user prompts a chatbot to generate a question combining two skills, in-context during the generation step helps the models to avoid such questions to a certain extent. Further, to make the question validation step more robust to such questions, we prompt the model to ensure that the complexity of each skill application in the question being validated in similar to or more than the complexity of these skills in the reference examples present in the skill descriptions. The combination of these two techniques helps us nearly eliminate questions where the absent one of the skills is absent completely and reduce questions involving shallow application of skills to a significant extent.
   637: 
>  638: \paragraph{Insufficient information in the questions.} Another common failure mode of the pipeline is the generated questions missing information or details essential for solving the question. For example in the question given below which is supposed to combine the skills \texttt{understanding\_and\_applying\_floor\_and\_ceiling\_functions} and \texttt{basic\_trigonometry}, lacks sufficient detail about the inclinations and elevations of the paths relative to the streetlight's position which is necessary to answer the question.
   639: 
   640: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 684)
  message: Should this be "Finding a Needle in the Haystack."? Follow your preferred style guide and register as an exception if necessary.
   682: While solving this question, the model arrives at the conditions $sin(\theta) = 2$ or $sin(\theta) = -2$. Clearly, these conditions have no solutions since $-1 \leq sin(\theta) \leq 1, \forall \theta \in [0, 2\pi]$. However, the model goes on to argue that the the closest values to 2 and -2 in the range of $\sin(\theta)$ are 1 and -1, and thus, goes on to solve the question for $sin(\theta) = 1$ or $sin(\theta) = -1$.
   683: 
>  684: \paragraph{Finding a needle in the haystack.} In an attempt to make the \textit{question validation} step robust to as many failure modes as possible, we come up with a long and sophisticated prompt (see Appendix~\ref{app:prompt_val} for an example of this prompt). To elaborate, the validation prompt comprises of 1.) skill descriptions consisting of 3 exemplars for each of the 2 skills, 2.) 6 very long validation exemplars 3.) rest of the prompt consisting of the 7 conditions described in Section~\ref{sec:ques_val}. In prior iterations of the validation prompt, the names of the two skills which are supposed to be combined in the question, were mentioned only once throughout the prompt. In such a case, we observed that more often than not, model confused the pair of skills at hand, with skills mentioned in the validation exemplars. We also observed cases where the model was unable to locate the original skill names, came up with its own skill names depending on the skill exemplars provided in the skill descriptions. More specifically, while checking the question for \textbf{Dual Skill Requirement} in Section~\ref{sec:ques_val}, the models would check the question for the presence of skills distinct from the pair of skills at hand. We attribute this phenomenon to the the \textit{lost in the middle} or \textit{finding a needle in the haystack} challenges faced by LLMs. We provide an example of the phenomenon below. Notice how in Point 3 of the reasoning trace the model checks the question for the presence of two completely unrelated skills. We were able to nearly eliminate this problem by replacing referential terms (such as \textit{above given skills}, \textit{these skills}, etc.) to the two skills by the skill names.
   685: 
   686: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 725)
  message: Should this be "Thinking Out of the Box."? Follow your preferred style guide and register as an exception if necessary.
   723: Despite struggling with the failure modes described above, there also exist cases where the models exhibit positively surprising and creative behaviors. We talk about some of them below.
   724: 
>  725: \paragraph{Thinking out of the box.} Although rare, we observe instances where the models get creative while validating the question. Consider the question below
   726: 
   727: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2055)
  message: Should this be "Finetuned Models Suffer More Than Pre-Trained Models."? Follow your preferred style guide and register as an exception if necessary.
  2053:  %Llama-3-8B-Instruct  Similarly, at the 70B parameter scale, Llama-3-70B-Instruct suffers a drop of 52.45\% whereas MetaMath-70B and MAmmoTH-70B suffer a drop of 76.74\% and 74.11\% respectively. This observation may be explained as follows - Math specialist models such as the MAmmoTH \cite{mammoth} and MetaMath \cite{metamath} series of models are often obtained by finetuning pre-trained models on large corpuses of synthetically generated data in a supervised manner. These synthetic datasets such as the MetaMathQA \cite{metamath} and MathInstruct \cite{mammoth} are seeded using smaller datasets such as Math \cite{math} and GSM8k \cite{gsm8k}, for eg. by asking generative models to generate questions \textit{similar} to the questions in these small datasets. This procedure severely limits the diversity of synthetic datasets thereby affecting the generalization abilities of the models finetuned on these datasets.
  2054: 
> 2055: % \paragraph{Finetuned models suffer more than pre-trained models.}
  2056: 
  2057: 

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2240)
  message: Should this be "Insufficient Involvement of Skills."? Follow your preferred style guide and register as an exception if necessary.
  2238: Despite the sophistication of our pipeline, models frequently exhibit several failure modes: (a) \textit{Insufficient Involvement of Skills}: Models often generate questions that either miss one of the skills completely or require a very shallow application of one or both skills. For example, a geometry question may fail to involve ratio and proportion adequately, (b) \textit{Insufficient Information}: Questions may lack essential details needed for solving, making them incomplete or ambiguous. For instance, a trigonometry question might omit necessary angles or distances, (c) \textit{Unsolvable or Computationally Intractable Questions}: Some questions generated are either unsolvable or require excessive brute-force calculations, which are impractical for evaluating reasoning abilities, (d) \textit{Nonsensical Questions}: Models sometimes produce questions that are logically inconsistent, confusing, or ambiguous, such as a probability problem with unclear parameters or an impossible geometry scenario, (e) \textit{Deceitful Solutions}: Occasionally, models fabricate solutions to nonsensical or unsolvable questions, presenting incorrect logic as plausible reasoning and (f) \textit{Finding a Needle in the Haystack}: Long and complex validation prompts sometimes cause models to confuse or overlook the specified skills, leading to incorrect evaluations. 
  2239: 
> 2240: \paragraph{Insufficient involvement of skills.} Despite clearly specifying that solving the question should necessarily require a rigorous application of both skills, the models often generate questions that either miss one of the skills completely or require a very shallow application of one (while the other one is sufficiently involved) or both skills. This is the most prominent failure mode of the models in the context of question generation. This leads to potentially easy questions, defeating the purpose of skill composition. Consider the question given below which was generated by Claude Opus when asked to combine the skills \texttt{ratio\_and\_proportion} and \texttt{geometry}. \\
  2241: 
  2242: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2248)
  message: Should this be "Insufficient Information in the Questions."? Follow your preferred style guide and register as an exception if necessary.
  2246: Upon careful examination of the question, we note that although the question tests \texttt{geometry}, the involvement of \texttt{ratio\_and\_proportions} is practically non-existent. Further, the question validation step in some cases also fails to identify these flaws. Supplying multi-turn human-AI interactions where the user prompts a chatbot to generate a question combining two skills, in-context during the generation step helps the models to avoid such questions to a certain extent. Further, to make the question validation step more robust to such questions, we prompt the model to ensure that the complexity of each skill application in the question being validated in similar to or more than the complexity of these skills in the reference examples present in the skill descriptions. The combination of these two techniques helps us nearly eliminate questions where the absent one of the skills is absent completely and reduce questions involving shallow application of skills to a significant extent.
  2247: 
> 2248: \paragraph{Insufficient information in the questions.} Another common failure mode of the pipeline is the generated questions missing information or details essential for solving the question. For example in the question given below which is supposed to combine the skills \texttt{understanding\_and\_applying\_floor\_and\_ceiling\_functions} and \texttt{basic\_trigonometry}, lacks sufficient detail about the inclinations and elevations of the paths relative to the streetlight's position which is necessary to answer the question.
  2249: 
  2250: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2294)
  message: Should this be "Finding a Needle in the Haystack."? Follow your preferred style guide and register as an exception if necessary.
  2292: While solving this question, the model arrives at the conditions $sin(\theta) = 2$ or $sin(\theta) = -2$. Clearly, these conditions have no solutions since $-1 \leq sin(\theta) \leq 1, \forall \theta \in [0, 2\pi]$. However, the model goes on to argue that the the closest values to 2 and -2 in the range of $\sin(\theta)$ are 1 and -1, and thus, goes on to solve the question for $sin(\theta) = 1$ or $sin(\theta) = -1$.
  2293: 
> 2294: \paragraph{Finding a needle in the haystack.} In an attempt to make the \textit{question validation} step robust to as many failure modes as possible, we come up with a long and sophisticated prompt (see Appendix~\ref{app:prompt_val} for an example of this prompt). To elaborate, the validation prompt comprises of 1.) skill descriptions consisting of 3 exemplars for each of the 2 skills, 2.) 6 very long validation exemplars 3.) rest of the prompt consisting of the 7 conditions described in Section~\ref{sec:ques_val}. In prior iterations of the validation prompt, the names of the two skills which are supposed to be combined in the question, were mentioned only once throughout the prompt. In such a case, we observed that more often than not, model confused the pair of skills at hand, with skills mentioned in the validation exemplars. We also observed cases where the model was unable to locate the original skill names, came up with its own skill names depending on the skill exemplars provided in the skill descriptions. More specifically, while checking the question for \textbf{Dual Skill Requirement} in Section~\ref{sec:ques_val}, the models would check the question for the presence of skills distinct from the pair of skills at hand. We attribute this phenomenon to the the \textit{lost in the middle} or \textit{finding a needle in the haystack} challenges faced by LLMs. We provide an example of the phenomenon below. Notice how in Point 3 of the reasoning trace the model checks the question for the presence of two completely unrelated skills. We were able to nearly eliminate this problem by replacing referential terms (such as \textit{above given skills}, \textit{these skills}, etc.) to the two skills by the skill names.
  2295: 
  2296: \begin{example}

- file: sample\arxiv_sources\2407.21009v4\arxiv.tex (line 2335)
  message: Should this be "Thinking Out of the Box."? Follow your preferred style guide and register as an exception if necessary.
  2333: Despite struggling with the failure modes described above, there also exist cases where the models exhibit positively surprising and creative behaviors. We talk about some of them below.
  2334: 
> 2335: \paragraph{Thinking out of the box.} Although rare, we observe instances where the models get creative while validating the question. Consider the question below
  2336: 
  2337: \begin{example}

- file: sample\arxiv_sources\2409.02834v3\03-Datasets.tex (line 42)
  message: Should this be "Comparison With Existing Datasets"? Follow your preferred style guide and register as an exception if necessary.
    40: 
    41: \vspace{-2mm}
>   42: \subsection{Comparison with Existing Datasets}
    43: To clarify the characteristics of our CMM-Math, we compare it with multiple existing mathematical benchmarks, including textual datasets (e.g., MATH, GSM8K, MathQA) and multimodal datasets (e.g., MMMU, MATHVISTA, MATH-V, and We-Math), as shown in Table \ref{table: comparison}. 
    44: % CMM-Math has a rich dataset that is comparable to the MathQA dataset and far surpasses other existing benchmarks such as MATHVISTA, MATH-V. 

- file: sample\arxiv_sources\2411.00387v3\appendix.tex (line 91)
  message: Should this be "Fine-Tuning vs In-Context Learning."? Follow your preferred style guide and register as an exception if necessary.
    89: 
    90: \input{tables/finetune_gpt}
>   91: \paragraph{Fine-tuning vs In-context learning.} 
    92: Table \ref{tab:fine_tune} shows the comparison result on main attributes between fine-tuned and directly vanilla-referenced GPT3.5. Notably, the fine-tuned GPT-3.5 model achieves an accuracy of 67.4\% in the one-sentence context. However, its performance diminishes as the context length increases, with a noticeable drop to 66.9\% for ten sentences and further down to 62.2\% for full manuscript-length context. 
    93: Such diminishing return for fine-tuned models with longer contexts indicates that fine-tuning amplifies sensitivity to the introduction of noisy or less relevant information when longer contexts are involved. The observation also could point to challenges in the fine-tuning process for long-context LLMs, which require more refined techniques to handle context length effectively.

- file: sample\arxiv_sources\2411.00387v3\appendix.tex (line 102)
  message: Should this be "Sub-Dataset Selection."? Follow your preferred style guide and register as an exception if necessary.
   100: \subsection{Setup}
   101: 
>  102: \paragraph{Sub-dataset Selection.}
   103: Building on the main experimental results, we select a subset of mathematical symbols from \ours datasetparticularly those frequently misclassifiedto analyze the model's failure modes.
   104: 

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 47)
  message: Should this be "SBI-RAG: Enhancing Math Word Problem Solving for Students Through Schema-Based Instruction and Retrieval-Augmented Generation"? Follow your preferred style guide and register as an exception if necessary.
    45: 
    46: 
>   47: \title{SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation}
    48: 
    49: 

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 494)
  message: Should this be "Appendix / Supplemental Material"? Follow your preferred style guide and register as an exception if necessary.
   492: \appendix
   493: 
>  494: \section{Appendix / supplemental material}
   495: 
   496: \section{Related Work}

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 180)
  message: Should this be "What Is a Schema?"? Follow your preferred style guide and register as an exception if necessary.
   178: As seen in Figure 1, our approach is divided into four main parts: 1) Schema Classifier, 2) Prompt Creation, 3) Context Retrieval, and 4) Answer and Response Generation. The training and dataset details are described in Appendix C and D, respectively.
   179: 
>  180: %\subsection{What is a Schema?}
   181: 
   182: A schema is a structured framework that represents a generalized method for solving a specific type of problem \cite{stoddard2019schema}. In the context of MWPs, schemas help categorize problems based on their underlying structure, making it easier to determine which mathematical operations to use \cite{fuchs2004enhancing}. For example, MWPs can often be grouped into two major schemas: Additive and Multiplicative \cite{powell2018effective}.

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 587)
  message: Should this be "Response Generation With Ollama Llama 3.1"? Follow your preferred style guide and register as an exception if necessary.
   585: We use Ollama embeddings to create document embeddings for context retrieval. The embeddings are stored in a Chroma vector store. During the retrieval process, the problem and schema-specific prompt are embedded, and a similarity search is performed to retrieve the most relevant documents. Re-ranking of documents is performed based on cosine similarity between the embedded question and the retrieved documents.
   586: 
>  587: \subsection{Response Generation with Ollama Llama 3.1}
   588: For generating a solution to the problem, we pass the schema, sub-category, and retrieved context to the Llama 3.1 model. The prompt is constructed in a structured format, and the model generates a detailed solution based on the provided context.
   589: 

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 590)
  message: Should this be "Prompt Template Used for Response Generation and With GPT Models"? Follow your preferred style guide and register as an exception if necessary.
   588: For generating a solution to the problem, we pass the schema, sub-category, and retrieved context to the Llama 3.1 model. The prompt is constructed in a structured format, and the model generates a detailed solution based on the provided context.
   589: 
>  590: % \subsection{Prompt Template used for Response Generation and with GPT Models}
   591: 
   592: 

- file: sample\arxiv_sources\2410.13293v2\neurips_2024.tex (line 603)
  message: Should this be "Advanced Re-Ranking for Document Retrieval"? Follow your preferred style guide and register as an exception if necessary.
   601: % In contrast to simple prompting, the SBI-RAG approach augments the response generation by providing context through retrieved documents and schema-based guidance, which significantly influences the reasoning process. This happens prior to the actual prompt, ensuring that the model has the necessary information and context to generate a more accurate and structured solution.
   602: 
>  603: \subsection{Advanced Re-ranking for Document Retrieval}
   604: An advanced re-ranking mechanism is implemented using cosine similarity between question embeddings and document embeddings. This ensures that the most contextually relevant documents are used for generating the final answer.
   605: 

- file: sample\arxiv_sources\2410.16930v4\experiments.tex (line 45)
  message: Should this be "MathNeuro With a Single Sample"? Follow your preferred style guide and register as an exception if necessary.
    43: We next evaluate performance when more highly activating math-specific parameters by scaling the weights by a universal factor.  For smaller models, we find the scalar 1.1 works best, while for larger models (Llama 3.1 8B IT), a smaller factor (1.01) works better. While we leave a rigorous study of this hyperparameter to future work due to its computational expense, see Appendix \ref{sec:hyperparameters} for our experimentation with scale factors. As in Section \ref{deleting_params}, we scale the parameters each method identifies based on 500 random samples from each relevant dataset and repeat the process five times, reporting the parameter proportion that performs best.
    44: \newline \indent Figures \ref{fig:MathNeuro_llama1b_scale}, \ref{fig:MathNeuro_phi15_scale}, \ref{fig:MathNeuro_gemma2b_scale}, \ref{fig:MathNeuro_llama3b_scale}, and \ref{fig:MathNeuro_llama8b_scale} display results from this experiment. An ideal method would fall in the top right of these plots, meaning GSM8K accuracy increases while non-math performance is maintained. As shown in these figures, scaling parameters identified by MathNeuro results in a GSM8K performance increase of 4-17\% across models, while scaling Wanda-identified parameters tends to either harm or slightly improve performance. As with pruning, LAPE performs inconsistently in the scaling setting across models. Scaling random parameters can help for some models, although the effect is not consistent across models. Each parameter identification method does not harm performance on RACE or MMLU, suggesting scaling's impact tends to be localized to math performance. %The GSM8K performance gains from scaling parameters identified by MathNeuro and the lack of catastrophic forgetting are consistent across models and highlight the potential for future work to utilize these parameters for interventions.
>   45: \subsection{MathNeuro with a Single Sample} \label{single_sample}
    46: \vspace{-\topsep}
    47: If a method can identify math-specific parameters using a single sample, then it could inform math interventions for settings where data are limited such as for assessing a specific math operation or topic. To test this with MathNeuro and the baselines, we conduct experiments to identify parameters based on a single math and non-math input. We then prune or scale parameters identified by each method and run each experiment five times using different random samples from each dataset. 

- file: sample\arxiv_sources\2410.16930v4\experiments.tex (line 68)
  message: Should this be "Consistency of Math-Specific Parameters"? Follow your preferred style guide and register as an exception if necessary.
    66:     \label{fig:MathNeuro_llama1b_scale_one_sample}
    67: \end{figure*}
>   68: \paragraph{Consistency of Math-specific Parameters} \label{consistency}
    69: We next explore if MathNeuro consistently identifies the same parameters as math-specific across different random subsets from a math and non-math dataset. This allows us to identify if math reasoning is in fact reliably concentrated in a subset of model parameters like the experiments above suggest. We first identify math-specific parameters using MathNeuro on two different random subsets from a math and non-math dataset. Next, we calculate the percentage overlap between the parameters identified in both subsets. We do this five times for different sample sizes (1, 10, 100, 500, and 1,000) and for calculating different proportions of top parameters from each dataset. This allows us to construct confidence intervals and see how parameter identification consistency varies when calculating based on different sample sizes and top parameter proportions. As shown in Figure \ref{fig:race_consistency} and Appendix \ref{sec:mmlu_param_location_number}, with 100 or more samples, roughly 95\% or more of the parameters MathNeuro identifies overlap between two random subsets regardless of the proportion of top parameters calculated, which shows that the method is able to consistently identify the most important parameters for math performance and that these parameters are largely invariant with regard to the subset of data used to calculate them. 
    70: \begin{figure}[t]

- file: sample\arxiv_sources\2410.16930v4\experiments.tex (line 78)
  message: Should this be "Number and Location of Math-Specific Parameters"? Follow your preferred style guide and register as an exception if necessary.
    76: 
    77: 
>   78: \paragraph{Number and Location of Math-specific Parameters} \label{param_location_and_number}
    79: We next examine the proportion of parameters MathNeuro identifies as math-specific. We first identify math-specific parameters using random subsets from each dataset. Next, we calculate the percentage of the top K\% of parameters that are identified as math-specific using those subsets. We repeat this five times for different sample sizes and top K\%s to construct confidence intervals.  
    80: 

- file: sample\arxiv_sources\2410.16930v4\methods.tex (line 19)
  message: Should this be "Isolating Math-Specific Parameters"? Follow your preferred style guide and register as an exception if necessary.
    17: where $W_{ij}$ represents the weight, $|\cdot|$ is the absolute value operator, and $\| X_j \|_2$ is the $\ell_2$ norm of the \(j\)-th feature aggregated across input tokens to normalize the input $X$, or activation values. Wanda then prunes the parameters with the smallest scores. Wanda considers both weights and activations as elements of parameter importance because small but highly activated weights can be highly influential, while large but lightly activated weights may be less influential. MathNeuro inverts Wanda by identifying the parameters with the largest weights times activations as being most important to a given task. 
    18: 
>   19: \subsection{Isolating Math-specific Parameters}
    20: While naively identifying the parameters with the highest absolute value of weights times activations may find parameters important for a given task, it may not isolate the parameters important for that task \textit{only}, as discussed above. Thus, we calculate parameter importance for other unrelated tasks and use the disjoint set between these sets of parameters as the ones that are math-specific, which is the critical innovation of MathNeuro. To do this, we separately sum\footnote{This summation is akin to gradient-based identification methods summing gradients over inputs (e.g., \citealt{das_unified_2023}).} the absolute value of weights times activations for each parameter in attention and MLP layers for each data point $k$ across $N$ samples from a math dataset and an unrelated natural language task dataset. We focus on attention and MLP layers because recent work has found that knowledge and skills are often distributed in these two model components \cite{wei_does_2024, yin_lofit_2024}. Using this formulation, we compute scores for each parameter over math and non-math inputs: 
    21: \begin{equation*}

- file: sample\arxiv_sources\2411.00387v3\dataset.tex (line 63)
  message: Should this be "Inter-Annotator Agreements."? Follow your preferred style guide and register as an exception if necessary.
    61: \paragraph{Consistency Checks.} To ensure reliability, we perform the following consistency checks: each article is assigned to domain-specific experts for labeling, and we provide precise definitions and examples for each label and category to guide the process. After labeling, we randomly select a subset of the labeled data for consistency evaluation. Additionally, we analyze data points with inconsistent labels, facilitate discussions among annotators to resolve ambiguities and reach a consensus, and refine the annotation guidelines to address any common sources of confusion.
    62: 
>   63: \paragraph{Inter-annotator Agreements.} Regarding the IAA in our human annotation process, we engage 33 domain experts as our annotators to annotate domain-specific articles. After the initial labeling process, the rest annotators (5 Annotator/Discipline on average) from the same domain reviewed the annotated data by switching their labeling components. For the Inter-annotator Agreement, we measure with Cohen's Kappa value and ensure the value ranges from 0.81 to 1 (0.903 on average across all labeled data), regarding the dataset's mathematical symbols and their corresponding attributes. To maintain accuracy, annotators have access to the original papers through the STEM-PoM labeler and annotate the attributes of the data based on the content of the original papers. This thorough review process reinforces the reliability of our annotated dataset.
    64: 
    65: \subsection{STEM-PoM Labeler}

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 345)
  message: Should this be "Pre-Training"? Follow your preferred style guide and register as an exception if necessary.
   343: 
   344: 
>  345: \section{Pre-training}\label{sec:pretraining}
   346: %We use a unidirectional Transformer acting as encoder which we call CarFormer. We argue that we highly benefit from the better sample efficiently induced by the next-token-prediction task instead of masking events like in a BERT mod. Also, in future we plan to explain causality links between events, thus a unidirectional Transformer architecture seems to be a better fit.
   347: %Contrary to similar work on modelling event data with a Transformer architecture \cite{shou2024selfsupervisedcontrastivepretrainingmultivariate}, we use a unidirectional Transformer. We argue that for our prediction task, we highly benefit from the better sample efficiently induced by the next-token-prediction task. Also, in future we plan to explain causality links between events, thus a unidirectional Transformer architecture seems to be a better fit.

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 574)
  message: Should this be "CarFormer Pre-Training Details"? Follow your preferred style guide and register as an exception if necessary.
   572: In real-world settings, EPredictor is easy to use in a car. After each DTC occurrence and until reaching a minimum number of observations is reached, we would then infer the most likely EP and its time of occurrence. If the model is confident enough, the user will be alerted to an impending critical fault and directed to a nearby dealer, hence enhancing vehicle safety on the road and reducing maintenance costs.
   573: \appendix
>  574: \section{CarFormer Pre-training Details}\label{appendix:pretraining}
   575: We trained the CarFormer model for 70,000 steps with a learning rate of \(5 \times 10^{-4}\), scheduled using a cosine warm restart with 10,000 warm-up steps, and a weight decay of 0.1. The loss coefficients were set to \(\alpha = 1\) and \(\beta = 1\). The model architecture included 12 attention heads, 6 layers, and a feature size of 600, utilizing the GELU activation function in all feed-forward layers. We employed the AdamW optimizer with a batch size of 192 and a sequence length of 258, resulting in approximately 34 million parameters. It is important to note that on all experiments we fixed the same number of parameters when introducing news embeddings for all evaluated model to provide a fair comparison, same for Epredictor. The training data was split into $85\%$ training and $15\%$ testing without up-sampling, and random events were injected with a probability of \(p = 0.05\) per sample. On average, each training session lasted about 20 hours on an Nvidia A10G GPU.
   576: 

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 206)
  message: Should this be "Event Sequence Modelling With TPP"? Follow your preferred style guide and register as an exception if necessary.
   204: 
   205: \section{Background and Related Work}
>  206: \subsection{Event Sequence Modelling with TPP}
   207: Event data is commonly modelled via Temporal Point Processes (TPPs), which describe stochastic processes of discrete events. Each event is composed of a time of occurrence $t \in \mathbb{R}^+$ and an event type $u \in U$ forming a pair $(t, u)$. $U$ is a finite set of discrete event types.
   208: A sequence is constructed with multiple pairs of events, such as $S = \{(t_1, u_1), ... , (t_L, u_L)\}$ where $0<t_1< ... < t_n$.

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 266)
  message: Should this be "Self-Supervised Learning"? Follow your preferred style guide and register as an exception if necessary.
   264: \end{split}
   265: \end{equation}
>  266: \subsection{Self-supervised learning}
   267: By leveraging an efficient pre-training task (e.g. token masking or next token prediction) and then fine-tuning a smaller model with fewer parameters for specific tasks, Transformer-based models achieve state-of-the-art performance in natural language processing tasks \cite{bert, gpt3}.
   268: For example, the GPT model is pre-trained on the next token prediction task, where the labels are generated by shifting the tokens to the right. Then, a classification head is added on top of the Transformer model to assign a probability to each token. Contrary to BERT \cite{bert} a causal mask is applied so that tokens can only attend to the previous one, thus preventing cheating. In section \ref{sec:pretraining} we will introduce a pre-trained model serving as an encoder trained on specific event prediction tasks to ensure adaptability to the event stream domain of vehicles. We found that modelling event streams with autoregressive Transformer-based models for fault predictions were not addressed well in the literature \cite{nppreview} although there is some related work for TPPs \cite{lin2022exploring, shou2024selfsupervisedcontrastivepretrainingmultivariate}. 

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 405)
  message: Should this be "Multi-Task Learning"? Follow your preferred style guide and register as an exception if necessary.
   403: Adding \(\mathbf{CE}\) after the projection to query and key can be seen as a refinement of 
   404: \(\mathbf{Q}\), \(\mathbf{K}\) by \(\mathbf{T}\), \(\mathbf{M}\), providing additional context to the attention scores. We also add a scaling factor of 3 to compensate for the additional terms in Equation \ref{eq:qkproduct}.
>  405: \subsection{Multi-task Learning}
   406: \begin{figure}[t]
   407:     \centering

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 646)
  message: Should this be "B.1 Architecture Choice"? Follow your preferred style guide and register as an exception if necessary.
   644: $$
   645: For EPredictor, $L' = L - c$ and $i$ starts at $c$, whereas for CarFormer, $L' = L$ and $i = 0$.
>  646: \subsection{B.1 Architecture choice}
   647: We defined multiple models for comparison with different architectures:
   648: 

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 245)
  message: Should this be "Event-Type Embedding"? Follow your preferred style guide and register as an exception if necessary.
   243: \end{equation}
   244: where $i$ is the index of the $i$-th event, $\omega_0$ is the frequency (usually $10^{-4}$).
>  245: \subsubsection{Event-type Embedding}\label{eventypeemb} To get a dense representation of our sequence, we embed each event into a $d$ dimensional space using an embedding matrix $\mathbf{L}^{V \times d}$ where $V$ is the distinct number of events (vocabulary). As we would do for word embeddings, we create a sequence of one-hot encoded vectors from the event types $\{u_i\}^L_{i=0}$ as $\mathbf{Y} \in \mathbb{R}^{L \times V}$. Thus, the event-type embedding $\mathbf{E} = \mathbf{Y} \mathbf{L} \in \mathbb{R}^{L \times d}$ and the input embedding $\mathbf{U}$ is defined as $\mathbf{U} =\mathbf{E} + \mathbf{P} \in \mathbb{R}^{L \times d}$
   246: 
   247: \subsubsection{Attention}

- file: sample\arxiv_sources\2412.13041v1\Formatting-Instructions-LaTeX-2025.tex (line 579)
  message: Should this be "Feed-Forward and Initialization."? Follow your preferred style guide and register as an exception if necessary.
   577: \subsection{A.1 Models Definition}
   578: A GPT \cite{gpt} model is added to improve comparison over baseline models.
>  579: %\subsubsection{Feed-forward and Initialization.}
   580: We kept the original implementation of the feed-forward layers \cite{attention} but initialize the intermediate layers with: $ W_l \sim \mathcal{N}(0, \frac{2}{L \sqrt{d_l}}) $.
   581: We used root-mean-square normalization (referred to as RMS Norm) from \cite{rmsnorm} instead of traditional layer normalization and initialize all other linear layers using the SMALLINIT schema \cite{transformernotears} $ W_l \sim \mathcal{N}\left(0, \sqrt{\frac{2}{d_l + 4d_l}}\right)$.

- file: sample\arxiv_sources\2502.20808v6\X_1_dataset.tex (line 1)
  message: Should this be "More Details About MV-MATH"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{More Details about MV-MATH}
     2: In this chapter, we will introduce MV-MATH in more detail.
     3: \subsection{Question Distribution}

- file: sample\arxiv_sources\2502.20808v6\X_4_cot.tex (line 1)
  message: Should this be "Results of CoT, 2-Shot on 3 Question Types"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Results of CoT, 2-shot on 3 Question Types}
     2: 
     3: We observe a distinct difference in how prompting strategies affect model performance across different question types as shown in~\Cref{tab:CoT and shot}. For multiple-choice questions, the addition of Chain-of-Thought (CoT) and 2-shot examples tend to decrease performance for most models. Specifically, out of the ten models we test, eight models perform best with the original prompt. This suggests that for multiple-choice questions, which typically require selecting an answer from given options, simpler prompts lead to better outcomes as they reduce potential confusion or overthinking induced by extra information.

- file: sample\arxiv_sources\2501.04519v1\method.tex (line 104)
  message: Should this be "Training With Step-by-Step Verified Reasoning Trajectory"? Follow your preferred style guide and register as an exception if necessary.
   102: \subsection{Self-Evolved Deep Thinking} 
   103: \label{sec:selfevolution}
>  104: \subsubsection{Training with Step-by-Step Verified Reasoning Trajectory}
   105: \vspace{-1ex}
   106: \noindent\textbf{Math Problems Collection}. We collect a large dataset of 747k math word problems with final answer ground-truth labels, primarily from  NuminaMath~\citep{numina_math_datasets} and MetaMath~\citep{yu2023metamath}. Notably, only competition-level problems (e.g., Olympiads and AIME/AMC) from NuminaMath are included, as we  observe that  grade-school-level problems do not significantly improve LLM complex math reasoning. To augment the limited  competition-level problems, we follow ~\citep{xwin} and use GPT-4 to synthesize new problems based on the seed problems in 7.5k MATH train set and 3.6k AMC-AIME training split.  However, GPT-4 often generated unsolvable problems or incorrect solutions for challenging seed problems. To filter these, we prompt GPT-4 to generate 10 solutions per problem, retaining only those with at least 3 consistent solutions. %, which are then accepted as the ground truth.

- file: sample\arxiv_sources\2502.20808v6\4_EXPRIMENTS.tex (line 143)
  message: Should this be "Analysis of Question Type and Difficulty"? Follow your preferred style guide and register as an exception if necessary.
   141: As shown in~\Cref{tab:CoT&shot}, we observe that CoT and few-shot do not always improve model performance on MV-MATH. While Claude performs 3.4\% better with CoT and 1.3\% better with 2-shot based on CoT, GPT4o performs best under CoT with 2-shot setting, while Qwen-vl-max and gpt-4v perform best under CoT setting. For Gemini-1.5-pro and all open-source models, the original versions outperform CoT and CoT with 2-shot prompts. Notably, for all open-source models, performance declines steadily with the introduction of CoT and 2-shot prompting. We conduct further analysis on different types of questions in Appendix, and we find that original prompts perform better for multiple-choice questions, while CoT tends to produce better results for free-form questions. Adding 2-shot on top of CoT tends to degrade model performance on MV-MATH. Similar results are observed in Math-Vision~\cite{mathvision}.
   142: 
>  143: \subsection{Analysis of Question type and Difficulty}
   144: \noindent \textbf{Different Question Types.} We compare the performance of various models on three types of questions. As shown in~\Cref{fig: lidar}(right), the accuracy of the model on multiple-choice questions is significantly higher than on free-form questions. We design two evaluation metrics for multi-step questions: Step Accuracy Rate (\textbf{SAR}) and Question Completeness Rate (\textbf{QCR}). SAR refers to the proportion of correctly answered steps out of the total steps, while QCR is the proportion of questions for which all steps were answered correctly. The model with the best performance on the QCR metric is GPT-4o, achieving only 6\%, while its corresponding SAR is 32.6\%. This reflects the model's insufficient ability to perform complex reasoning on open and multi-step questions, and also reveals that the multiple-choice question format may not truly reflect the model's actual reasoning and problem-solving ability, as they usually rely on prompts to identify options.
   145: 

- file: sample\arxiv_sources\2502.20808v6\3_MI-MATH.tex (line 68)
  message: Should this be "Comparison With Existing Benchmarks"? Follow your preferred style guide and register as an exception if necessary.
    66: \end{figure}
    67: 
>   68: \subsection{Comparison with Existing Benchmarks}
    69: \label{subsec: cv}
    70: Most existing multimodal mathematical reasoning datasets are limited to single-visual contexts, where the model interprets only a single image without the need for information interaction between images. To further distinguish the difference between MV-MATH and other existing ones, we elaborate the benchmark details in~\Cref{fig:comparison}. Here, we primarily compare our MV-MATH with MathVerse-mv~\cite{llava-next-interleave} and CMM-MATH~\cite{mathvista}.

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 783)
  message: Should this be "Domains by Source"? Follow your preferred style guide and register as an exception if necessary.
   781: \clearpage
   782: 
>  783: \section{Domains By Source}
   784: \begin{center}
   785:     \begin{adjustbox}{angle=90}

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 862)
  message: Should this be "Llama-3.1-70B Filter Prompts"? Follow your preferred style guide and register as an exception if necessary.
   860: \label{app:prompts}
   861: 
>  862: \subsection{Llama-3.1-70B Filter prompts}
   863: \label{app:filter_prompts}
   864: 

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 277)
  message: Should this be "Source-Specific Filtering and Cleaning"? Follow your preferred style guide and register as an exception if necessary.
   275: 
   276: % Source-specific Filtering
>  277: \subsubsection{Source-specific Filtering and Cleaning}
   278: The first step in our cleaning and filtering process is to observe a sampling of data from each dataset, and to design bespoke filters to be utilized on each source separately based on their unique idiosyncrasies. 
   279: \paragraph{HARP}

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 337)
  message: Should this be "Source-Agnostic Filtering"? Follow your preferred style guide and register as an exception if necessary.
   335: 
   336: % Source-agnostic filtering
>  337: \subsubsection{Source-agnostic Filtering}
   338: \label{sec:source_agnostic_filters}
   339: % \alon{Probably should slightly re-arrange the paragraphs to align with the desiderata: uniquely verifiable answers, open-ended problems, close-form solutions.}

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 444)
  message: Should this be "Reformulation Strategy"? Follow your preferred style guide and register as an exception if necessary.
   442: 
   443: % - What's the process we use to rewrite the mc problems (rewrite, solve, judge), include prompts and model used (https://github.com/SynthLabsAI/math-reformulation)
>  444: \subsubsection{Reformulation strategy}
   445: \label{sec:reformulation_strategy}
   446: \begin{wraptable}{r}{0.35\textwidth}

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 367)
  message: Should this be "Ensuring That Problems Are Solvable"? Follow your preferred style guide and register as an exception if necessary.
   365: We were surprised to find minimal duplication ($<1\%$), removing only 4,229 problems, with the majority of duplicates being between the Orca-Math (3,916), GSM8k (3,875), and cn\_k12 (405) datasets.
   366: 
>  367: \paragraph{Ensuring that problems are solvable}
   368: For a number of reasons, there are problems in existing math datasets which are not solvable.\\
   369: % - English-only

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 382)
  message: Should this be "Ensuring That Problems Are Open-Ended"? Follow your preferred style guide and register as an exception if necessary.
   380: %\kg{how many were filtered this way? what was the ratio of correctness etc. for the two models?}
   381: 
>  382: \paragraph{Ensuring that problems are open-ended}
   383: An important aspect of reinforcement learning is that the training signal should appropriately attribute the good actions with high rewards and poor actions with low rewards. Therefore, problems with multiple choice answers pose a problem: the model can inadvertently respond with the correct answer option (generally between a 25-50\% chance of guessing correctly) without providing the correct intermediate reasoning steps, leading to a poor learning signal. For this reason, we choose to remove any problems that are multiple choice, True/False, and Yes/No.
   384: To detect and remove all three types of questions, we develop both a regular expression-based filter, and a model-based filter.\\

- file: sample\arxiv_sources\2502.17387v1\main.tex (line 398)
  message: Should this be "Ensuring That Problems Are Uniquely Verifiable"? Follow your preferred style guide and register as an exception if necessary.
   396: Therefore, for each question type, we design a model-based filter by iteratively developing a prompt to use with Llama-3.1-70B~\citep{dubey2024llama3herdmodels}. For example, to develop the prompt for multiple choice questions, we first manually find examples of multiple choice problems and open-ended problems and include these as in-context examples. Next, we run our filter over the dataset and inspect 100 problems classified as positive examples (multiple choice) and 100 problems classified as negative examples (open-ended). We iteratively add the difficult incorrectly classified problems into the prompt, mostly selecting problems following a previously unseen pattern. For these filters we prioritize a high recall, ensuring that we remove as much undesirable data as possible. In this iterative process of filter development, we continue until achieving over 98\% recall, requiring between 5-8 rounds of manual verification.
   397: 
>  398: \paragraph{Ensuring that problems are uniquely verifiable}
   399: A critical aspect of training reasoning models with reinforcement learning is the existence of verifiable answers, generally in the form of a ground truth to be compared against the model response.\\
   400: % Only keep examples where the final answer can be extracted (HARP, Omni-math, MATH, GSM8k include answers, so only need to do this for remaining subsets. answer is usually boxed, sometimes the final line)

- file: sample\arxiv_sources\2507.20527v3\appendix.tex (line 182)
  message: Should this be "Sensitivity Analysis for De-Duplication Threshold"? Follow your preferred style guide and register as an exception if necessary.
   180: 
   181: 
>  182: \section{Sensitivity Analysis for De-duplication Threshold}
   183: \label{app:sensitivity_analysis}
   184: 

- file: sample\arxiv_sources\2507.20527v3\appendix.tex (line 518)
  message: Should this be "Step 1: Identify G Using the Concept of Cyclic Groups"? Follow your preferred style guide and register as an exception if necessary.
   516: The problem asks for the number of subsets $S$ of the set $G = \{ k \mid 1 \leq k \leq 8, \gcd(k, 9) = 1 \}$ that satisfy two conditions: the sum of elements is divisible by 9, and the product of elements is congruent to 1 modulo 9.
   517: 
>  518: \subsubsection*{Step 1: Identify G using the concept of Cyclic Groups}
   519: 
   520: First, we identify the elements of the set $G$ and analyze its structure as a cyclic group under multiplication modulo 9. . . . . . . . . . . . . . . 

- file: sample\arxiv_sources\2502.20808v6\X_7_comparison.tex (line 1)
  message: Should this be "Comparison With Existing Benchmarks"? Follow your preferred style guide and register as an exception if necessary.
>    1: \section{Comparison with Existing Benchmarks}
     2: 
     3: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 299)
  message: Should this be "Submission of Papers to NeurIPS 2025"? Follow your preferred style guide and register as an exception if necessary.
   297: % \input{sand_math}
   298: 
>  299: % \section{Submission of papers to NeurIPS 2025}
   300: 
   301: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 373)
  message: Should this be "General Formatting Instructions"? Follow your preferred style guide and register as an exception if necessary.
   371: 
   372: 
>  373: % \section{General formatting instructions}
   374: % \label{gen_inst}
   375: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 402)
  message: Should this be "Headings: First Level"? Follow your preferred style guide and register as an exception if necessary.
   400: % regarding figures, tables, acknowledgments, and references.
   401: 
>  402: % \section{Headings: first level}
   403: % \label{headings}
   404: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 433)
  message: Should this be "Citations, Figures, Tables, References"? Follow your preferred style guide and register as an exception if necessary.
   431: 
   432: 
>  433: % \section{Citations, figures, tables, references}
   434: % \label{others}
   435: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 571)
  message: Should this be "Preparing PDF Files"? Follow your preferred style guide and register as an exception if necessary.
   569: 
   570: 
>  571: % \section{Preparing PDF files}
   572: 
   573: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 169)
  message: Should this be "De-Duplication and Decontamination"? Follow your preferred style guide and register as an exception if necessary.
   167: \label{subsec:solution_correctness_filtering}
   168: Next, we apply self-consistency \citep{wang2023selfconsistencyimproveschainthought} to $\mathcal{D}_1$: a question is retained only if all $k$ answers agree ($a'_{i1} = a'_{i2} = \dots = a'_{ik}$). One reasoning traceanswer pair $(r_i, a_i)$ is sampled from $k$ pairs to form $\mathcal{D}_{cons}$, yielding 17,578 consistent examples ($\sim$74\% of original yield).
>  169: \subsection{De-duplication and Decontamination}
   170: \label{subsec:decontamination_deduplication}
   171: We ensure novelty and integrity of $\mathcal{D}_{cons}$ via two steps. First, semantic de-duplication is performed using the \texttt{semhash} framework \citep{minishlab2025semhash} with \texttt{minisilab/potion-base-8M} \citep{minishlab2024model2vec}, removing 1,293 duplicates (7.3\%) at a 0.99 similarity threshold, chosen through sensitivity analysis to preserve diversity yet removing duplicates. For the full analysis of threshold see Appendix~\ref{app:sensitivity_analysis}. Next, to prevent test set leakage, we use a two-stage decontamination pipeline: an efficient retrieval model finds the top-5 candidates from test benchmarks, which are then semantically verified by our judge model, $\mathcal{M}_{\text{judge}}$, guided by the prompt (Appendix~\ref{app:decontamination_prompt}). This hybrid design is optimized for scalability, with our model choice empirically justified in Appendix~\ref{app:decontamination_model_choice}, and removed only 4 questions, leaving 16,281 examples.

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 326)
  message: Should this be "Retrieval of Style Files"? Follow your preferred style guide and register as an exception if necessary.
   324: 
   325: 
>  326: % \subsection{Retrieval of style files}
   327: 
   328: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 413)
  message: Should this be "Headings: Second Level"? Follow your preferred style guide and register as an exception if necessary.
   411: 
   412: 
>  413: % \subsection{Headings: second level}
   414: 
   415: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 440)
  message: Should this be "Citations Within the Text"? Follow your preferred style guide and register as an exception if necessary.
   438: 
   439: 
>  440: % \subsection{Citations within the text}
   441: 
   442: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 562)
  message: Should this be "Final Instructions"? Follow your preferred style guide and register as an exception if necessary.
   560: % Note that display math in bare TeX commands will not create correct line numbers for submission. Please use LaTeX (or AMSTeX) commands for unnumbered display math. (You really shouldn't be using \$\$ anyway; see \url{https://tex.stackexchange.com/questions/503/why-is-preferable-to} and \url{https://tex.stackexchange.com/questions/40492/what-are-the-differences-between-align-equation-and-displaymath} for more information.)
   561: 
>  562: % \subsection{Final instructions}
   563: 
   564: % Do not change any aspects of the formatting parameters in the style files.  In

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 419)
  message: Should this be "Headings: Third Level"? Follow your preferred style guide and register as an exception if necessary.
   417: 
   418: 
>  419: % \subsubsection{Headings: third level}
   420: 
   421: 

- file: sample\arxiv_sources\2507.20527v3\neurips_2025.tex (line 349)
  message: Should this be "Preprint Option"? Follow your preferred style guide and register as an exception if necessary.
   347: 
   348: 
>  349: % \paragraph{Preprint option}
   350: % If you wish to post a preprint of your work online, e.g., on arXiv, using the
   351: % NeurIPS style, please use the \verb+preprint+ option. This will create a

- file: sample\arxiv_sources\2509.23213v2\neurips_2025.tex (line 99)
  message: Should this be "One-Shot Multi-Label Causal Discovery Using Autoregressive Transformers as Density Estimators for High-Dimensional Event Sequences"? Follow your preferred style guide and register as an exception if necessary.
    97: }
    98: 
>   99: %\title{One-Shot Multi-Label Causal Discovery using Autoregressive Transformers as Density Estimators for High-dimensional Event Sequences}
   100: \title{One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences}
   101: % The \author macro works with any number of authors. There are two commands

- file: sample\arxiv_sources\2509.23213v2\neurips_2025.tex (line 693)
  message: Should this be "Explanation Example"? Follow your preferred style guide and register as an exception if necessary.
   691: 
   692: 
>  693: \section{Explanation example}\label{appendix:explaination_ex}
   694: To enhance interpretability and illustrate the learned relationships, we present graphical explanations of error pattern occurrences based on sequences of Diagnostic Trouble Codes (DTCs). For each case, we selected representative samples that reflect diverse yet intuitive failure scenarios.
   695: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 114)
  message: Should this be "Related Work"? Follow your preferred style guide and register as an exception if necessary.
   112: \end{itemize}
   113: 
>  114: \section{Related work}
   115: 
   116: \paragraph{AI for mathematical problem solving.}

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1011)
  message: Should this be "Submission of Papers to NeurIPS 2025"? Follow your preferred style guide and register as an exception if necessary.
  1009: \end{comment}
  1010: \begin{comment}
> 1011: \section{Submission of papers to NeurIPS 2025}
  1012: 
  1013: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1085)
  message: Should this be "General Formatting Instructions"? Follow your preferred style guide and register as an exception if necessary.
  1083: 
  1084: 
> 1085: \section{General formatting instructions}
  1086: \label{gen_inst}
  1087: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1114)
  message: Should this be "Headings: First Level"? Follow your preferred style guide and register as an exception if necessary.
  1112: regarding figures, tables, acknowledgments, and references.
  1113: 
> 1114: \section{Headings: first level}
  1115: \label{headings}
  1116: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1145)
  message: Should this be "Citations, Figures, Tables, References"? Follow your preferred style guide and register as an exception if necessary.
  1143: 
  1144: 
> 1145: \section{Citations, figures, tables, references}
  1146: \label{others}
  1147: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1283)
  message: Should this be "Preparing PDF Files"? Follow your preferred style guide and register as an exception if necessary.
  1281: 
  1282: 
> 1283: \section{Preparing PDF files}
  1284: 
  1285: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 369)
  message: Should this be "How Can We Bridge the Gap Between Human and LLM Perceptions of Interestingness?"? Follow your preferred style guide and register as an exception if necessary.
   367: \end{comment}
   368: \begin{comment}
>  369: \subsection{How can we bridge the gap between human and LLM perceptions of interestingness?}
   370: 
   371: \begin{itemize}

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 918)
  message: Should this be "Variant Types"? Follow your preferred style guide and register as an exception if necessary.
   916: \section{Prolific Study}
   917: \label{app:prolific}
>  918: \subsection{Variant types}
   919: \label{app:prolific-variant-types}
   920: \begin{itemize}

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 927)
  message: Should this be "List of Problems"? Follow your preferred style guide and register as an exception if necessary.
   925: 
   926: \clearpage
>  927: \subsection{List of problems}
   928: We list all problems for our Prolific study, their variants, and variant types in Table \ref{tab:prolific_probs}.
   929: \label{app:problems}

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1038)
  message: Should this be "Retrieval of Style Files"? Follow your preferred style guide and register as an exception if necessary.
  1036: 
  1037: 
> 1038: \subsection{Retrieval of style files}
  1039: 
  1040: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1125)
  message: Should this be "Headings: Second Level"? Follow your preferred style guide and register as an exception if necessary.
  1123: 
  1124: 
> 1125: \subsection{Headings: second level}
  1126: 
  1127: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1152)
  message: Should this be "Citations Within the Text"? Follow your preferred style guide and register as an exception if necessary.
  1150: 
  1151: 
> 1152: \subsection{Citations within the text}
  1153: 
  1154: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1274)
  message: Should this be "Final Instructions"? Follow your preferred style guide and register as an exception if necessary.
  1272: Note that display math in bare TeX commands will not create correct line numbers for submission. Please use LaTeX (or AMSTeX) commands for unnumbered display math. (You really shouldn't be using \$\$ anyway; see \url{https://tex.stackexchange.com/questions/503/why-is-preferable-to} and \url{https://tex.stackexchange.com/questions/40492/what-are-the-differences-between-align-equation-and-displaymath} for more information.)
  1273: 
> 1274: \subsection{Final instructions}
  1275: 
  1276: Do not change any aspects of the formatting parameters in the style files.  In

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1131)
  message: Should this be "Headings: Third Level"? Follow your preferred style guide and register as an exception if necessary.
  1129: 
  1130: 
> 1131: \subsubsection{Headings: third level}
  1132: 
  1133: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 116)
  message: Should this be "AI for Mathematical Problem Solving."? Follow your preferred style guide and register as an exception if necessary.
   114: \section{Related work}
   115: 
>  116: \paragraph{AI for mathematical problem solving.}
   117: The use of large language models for math problem solving began with grade- and high-school level mathematics \cite{cobbe2021trainingverifierssolvemath, hendrycks2021measuringmathematicalproblemsolving}. LLMs quickly progressed from solving a handful of problems to saturating the benchmarks due to increased problem-solving abilities \cite{bubeck2023sparksartificialgeneralintelligence}. To address this gap, more challenging benchmarks containing PhD and competition-level mathematics emerged \cite{gulati2025putnamaxiomfunctionalstaticbenchmark, tsoukalas2024putnambenchevaluatingneuraltheoremprovers, glazer2025frontiermathbenchmarkevaluatingadvanced, ai-mathematical-olympiad-prize, ai-mathematical-olympiad-progress-prize-2}. Large Reasoning Models (LRMs), trained with Reinforcement Learning techniques to utilize additional compute at inference-time, quickly rose to this challenge. LRMs from providers like DeepMind \cite{DeepMind2025GeminiGold}, Harmonic \cite{achim2025aristotleimolevelautomatedtheorem}, and OpenAI \cite{openai2025o3o4mini} achieved Gold medal-level performance at the 2025 International Mathematics Olympiad. These accomplishments complement a parallel line of computer-assisted discovery systems (e.g., FunSearch \cite{velikovi2024amplifyinghumanperformancecombinatorial}, AlphaTensor \cite{AlphaTensor2022}, AlphaEvolve \cite{novikov2025alphaevolvecodingagentscientific}), which demonstrated that search, learning, and symbolic tools can together yield novel or improved results. Despite these achievements, these systems share one feature: the solving and discovery models engage in occurs for problems \emph{posed by humans}, and thus they are not evaluated at judging problems. 
   118: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 124)
  message: Should this be "Human Interestingness Judgments."? Follow your preferred style guide and register as an exception if necessary.
   122: \cite{zheng2023judgingllmasajudgemtbenchchatbot, jiang2025codejudgebenchbenchmarkingllmasajudgecoding, stephan2025calculationadjudicationexaminingllm, gu2025surveyllmasajudge}. In our work, we explore whether LLMs' interestingness judgments of the math problems themselves align with peoples' judgements. 
   123: 
>  124: \paragraph{Human interestingness judgments.} Previous work in cognitive science has attempted to build models of what humans find interesting, and ultimately, what drives human curiosity \cite{Loewenstein1994Curiosity, hy_day_curiosity}. Some experiments studied students' reactions to irregular patterns \cite{berlyne1963complexity} and complex shapes \cite{day1967evaluations}, linking how they judged interestingness to complexity, novelty, and incongruity, and how these factors shape exploratory behavior. Studies done within mathematics specifically explore expert appraisals of what makes a proof ``beautiful'' \cite{10.1093/philmat/nku014}. Attempts to build artificially intelligent mathematical systems, including AMD systems such as Graffiti \cite{Colton1999AutomaticCF}, AM \cite{COLTON2000351, Lenat1976AMAA}, HR \cite{Colton1999AutomaticCF, COLTON2000351}, and GT \cite{epstein1987}, operationalized ``interestingness'' via large sets of hand-coded heuristics, which enabled early progress but limited scalability and adaptability across domains. While research in cognitive science has tried to explain how humans judge interestingness, work involving AMD systems often manually imbues these systems with problem features humans deem interesting. While not the primary focus in this work, our data collection and analyses also raise new questions of how people decide what problems are even worth solving~\citep{getzels1982problem, nickles1981problem, chu2025makes, collins2025people, wong2025meta}.  % In our work, we draw on techniques from both cognitive science and artificial intelligence to study how human and LLM judgments of interestingness in math problems compare. %[todo: last sentence needs work]
   125: 
   126: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 144)
  message: Should this be "An Understanding of Which Directions Are Meaningful:"? Follow your preferred style guide and register as an exception if necessary.
   142: \end{itemize}
   143: 
>  144: \paragraph{An understanding of which directions are meaningful:}
   145: \begin{itemize}
   146:     \item \textbf{Human studies: } Evaluations of subjective complexity, pleasingness, and interestingness for a series of random polygons varying in complexity; Role of Specific Curiosity in School Achievement; Complexity and Incongruity Variables as Determinants of Exploratory Choice and Evaluative Ratings

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 155)
  message: Should this be "Crowdsourcing Human Interestingness Judgments."? Follow your preferred style guide and register as an exception if necessary.
   153: We study human interestigness judgments in two participant pools and two different banks of problems: (1) crowdsourced participants reasoning about AMC problems, and (2) IMO participants (engaged in-person at the 2024 competition) reasoning about past IMO problems. Both studies received ethics approval by our institutional ethics review boards (the former study through MIT, and the latter through the University of Cambridge).
   154: 
>  155: \paragraph{Crowdsourcing human interestingness judgments.} %We first describe our crowdsourced participant judgements. 
   156: We recruit 63 participants from Prolific, a crowdsourcing platform common in cognitive science~\citep{palan2018prolific}. Each participant was assigned to one of 2 conditions, rating 10 problems each. Each participant saw the same control problems and either a problem's original version or its variant. Participants were required to think about each problem for at least 1 minute before rating its \emph{interestingness} and \emph{difficulty} on a scale of 0-100, and providing a \mbox{1- to 3-sentence} rationale for each rating. For analysis, we filter out participants that rate the negative control math problem (``What is 28 + 13?'') as having interestingness > 90, which filtered out the 6 outlier participants' responses.
   157: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 165)
  message: Should this be "IMO Data Collection."? Follow your preferred style guide and register as an exception if necessary.
   163: % For our Prolific study, we curate problems from AMC8 and AMC12, high school-level contests given by the Mathematical Association of America \cite{maa-amc}. To systematically probe how dimensions of a problem impact its perception and to increase problem set diversity, we introduce the notion of a \emph{variant}: a type of change that can be applied to a problem to transform it. Examples of variants include increasing/decreasing the sizes of the numbers in the problem, adding/removing steps, etc. For each contest problem, we hand-write a new problem based on a variant type. We also create two control problems: a negative and a positive control, which are later used to filter out any unfaithful participant ratings. This results in our final dataset for the Prolific study, which contains $18$ problems ($2$ controls and $8$ problems with one variant each). A list of all our problems and variants is provided in Appendix \ref{app:prolific}. 
   164: 
>  165: \paragraph{IMO data collection.} We conducted a survey of interestingness judgements made by participants at the 2024 IMO. Each of the 48 survey participants saw 4 problems. Each participant saw the same baseline: problem 1 from IMO 2024. The rest of the problems were selected randomly from IMO shortlists, with each participant survey being unique and including problems from the same area (Algebra, Combinatorics, Number Theory, and Geometry). The participants were asked if they wanted to see the solution to the problem before rating its \emph{interestingness} and \emph{difficulty}. They were also asked to select reasons for their interestingness and uninterestingness rating from a multiple choice list (see Appendix~\ref{app:imo-reasons}), plus an additional free-text box to state their own reasons. Most problems only received 1 to 2 responses; this is too few to compare human and model judgments at a per-problem level. As such, for the bulk of this paper, all IMO data comparisons are made over the interestingness \textit{criteria} that participants selected. 
   166: 
   167: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 183)
  message: Should this be "On Average, LLM Judgments of Interestingness and Difficulty Are Correlated With Human Judgments."? Follow your preferred style guide and register as an exception if necessary.
   181: \end{figure}
   182: 
>  183: \paragraph{On average, LLM judgments of interestingness and difficulty are correlated with human judgments.} For each LLM, we compute the $R^2$ between per-problem mean interestingness in humans and the model (see Figure~\ref{fig:prolific-heatmaps-t1.0}).%  Each cell shows the squared correlation between the row and column agents mean ratings; the diagonal is $100$ by definition. 
   184: The human row/column reveal modelhuman agreement, while other row/column combinations report correlations amongst the models. On the Prolific dataset, modelhuman $R^2$ ranges from about 0.48 to 0.78, with the strongest agreements from the Mistral family. Split-half human $R^2$our noise ceiling on explainable varianceis 0.71 (see Appendix~\ref{app:human_noise_ceiling}).  This indicates that current LLMs (especially those in the Mistral family) are able to approximate human perceptions of interestingness with surprising fidelity.
   185: 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 309)
  message: Should this be "Elegance Played a Key Role in Human Interestingness Judgments of the IMO Problems."? Follow your preferred style guide and register as an exception if necessary.
   307: 
   308: 
>  309: \paragraph{Elegance played a key role in human interestingness judgments of the IMO problems.} For the IMO survey, each participant rated the interestingness of four problems and selected interestingness/uninterestingness rationales for their rating. In Appendix Figure \ref{fig:hist_int_unint}, we include a histogram of the frequency of different rationales for interestingness/uninterestingness. The three most frequently marked reasons for interestingness were ``the problem statement is simple and elegant," ``the solution does not require any sophisticated techniques/theorems," and ``the solution is elegant." We also include a correlation matrix depicting when people chose multiple reasons for interestingness/uninterestingness for the same problem in Appendix Figure~\ref{fig:int_unint_corr}.
   310: 
   311: \paragraph{Most LLMs do not reflect \emph{why} humans find problems interesting.} 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 334)
  message: Should this be "LRMs Tend to Make Flash Judgments of Uninterestingness Than of Interestingness for Simpler Problems."? Follow your preferred style guide and register as an exception if necessary.
   332: 
   333: 
>  334: \paragraph{LRMs tend to make flash judgments of uninterestingness than of interestingness for simpler problems.}
   335: \begin{figure}
   336:     \centering

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 409)
  message: Should this be "LLM Correlation With Human Perceptions of Interestingness and Difficulty"? Follow your preferred style guide and register as an exception if necessary.
   407: \subsection{IMO Participants}
   408: \subsection{LLM Performance}
>  409: \paragraph{LLM Correlation with Human Perceptions of Interestingness and Difficulty}
   410: \begin{table}[h]
   411: \centering

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 647)
  message: Should this be "Elegance Played a Key Role in Human Interestingness Judgments of the IMO Problems."? Follow your preferred style guide and register as an exception if necessary.
   645: \subsection{IMO Survey Results}
   646: \label{app:add_results_imo}
>  647: \paragraph{Elegance played a key role in human interestingness judgments of the IMO problems.} For the IMO survey, each participant rated the interestingness of four problems and selected interestingness/uninterestingness rationales for their rating. In Appendix Figure \ref{fig:hist_int_unint}, we include a histogram of the frequency of different rationales for interestingness/uninterestingness. The three most frequently marked reasons for interestingness were ``the problem statement is simple and elegant," ``the solution does not require any sophisticated techniques/theorems," and ``the solution is elegant." We also include a correlation matrix depicting when people chose multiple reasons for interestingness/uninterestingness for the same problem in Appendix Figure~\ref{fig:int_unint_corr}.
   648: 
   649: \paragraph{Reasons for interestingness across LLMs.} In Figure~\ref{fig:human_interestingness_importance}, we show histograms of human participants importance ratings for various interestingness criteria. Figures~\ref{fig:mistral_7b_interestingness_importance} through \ref{fig:r1_interestingness_importance} includes this for the LLMs we examine. 

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 649)
  message: Should this be "Reasons for Interestingness Across LLMs."? Follow your preferred style guide and register as an exception if necessary.
   647: \paragraph{Elegance played a key role in human interestingness judgments of the IMO problems.} For the IMO survey, each participant rated the interestingness of four problems and selected interestingness/uninterestingness rationales for their rating. In Appendix Figure \ref{fig:hist_int_unint}, we include a histogram of the frequency of different rationales for interestingness/uninterestingness. The three most frequently marked reasons for interestingness were ``the problem statement is simple and elegant," ``the solution does not require any sophisticated techniques/theorems," and ``the solution is elegant." We also include a correlation matrix depicting when people chose multiple reasons for interestingness/uninterestingness for the same problem in Appendix Figure~\ref{fig:int_unint_corr}.
   648: 
>  649: \paragraph{Reasons for interestingness across LLMs.} In Figure~\ref{fig:human_interestingness_importance}, we show histograms of human participants importance ratings for various interestingness criteria. Figures~\ref{fig:mistral_7b_interestingness_importance} through \ref{fig:r1_interestingness_importance} includes this for the LLMs we examine. 
   650: 
   651: % ================= GPT-5 =================

- file: sample\arxiv_sources\2511.08548v1\neurips_2025.tex (line 1061)
  message: Should this be "Preprint Option"? Follow your preferred style guide and register as an exception if necessary.
  1059: 
  1060: 
> 1061: \paragraph{Preprint option}
  1062: If you wish to post a preprint of your work online, e.g., on arXiv, using the
  1063: NeurIPS style, please use the \verb+preprint+ option. This will create a

- file: sample\arxiv_sources\2509.19112v2\neurips_2025.tex (line 81)
  message: Should this be "Efficient One-Shot Causal Graph Aggregation for High-Dimensional Multi-Label Event Sequences"? Follow your preferred style guide and register as an exception if necessary.
    79: % Note. For the workshop paper template, both \title{} and \workshoptitle{} are required, with the former indicating the paper title shown in the title and the latter indicating the workshop title displayed in the footnote. 
    80: 
>   81: %\title{Efficient One-shot Causal Graph Aggregation for High-Dimensional Multi-label Event Sequences}
    82: %\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
    83: 

- file: sample\arxiv_sources\2509.19112v2\neurips_2025.tex (line 117)
  message: Should this be "Towards Practical Multi-Label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation"? Follow your preferred style guide and register as an exception if necessary.
   115: %\title{Production-Scale Multi-Label Causal Discovery via One-Shot Graph Fusion in Event Sequences}
   116: %\title{Scalable Multi-Label Causal Discovery via One-Shot Graph Aggregation in High-Dimensional Event Sequences}
>  117: \title{Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation}
   118: %\title{Towards Multi-label Causal Discovery for  High Dimensional Event Sequences via One-Shot Graph Aggregation}
   119: 

- file: sample\arxiv_sources\2509.19112v2\neurips_2025.tex (line 118)
  message: Should this be "Towards Multi-Label Causal Discovery for  High Dimensional Event Sequences via One-Shot Graph Aggregation"? Follow your preferred style guide and register as an exception if necessary.
   116: %\title{Scalable Multi-Label Causal Discovery via One-Shot Graph Aggregation in High-Dimensional Event Sequences}
   117: \title{Towards Practical Multi-label Causal Discovery in High-Dimensional Event Sequences via One-Shot Graph Aggregation}
>  118: %\title{Towards Multi-label Causal Discovery for  High Dimensional Event Sequences via One-Shot Graph Aggregation}
   119: 
   120: 

- file: sample\arxiv_sources\2509.19112v2\neurips_2025.tex (line 461)
  message: Should this be "Aggregation Under Imperfect CI-Tests"? Follow your preferred style guide and register as an exception if necessary.
   459:  
   460: 
>  461: \subsection{Aggregation under imperfect CI-tests}\label{sec:agg_imperfect_ci_tests}
   462: The assumption of an Oracle CI-tester, while necessary for initial theoretical guarantees, is invariably violated in practice due to factors like model capacity, limited data or class imbalance. The extracted one-shot graphs will most likely violate the independencies in \(\mathbb{G}_k\) and thus \(\mathbb{G}^*\).
   463: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 61)
  message: Should this be "Nemotron-Cc-Math: a 133 Billion-Token-Scale High Quality Math Pretraining Dataset"? Follow your preferred style guide and register as an exception if necessary.
    59: \newcommand{\datasetlocation}[0]{\url{https://huggingface.co/datasets/nvidia/Nemotron-CC-Math-v1}}
    60: 
>   61: \title{Nemotron-cc-math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset}
    62: 
    63: % Authors must not appear in the submitted version. They should be hidden

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 151)
  message: Should this be "Reliable Text Extraction for Scientific Content"? Follow your preferred style guide and register as an exception if necessary.
   149: 
   150: \vspace{-0.5em}
>  151: \subsection{Reliable Text Extraction For Scientific Content}\label{sec:math_extraction_pipeline} %\vspace{-0.5em}
   152: \subsubsection{Limitations of Prior Work}  \label{sec:issues-in-previous-pipeline}
   153: Extracting mathematical content from raw HTML presents a significant challenge for text extraction pipelines. Unlike natural language, which often follows consistent structural patterns, math equations appear in highly variable forms across the web (see Figure~\ref{fig:html-math-varied-forms}). These variations stem from the absence of standardized conventions for embedding math in HTML, as well as the diversity of rendering engines (e.g., MathJax, KaTeX, MathML, image-based representations, and custom plugins). Moreover, websites frequently evolve their rendering strategies, making any fixed set of heuristics fragile in practice. As a result, existing extraction pipelines often fail to reliably extract scientific content, with equations either missed entirely, mis-parsed, or distorted. Preserving formatting is equally important: the indentation and layout of code blocks and the placement of mathematical symbols often carry semantic meaning, and losing this structure severely degrades the value of the extracted content for downstream modeling.

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 311)
  message: Should this be "Ablation on Model Choice"? Follow your preferred style guide and register as an exception if necessary.
   309: 
   310: \vspace{-0.5em}
>  311: \subsection{Ablation On Model Choice} \label{sec:ablation-on-models} %\vspace{-0.5em}
   312: To ablate the model choice for the task of boilerplate removal from rendered web pages, we sampled 7M documents and evaluated several instruction-tuned LLMs including DeepSeek-V3~\citep{liu2024deepseek}, Qwen2.5-32B/Instruct, Qwen2.5-72B/Instruct~\citep{team2024qwen2}, and Phi-4 across knowledge, coding, and math benchmarks.
   313: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 463)
  message: Should this be "Prompt Used for Topic Classification"? Follow your preferred style guide and register as an exception if necessary.
   461: \section{Appendix}
   462: 
>  463: \subsection{Prompt used for Topic Classification} \label{app:classification_prompt}
   464: We employ the following prompt to classify documents into a predefined set of categories. During classification, the large language model (LLM) occasionally produces category labels that fall outside the predefined taxonomy: Mathematics, Computer Science, Physics, Statistics, Economics, Chemistry,  and Other. To maintain consistency and reduce label fragmentation, any out-of-taxonomy label is reassigned to the category Other, ensuring a coherent and structured category distribution.
   465: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 1806)
  message: Should this be "Hyper-Parameters"? Follow your preferred style guide and register as an exception if necessary.
  1804: \end{tcolorbox}
  1805: 
> 1806: \subsection{Hyper-parameters} \label{app:hyperparameters}
  1807: For phase 1 training, we trained a transformer model on a token horizon of 9 trillion tokens. We used a sequence length of 8192 and global batch size of 768 (6291456 tokens per batch). we used a peak learning rate of $6\times10^{-4}$, and warmup over 8.3 billion toknes; we used cosine learning rate decay with a minimum value equal to 1\% of the peak value, and weight decay of 0.1. We use AdamW optimizer~\citep{loshchilov2017decoupled} with parameters $\beta_1=0.9$ and $\beta_2= 0.95$, and a gradient clipping threshold of 1.0.
  1808: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 1856)
  message: Should this be "Data Mixtures Used During Pre-Training Experiments."? Follow your preferred style guide and register as an exception if necessary.
  1854: \end{tcolorbox}
  1855: 
> 1856: \subsection{Data Mixtures used During Pre-training Experiments.} \label{app:blend}
  1857: To evaluate the value of our data, we setup a pretraining experiment. We used the same mixture as used in \citet{nvidia2025nemotronhfamilyaccurateefficient}. The data mixture spans eight broad content categories: web crawl, mathematics, Wikipedia, code, academic publications, high quality crawl subset (Crawl++), multilingual corpora, and synthetic instruction-style datasets. The Crawl++ category aggregates curated web-derived sources such as OpenWebText, BigScience, and Reddit. The multilingual component covers nine languages: Spanish, German, French, Italian, Portuguese, Chinese, Japanese, Korean, and Russian. To construct the mixtures, \citet{nvidia2025nemotronhfamilyaccurateefficient} applied uniform weighting within datasets of the same quality tier, and they assigned greater weight to datasets of higher quality. 
  1858: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 494)
  message: Should this be "Degenerate Cases in Megamath-Pro Dataset"? Follow your preferred style guide and register as an exception if necessary.
   492: %We find the joint subset between OWM, Megamath-pro and our 4+ subset and finemath-4+ and found 97788 samples. 
   493: 
>  494: \subsubsection{Degenerate cases in Megamath-pro dataset}
   495: We identified a subset of degenerate generations within the MegaMath-Pro dataset. Representative examples are presented below to illustrate this phenomenon. Notably, these samples achieve unexpectedly high scores on both mathematical and language scores, raising concerns about the datasets overall reliability for pretraining LLMs. For each example, we provide the associated metadata. The excerpts shown correspond to the initial portion of each generation; in every case, the text extends over several additional pages, repeating the final sentence displayed.
   496: 

- file: sample\arxiv_sources\2508.15096v1\iclr2025_conference.tex (line 497)
  message: Should this be "Side by Side Comparison Between Our Dataset and Prior Work"? Follow your preferred style guide and register as an exception if necessary.
   495: We identified a subset of degenerate generations within the MegaMath-Pro dataset. Representative examples are presented below to illustrate this phenomenon. Notably, these samples achieve unexpectedly high scores on both mathematical and language scores, raising concerns about the datasets overall reliability for pretraining LLMs. For each example, we provide the associated metadata. The excerpts shown correspond to the initial portion of each generation; in every case, the text extends over several additional pages, repeating the final sentence displayed.
   496: 
>  497: \subsubsection{Side by side comparison between our dataset and prior work} 
   498: We observe that our pipeline not only keep the math equations but also keep the codes and their formatting.
   499: We observe that previous pipeline in most cases are not keeping codes or lose their formatting. This is specifically important for languages like python. To highlight this difference, we provide two sets of examples demonstrating both code and mathematical equations. Notably, inline equations are often removed in prior work, such as MegaMath.

- file: sample\arxiv_sources\2501.05096v2\arxiv25.tex (line 9134)
  message: Should this be "Elemente Der Mathematik"? Follow your preferred style guide and register as an exception if necessary.
  9132: 
  9133: 
> 9134: \gr{\huge\section{Elemente der Mathematik}}
  9135: \bigskip
  9136: 

- file: sample\arxiv_sources\2501.05096v2\arxiv25.tex (line 1159)
  message: Should this be "The Calculations"? Follow your preferred style guide and register as an exception if necessary.
  1157:    $$S(r)=\sum_{j=0}^{\infty}  \binom{r-1}{j} (-1)^j  \frac{2}{(j+1)^3}.$$
  1158:    
> 1159:  \subsection{The calculations}
  1160:   
  1161:  Let $m,n\in\N^*:=\N\setminus \{0\}$  and $r\in \R, r\geq0$. Then

- file: sample\arxiv_sources\2501.05096v2\arxiv25.tex (line 6970)
  message: Should this be "An Analytic Proof"? Follow your preferred style guide and register as an exception if necessary.
  6968: \end{figure}
  6969: 
> 6970: \subsection{An analytic proof}
  6971: 
  6972: The intersection condition is equivalent to  solving, for $a\not=0$,  the cubic polynomial equation

